{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T22:07:29.470465Z",
     "start_time": "2025-04-28T22:07:29.467473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# The Facial Point Detection competition\n",
    "# Kaggle link to the competition: https://www.kaggle.com/competitions/facial-keypoints-detection"
   ],
   "id": "de1c39f5281c2aa9",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T22:07:29.526340Z",
     "start_time": "2025-04-28T22:07:29.522578Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from fontTools.misc import transform\n",
    "from torch import nn\n",
    "from torch.nn import BatchNorm1d\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv"
   ],
   "id": "74d8b90a8a2c5993",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T22:07:50.276808Z",
     "start_time": "2025-04-28T22:07:29.570086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def images_df_to_tensor(df):\n",
    "    split_df = df['Image'].str.split(' ', expand=True)\n",
    "    array = split_df.astype(np.float32).to_numpy()\n",
    "    tensor = torch.tensor(array, dtype=torch.float32)\n",
    "    tensor = tensor.reshape(-1, 1, 96, 96)\n",
    "    return tensor\n",
    "\n",
    "class FacialDataset(Dataset):\n",
    "    def __init__(self, csv_path):\n",
    "        self.images = pd.read_csv(csv_path)\n",
    "        self.labels = self.images.drop(\"Image\", axis=1)\n",
    "        self.images = self.images[[\"Image\"]]\n",
    "\n",
    "        self.labels = torch.tensor(self.labels.values, dtype=torch.float32).squeeze() / 95 - 0.5\n",
    "        self.images = images_df_to_tensor(self.images) / 255 - 0.5\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx], self.labels[idx]\n",
    "\n",
    "class UnlabeledFacialDataset(Dataset):\n",
    "    def __init__(self, csv_path):\n",
    "        self.images = pd.read_csv(csv_path)\n",
    "        self.images = self.images[[\"Image\"]]\n",
    "        self.images = images_df_to_tensor(self.images) / 255 - 0.5\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx]\n",
    "\n",
    "train_dataset = FacialDataset(\"data/training.csv\")\n",
    "\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "train_set, test_set = random_split(train_dataset, [0.80, 0.20], generator=generator)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=64, shuffle=True)"
   ],
   "id": "a2a040da9fc69d05",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T22:07:50.291048Z",
     "start_time": "2025-04-28T22:07:50.288201Z"
    }
   },
   "cell_type": "code",
   "source": "train_dataset.images.shape",
   "id": "f161ff1e54f71778",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7049, 1, 96, 96])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T22:07:50.426529Z",
     "start_time": "2025-04-28T22:07:50.341679Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Display image and label.\n",
    "train_features, train_labels = next(iter(train_loader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = (train_features[0].squeeze() + 0.5) * 255\n",
    "label = train_labels[0]\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")\n"
   ],
   "id": "ad5ddb5bcd19075b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 1, 96, 96])\n",
      "Labels batch shape: torch.Size([64, 30])\n",
      "Feature batch shape: torch.Size([64, 1, 96, 96])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor([ 0.2020, -0.1223, -0.2045, -0.1007,  0.1229, -0.1043,  0.2920, -0.1187,\n",
      "        -0.1218, -0.1043, -0.2980, -0.0899,  0.0725, -0.2050,  0.3675, -0.2446,\n",
      "        -0.0534, -0.1907, -0.3736, -0.1979,  0.0401,  0.1079,  0.2020,  0.3130,\n",
      "        -0.1577,  0.3094,  0.0365,  0.2411,  0.0365,  0.3706])\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T22:07:50.665841Z",
     "start_time": "2025-04-28T22:07:50.442680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "class LinearBlock(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "        self.relu = nn.LeakyReLU(0.1)\n",
    "        self.norm = nn.BatchNorm1d(out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_features, out_features, 3)\n",
    "        self.batchnorm = nn.BatchNorm2d(out_features)\n",
    "        self.relu = nn.LeakyReLU(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.batchnorm(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_stack = nn.Sequential(\n",
    "            ConvBlock(1, 2),\n",
    "            ConvBlock(2, 4),\n",
    "            nn.MaxPool2d(2),\n",
    "            ConvBlock(4, 8),\n",
    "            ConvBlock(8, 16),\n",
    "            nn.MaxPool2d(2),\n",
    "            ConvBlock(16, 16),\n",
    "            ConvBlock(16, 32),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.block1 = LinearBlock(2048, 2048*2)\n",
    "        self.block2 = LinearBlock(2048*2, 2048*2)\n",
    "        self.block3 = LinearBlock(2048*2, 2048)\n",
    "        self.block4 = LinearBlock(2048, 30)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_stack(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        return x\n",
    "\n",
    "model = NeuralNetwork().eval()\n",
    "print(f\"Model size {sum(p.numel() for p in model.parameters())}\")\n",
    "\n",
    "_ = model(train_dataset[0][0].unsqueeze(0))\n"
   ],
   "id": "501c47a387f91171",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Model size 33655358\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T22:07:50.683553Z",
     "start_time": "2025-04-28T22:07:50.678406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "step_count = 0\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    global step_count\n",
    "    global train_accuracy, train_losses\n",
    "    total_loss = 0\n",
    "    total = 0\n",
    "    curr_step_count = 0\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        total_loss += loss.item()\n",
    "        total += y.size(0)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        step_count += 1\n",
    "        curr_step_count += 1\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"Loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            print(f\"At step count {step_count}\")\n",
    "\n",
    "    train_losses.append(total_loss / curr_step_count)\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    global test_losses\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Avg loss: {test_loss:>8f} \\n\")\n",
    "    test_losses.append(test_loss)"
   ],
   "id": "abb87fb5dbd8cd5b",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T22:57:59.741348Z",
     "start_time": "2025-04-28T22:07:50.729189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "def plot_metrics():\n",
    "    global train_losses, test_losses\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(25, 10))\n",
    "\n",
    "    # Plot loss\n",
    "    ax.plot(train_losses[10:], label='Train Loss', marker='o', linestyle='-')\n",
    "    ax.plot(test_losses[10:], label='Test Loss', marker='s', linestyle='--')\n",
    "\n",
    "    ax.set_title(\"Loss Over Epochs\")\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.legend()\n",
    "    ax.grid()\n",
    "    plt.show()\n",
    "\n",
    "class loss_function(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "\n",
    "    def forward(self, label, x):\n",
    "        mask = ~torch.isnan(x)\n",
    "        return self.mse_loss(x[mask], label[mask])\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "loss_fn = loss_function()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "epochs = 1000\n",
    "print(\"Start\")\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_loader, model, loss_fn, optimizer)\n",
    "    test(test_loader, model, loss_fn)\n",
    "print(\"Done!\")\n",
    "\n",
    "plot_metrics()"
   ],
   "id": "4683ab6aa09f3257",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "Loss: 0.498663  [   64/ 7049]\n",
      "At step count 1\n",
      "Loss: 0.053815  [ 6464/ 7049]\n",
      "At step count 101\n",
      "Test Error: \n",
      " Avg loss: 0.159349 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "Loss: 0.068533  [   64/ 7049]\n",
      "At step count 112\n",
      "Loss: 0.036226  [ 6464/ 7049]\n",
      "At step count 212\n",
      "Test Error: \n",
      " Avg loss: 0.052294 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "Loss: 0.032184  [   64/ 7049]\n",
      "At step count 223\n",
      "Loss: 0.027348  [ 6464/ 7049]\n",
      "At step count 323\n",
      "Test Error: \n",
      " Avg loss: 0.022759 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "Loss: 0.031544  [   64/ 7049]\n",
      "At step count 334\n",
      "Loss: 0.024381  [ 6464/ 7049]\n",
      "At step count 434\n",
      "Test Error: \n",
      " Avg loss: 0.048044 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "Loss: 0.019833  [   64/ 7049]\n",
      "At step count 445\n",
      "Loss: 0.017163  [ 6464/ 7049]\n",
      "At step count 545\n",
      "Test Error: \n",
      " Avg loss: 0.056012 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "Loss: 0.031508  [   64/ 7049]\n",
      "At step count 556\n",
      "Loss: 0.034578  [ 6464/ 7049]\n",
      "At step count 656\n",
      "Test Error: \n",
      " Avg loss: 0.019254 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "Loss: 0.021526  [   64/ 7049]\n",
      "At step count 667\n",
      "Loss: 0.029986  [ 6464/ 7049]\n",
      "At step count 767\n",
      "Test Error: \n",
      " Avg loss: 0.033532 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "Loss: 0.014301  [   64/ 7049]\n",
      "At step count 778\n",
      "Loss: 0.015006  [ 6464/ 7049]\n",
      "At step count 878\n",
      "Test Error: \n",
      " Avg loss: 0.055957 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "Loss: 0.018834  [   64/ 7049]\n",
      "At step count 889\n",
      "Loss: 0.021364  [ 6464/ 7049]\n",
      "At step count 989\n",
      "Test Error: \n",
      " Avg loss: 0.048386 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "Loss: 0.022983  [   64/ 7049]\n",
      "At step count 1000\n",
      "Loss: 0.017595  [ 6464/ 7049]\n",
      "At step count 1100\n",
      "Test Error: \n",
      " Avg loss: 0.019985 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "Loss: 0.015830  [   64/ 7049]\n",
      "At step count 1111\n",
      "Loss: 0.022025  [ 6464/ 7049]\n",
      "At step count 1211\n",
      "Test Error: \n",
      " Avg loss: 0.027474 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "Loss: 0.016947  [   64/ 7049]\n",
      "At step count 1222\n",
      "Loss: 0.017549  [ 6464/ 7049]\n",
      "At step count 1322\n",
      "Test Error: \n",
      " Avg loss: 0.033763 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "Loss: 0.013441  [   64/ 7049]\n",
      "At step count 1333\n",
      "Loss: 0.014766  [ 6464/ 7049]\n",
      "At step count 1433\n",
      "Test Error: \n",
      " Avg loss: 0.022485 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "Loss: 0.013382  [   64/ 7049]\n",
      "At step count 1444\n",
      "Loss: 0.016076  [ 6464/ 7049]\n",
      "At step count 1544\n",
      "Test Error: \n",
      " Avg loss: 0.034745 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "Loss: 0.012543  [   64/ 7049]\n",
      "At step count 1555\n",
      "Loss: 0.013072  [ 6464/ 7049]\n",
      "At step count 1655\n",
      "Test Error: \n",
      " Avg loss: 0.020764 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "Loss: 0.010803  [   64/ 7049]\n",
      "At step count 1666\n",
      "Loss: 0.012092  [ 6464/ 7049]\n",
      "At step count 1766\n",
      "Test Error: \n",
      " Avg loss: 0.026404 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "Loss: 0.010011  [   64/ 7049]\n",
      "At step count 1777\n",
      "Loss: 0.009976  [ 6464/ 7049]\n",
      "At step count 1877\n",
      "Test Error: \n",
      " Avg loss: 0.023858 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "Loss: 0.009637  [   64/ 7049]\n",
      "At step count 1888\n",
      "Loss: 0.015184  [ 6464/ 7049]\n",
      "At step count 1988\n",
      "Test Error: \n",
      " Avg loss: 0.018413 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "Loss: 0.011736  [   64/ 7049]\n",
      "At step count 1999\n",
      "Loss: 0.009250  [ 6464/ 7049]\n",
      "At step count 2099\n",
      "Test Error: \n",
      " Avg loss: 0.044726 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "Loss: 0.011917  [   64/ 7049]\n",
      "At step count 2110\n",
      "Loss: 0.013535  [ 6464/ 7049]\n",
      "At step count 2210\n",
      "Test Error: \n",
      " Avg loss: 0.021072 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "Loss: 0.010556  [   64/ 7049]\n",
      "At step count 2221\n",
      "Loss: 0.009704  [ 6464/ 7049]\n",
      "At step count 2321\n",
      "Test Error: \n",
      " Avg loss: 0.023974 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "Loss: 0.017918  [   64/ 7049]\n",
      "At step count 2332\n",
      "Loss: 0.008130  [ 6464/ 7049]\n",
      "At step count 2432\n",
      "Test Error: \n",
      " Avg loss: 0.013005 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "Loss: 0.007957  [   64/ 7049]\n",
      "At step count 2443\n",
      "Loss: 0.010632  [ 6464/ 7049]\n",
      "At step count 2543\n",
      "Test Error: \n",
      " Avg loss: 0.013736 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "Loss: 0.014968  [   64/ 7049]\n",
      "At step count 2554\n",
      "Loss: 0.007671  [ 6464/ 7049]\n",
      "At step count 2654\n",
      "Test Error: \n",
      " Avg loss: 0.027246 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "Loss: 0.008106  [   64/ 7049]\n",
      "At step count 2665\n",
      "Loss: 0.008663  [ 6464/ 7049]\n",
      "At step count 2765\n",
      "Test Error: \n",
      " Avg loss: 0.013575 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "Loss: 0.006962  [   64/ 7049]\n",
      "At step count 2776\n",
      "Loss: 0.008380  [ 6464/ 7049]\n",
      "At step count 2876\n",
      "Test Error: \n",
      " Avg loss: 0.012304 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "Loss: 0.008047  [   64/ 7049]\n",
      "At step count 2887\n",
      "Loss: 0.007098  [ 6464/ 7049]\n",
      "At step count 2987\n",
      "Test Error: \n",
      " Avg loss: 0.020097 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "Loss: 0.006875  [   64/ 7049]\n",
      "At step count 2998\n",
      "Loss: 0.009615  [ 6464/ 7049]\n",
      "At step count 3098\n",
      "Test Error: \n",
      " Avg loss: 0.016881 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "Loss: 0.007930  [   64/ 7049]\n",
      "At step count 3109\n",
      "Loss: 0.013867  [ 6464/ 7049]\n",
      "At step count 3209\n",
      "Test Error: \n",
      " Avg loss: 0.020860 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "Loss: 0.007233  [   64/ 7049]\n",
      "At step count 3220\n",
      "Loss: 0.007142  [ 6464/ 7049]\n",
      "At step count 3320\n",
      "Test Error: \n",
      " Avg loss: 0.021865 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "Loss: 0.008277  [   64/ 7049]\n",
      "At step count 3331\n",
      "Loss: 0.006411  [ 6464/ 7049]\n",
      "At step count 3431\n",
      "Test Error: \n",
      " Avg loss: 0.012800 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "Loss: 0.006569  [   64/ 7049]\n",
      "At step count 3442\n",
      "Loss: 0.007583  [ 6464/ 7049]\n",
      "At step count 3542\n",
      "Test Error: \n",
      " Avg loss: 0.010988 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "Loss: 0.005982  [   64/ 7049]\n",
      "At step count 3553\n",
      "Loss: 0.006386  [ 6464/ 7049]\n",
      "At step count 3653\n",
      "Test Error: \n",
      " Avg loss: 0.015780 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "Loss: 0.006003  [   64/ 7049]\n",
      "At step count 3664\n",
      "Loss: 0.005817  [ 6464/ 7049]\n",
      "At step count 3764\n",
      "Test Error: \n",
      " Avg loss: 0.017486 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "Loss: 0.005261  [   64/ 7049]\n",
      "At step count 3775\n",
      "Loss: 0.005785  [ 6464/ 7049]\n",
      "At step count 3875\n",
      "Test Error: \n",
      " Avg loss: 0.014388 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "Loss: 0.005938  [   64/ 7049]\n",
      "At step count 3886\n",
      "Loss: 0.005504  [ 6464/ 7049]\n",
      "At step count 3986\n",
      "Test Error: \n",
      " Avg loss: 0.010131 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "Loss: 0.005373  [   64/ 7049]\n",
      "At step count 3997\n",
      "Loss: 0.005301  [ 6464/ 7049]\n",
      "At step count 4097\n",
      "Test Error: \n",
      " Avg loss: 0.008988 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "Loss: 0.004499  [   64/ 7049]\n",
      "At step count 4108\n",
      "Loss: 0.005657  [ 6464/ 7049]\n",
      "At step count 4208\n",
      "Test Error: \n",
      " Avg loss: 0.012572 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "Loss: 0.005040  [   64/ 7049]\n",
      "At step count 4219\n",
      "Loss: 0.004194  [ 6464/ 7049]\n",
      "At step count 4319\n",
      "Test Error: \n",
      " Avg loss: 0.015455 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "Loss: 0.004669  [   64/ 7049]\n",
      "At step count 4330\n",
      "Loss: 0.003990  [ 6464/ 7049]\n",
      "At step count 4430\n",
      "Test Error: \n",
      " Avg loss: 0.005775 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "Loss: 0.004435  [   64/ 7049]\n",
      "At step count 4441\n",
      "Loss: 0.004684  [ 6464/ 7049]\n",
      "At step count 4541\n",
      "Test Error: \n",
      " Avg loss: 0.008625 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "Loss: 0.005140  [   64/ 7049]\n",
      "At step count 4552\n",
      "Loss: 0.004211  [ 6464/ 7049]\n",
      "At step count 4652\n",
      "Test Error: \n",
      " Avg loss: 0.007070 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "Loss: 0.004120  [   64/ 7049]\n",
      "At step count 4663\n",
      "Loss: 0.003462  [ 6464/ 7049]\n",
      "At step count 4763\n",
      "Test Error: \n",
      " Avg loss: 0.007008 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "Loss: 0.004347  [   64/ 7049]\n",
      "At step count 4774\n",
      "Loss: 0.003661  [ 6464/ 7049]\n",
      "At step count 4874\n",
      "Test Error: \n",
      " Avg loss: 0.008323 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "Loss: 0.003705  [   64/ 7049]\n",
      "At step count 4885\n",
      "Loss: 0.003138  [ 6464/ 7049]\n",
      "At step count 4985\n",
      "Test Error: \n",
      " Avg loss: 0.005880 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "Loss: 0.003682  [   64/ 7049]\n",
      "At step count 4996\n",
      "Loss: 0.003249  [ 6464/ 7049]\n",
      "At step count 5096\n",
      "Test Error: \n",
      " Avg loss: 0.004952 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "Loss: 0.003121  [   64/ 7049]\n",
      "At step count 5107\n",
      "Loss: 0.002964  [ 6464/ 7049]\n",
      "At step count 5207\n",
      "Test Error: \n",
      " Avg loss: 0.005229 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "Loss: 0.003454  [   64/ 7049]\n",
      "At step count 5218\n",
      "Loss: 0.002939  [ 6464/ 7049]\n",
      "At step count 5318\n",
      "Test Error: \n",
      " Avg loss: 0.004475 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "Loss: 0.002804  [   64/ 7049]\n",
      "At step count 5329\n",
      "Loss: 0.002200  [ 6464/ 7049]\n",
      "At step count 5429\n",
      "Test Error: \n",
      " Avg loss: 0.007358 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "Loss: 0.002265  [   64/ 7049]\n",
      "At step count 5440\n",
      "Loss: 0.004597  [ 6464/ 7049]\n",
      "At step count 5540\n",
      "Test Error: \n",
      " Avg loss: 0.003683 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "Loss: 0.003089  [   64/ 7049]\n",
      "At step count 5551\n",
      "Loss: 0.002401  [ 6464/ 7049]\n",
      "At step count 5651\n",
      "Test Error: \n",
      " Avg loss: 0.003082 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "Loss: 0.002425  [   64/ 7049]\n",
      "At step count 5662\n",
      "Loss: 0.002151  [ 6464/ 7049]\n",
      "At step count 5762\n",
      "Test Error: \n",
      " Avg loss: 0.003854 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "Loss: 0.001973  [   64/ 7049]\n",
      "At step count 5773\n",
      "Loss: 0.002388  [ 6464/ 7049]\n",
      "At step count 5873\n",
      "Test Error: \n",
      " Avg loss: 0.005868 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "Loss: 0.002113  [   64/ 7049]\n",
      "At step count 5884\n",
      "Loss: 0.002269  [ 6464/ 7049]\n",
      "At step count 5984\n",
      "Test Error: \n",
      " Avg loss: 0.002664 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "Loss: 0.002253  [   64/ 7049]\n",
      "At step count 5995\n",
      "Loss: 0.002311  [ 6464/ 7049]\n",
      "At step count 6095\n",
      "Test Error: \n",
      " Avg loss: 0.001955 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "Loss: 0.001564  [   64/ 7049]\n",
      "At step count 6106\n",
      "Loss: 0.002002  [ 6464/ 7049]\n",
      "At step count 6206\n",
      "Test Error: \n",
      " Avg loss: 0.001630 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "Loss: 0.001722  [   64/ 7049]\n",
      "At step count 6217\n",
      "Loss: 0.002437  [ 6464/ 7049]\n",
      "At step count 6317\n",
      "Test Error: \n",
      " Avg loss: 0.003399 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "Loss: 0.002448  [   64/ 7049]\n",
      "At step count 6328\n",
      "Loss: 0.005245  [ 6464/ 7049]\n",
      "At step count 6428\n",
      "Test Error: \n",
      " Avg loss: 0.004787 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "Loss: 0.004443  [   64/ 7049]\n",
      "At step count 6439\n",
      "Loss: 0.030924  [ 6464/ 7049]\n",
      "At step count 6539\n",
      "Test Error: \n",
      " Avg loss: 0.003323 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "Loss: 0.002834  [   64/ 7049]\n",
      "At step count 6550\n",
      "Loss: 0.002228  [ 6464/ 7049]\n",
      "At step count 6650\n",
      "Test Error: \n",
      " Avg loss: 0.002513 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "Loss: 0.003437  [   64/ 7049]\n",
      "At step count 6661\n",
      "Loss: 0.004304  [ 6464/ 7049]\n",
      "At step count 6761\n",
      "Test Error: \n",
      " Avg loss: 0.002071 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "Loss: 0.001934  [   64/ 7049]\n",
      "At step count 6772\n",
      "Loss: 0.001790  [ 6464/ 7049]\n",
      "At step count 6872\n",
      "Test Error: \n",
      " Avg loss: 0.001974 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "Loss: 0.001678  [   64/ 7049]\n",
      "At step count 6883\n",
      "Loss: 0.001299  [ 6464/ 7049]\n",
      "At step count 6983\n",
      "Test Error: \n",
      " Avg loss: 0.001810 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "Loss: 0.001738  [   64/ 7049]\n",
      "At step count 6994\n",
      "Loss: 0.001620  [ 6464/ 7049]\n",
      "At step count 7094\n",
      "Test Error: \n",
      " Avg loss: 0.001639 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "Loss: 0.001635  [   64/ 7049]\n",
      "At step count 7105\n",
      "Loss: 0.001493  [ 6464/ 7049]\n",
      "At step count 7205\n",
      "Test Error: \n",
      " Avg loss: 0.001623 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "Loss: 0.001678  [   64/ 7049]\n",
      "At step count 7216\n",
      "Loss: 0.002112  [ 6464/ 7049]\n",
      "At step count 7316\n",
      "Test Error: \n",
      " Avg loss: 0.007763 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "Loss: 0.002277  [   64/ 7049]\n",
      "At step count 7327\n",
      "Loss: 0.002428  [ 6464/ 7049]\n",
      "At step count 7427\n",
      "Test Error: \n",
      " Avg loss: 0.002892 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "Loss: 0.002822  [   64/ 7049]\n",
      "At step count 7438\n",
      "Loss: 0.001605  [ 6464/ 7049]\n",
      "At step count 7538\n",
      "Test Error: \n",
      " Avg loss: 0.001761 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "Loss: 0.002263  [   64/ 7049]\n",
      "At step count 7549\n",
      "Loss: 0.001588  [ 6464/ 7049]\n",
      "At step count 7649\n",
      "Test Error: \n",
      " Avg loss: 0.001792 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "Loss: 0.001469  [   64/ 7049]\n",
      "At step count 7660\n",
      "Loss: 0.001339  [ 6464/ 7049]\n",
      "At step count 7760\n",
      "Test Error: \n",
      " Avg loss: 0.001614 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "Loss: 0.001689  [   64/ 7049]\n",
      "At step count 7771\n",
      "Loss: 0.001265  [ 6464/ 7049]\n",
      "At step count 7871\n",
      "Test Error: \n",
      " Avg loss: 0.001355 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "Loss: 0.001378  [   64/ 7049]\n",
      "At step count 7882\n",
      "Loss: 0.001113  [ 6464/ 7049]\n",
      "At step count 7982\n",
      "Test Error: \n",
      " Avg loss: 0.001230 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "Loss: 0.001147  [   64/ 7049]\n",
      "At step count 7993\n",
      "Loss: 0.001742  [ 6464/ 7049]\n",
      "At step count 8093\n",
      "Test Error: \n",
      " Avg loss: 0.001198 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "Loss: 0.001020  [   64/ 7049]\n",
      "At step count 8104\n",
      "Loss: 0.000975  [ 6464/ 7049]\n",
      "At step count 8204\n",
      "Test Error: \n",
      " Avg loss: 0.001386 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "Loss: 0.001268  [   64/ 7049]\n",
      "At step count 8215\n",
      "Loss: 0.000904  [ 6464/ 7049]\n",
      "At step count 8315\n",
      "Test Error: \n",
      " Avg loss: 0.001081 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "Loss: 0.000885  [   64/ 7049]\n",
      "At step count 8326\n",
      "Loss: 0.001001  [ 6464/ 7049]\n",
      "At step count 8426\n",
      "Test Error: \n",
      " Avg loss: 0.000896 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "Loss: 0.000881  [   64/ 7049]\n",
      "At step count 8437\n",
      "Loss: 0.000855  [ 6464/ 7049]\n",
      "At step count 8537\n",
      "Test Error: \n",
      " Avg loss: 0.000883 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "Loss: 0.001036  [   64/ 7049]\n",
      "At step count 8548\n",
      "Loss: 0.000841  [ 6464/ 7049]\n",
      "At step count 8648\n",
      "Test Error: \n",
      " Avg loss: 0.000841 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "Loss: 0.000821  [   64/ 7049]\n",
      "At step count 8659\n",
      "Loss: 0.000938  [ 6464/ 7049]\n",
      "At step count 8759\n",
      "Test Error: \n",
      " Avg loss: 0.000793 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "Loss: 0.000823  [   64/ 7049]\n",
      "At step count 8770\n",
      "Loss: 0.000755  [ 6464/ 7049]\n",
      "At step count 8870\n",
      "Test Error: \n",
      " Avg loss: 0.000751 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "Loss: 0.000864  [   64/ 7049]\n",
      "At step count 8881\n",
      "Loss: 0.000663  [ 6464/ 7049]\n",
      "At step count 8981\n",
      "Test Error: \n",
      " Avg loss: 0.000685 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "Loss: 0.000905  [   64/ 7049]\n",
      "At step count 8992\n",
      "Loss: 0.000781  [ 6464/ 7049]\n",
      "At step count 9092\n",
      "Test Error: \n",
      " Avg loss: 0.000727 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "Loss: 0.000680  [   64/ 7049]\n",
      "At step count 9103\n",
      "Loss: 0.000604  [ 6464/ 7049]\n",
      "At step count 9203\n",
      "Test Error: \n",
      " Avg loss: 0.000766 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "Loss: 0.001018  [   64/ 7049]\n",
      "At step count 9214\n",
      "Loss: 0.000484  [ 6464/ 7049]\n",
      "At step count 9314\n",
      "Test Error: \n",
      " Avg loss: 0.000730 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "Loss: 0.000552  [   64/ 7049]\n",
      "At step count 9325\n",
      "Loss: 0.000622  [ 6464/ 7049]\n",
      "At step count 9425\n",
      "Test Error: \n",
      " Avg loss: 0.000646 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "Loss: 0.000662  [   64/ 7049]\n",
      "At step count 9436\n",
      "Loss: 0.000532  [ 6464/ 7049]\n",
      "At step count 9536\n",
      "Test Error: \n",
      " Avg loss: 0.000601 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "Loss: 0.000786  [   64/ 7049]\n",
      "At step count 9547\n",
      "Loss: 0.000527  [ 6464/ 7049]\n",
      "At step count 9647\n",
      "Test Error: \n",
      " Avg loss: 0.000647 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "Loss: 0.000406  [   64/ 7049]\n",
      "At step count 9658\n",
      "Loss: 0.001022  [ 6464/ 7049]\n",
      "At step count 9758\n",
      "Test Error: \n",
      " Avg loss: 0.000560 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "Loss: 0.000427  [   64/ 7049]\n",
      "At step count 9769\n",
      "Loss: 0.000652  [ 6464/ 7049]\n",
      "At step count 9869\n",
      "Test Error: \n",
      " Avg loss: 0.000557 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "Loss: 0.001257  [   64/ 7049]\n",
      "At step count 9880\n",
      "Loss: 0.000718  [ 6464/ 7049]\n",
      "At step count 9980\n",
      "Test Error: \n",
      " Avg loss: 0.000545 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "Loss: 0.000490  [   64/ 7049]\n",
      "At step count 9991\n",
      "Loss: 0.000515  [ 6464/ 7049]\n",
      "At step count 10091\n",
      "Test Error: \n",
      " Avg loss: 0.000479 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "Loss: 0.000397  [   64/ 7049]\n",
      "At step count 10102\n",
      "Loss: 0.000551  [ 6464/ 7049]\n",
      "At step count 10202\n",
      "Test Error: \n",
      " Avg loss: 0.000541 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "Loss: 0.000563  [   64/ 7049]\n",
      "At step count 10213\n",
      "Loss: 0.000621  [ 6464/ 7049]\n",
      "At step count 10313\n",
      "Test Error: \n",
      " Avg loss: 0.000550 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "Loss: 0.000373  [   64/ 7049]\n",
      "At step count 10324\n",
      "Loss: 0.000736  [ 6464/ 7049]\n",
      "At step count 10424\n",
      "Test Error: \n",
      " Avg loss: 0.000448 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "Loss: 0.000312  [   64/ 7049]\n",
      "At step count 10435\n",
      "Loss: 0.000374  [ 6464/ 7049]\n",
      "At step count 10535\n",
      "Test Error: \n",
      " Avg loss: 0.000608 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "Loss: 0.000593  [   64/ 7049]\n",
      "At step count 10546\n",
      "Loss: 0.000423  [ 6464/ 7049]\n",
      "At step count 10646\n",
      "Test Error: \n",
      " Avg loss: 0.000524 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "Loss: 0.000432  [   64/ 7049]\n",
      "At step count 10657\n",
      "Loss: 0.000353  [ 6464/ 7049]\n",
      "At step count 10757\n",
      "Test Error: \n",
      " Avg loss: 0.000660 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "Loss: 0.000283  [   64/ 7049]\n",
      "At step count 10768\n",
      "Loss: 0.000485  [ 6464/ 7049]\n",
      "At step count 10868\n",
      "Test Error: \n",
      " Avg loss: 0.000502 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "Loss: 0.000437  [   64/ 7049]\n",
      "At step count 10879\n",
      "Loss: 0.000510  [ 6464/ 7049]\n",
      "At step count 10979\n",
      "Test Error: \n",
      " Avg loss: 0.000428 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "Loss: 0.000363  [   64/ 7049]\n",
      "At step count 10990\n",
      "Loss: 0.000408  [ 6464/ 7049]\n",
      "At step count 11090\n",
      "Test Error: \n",
      " Avg loss: 0.000521 \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "Loss: 0.000375  [   64/ 7049]\n",
      "At step count 11101\n",
      "Loss: 0.000673  [ 6464/ 7049]\n",
      "At step count 11201\n",
      "Test Error: \n",
      " Avg loss: 0.000596 \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "Loss: 0.000305  [   64/ 7049]\n",
      "At step count 11212\n",
      "Loss: 0.000242  [ 6464/ 7049]\n",
      "At step count 11312\n",
      "Test Error: \n",
      " Avg loss: 0.000572 \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "Loss: 0.000559  [   64/ 7049]\n",
      "At step count 11323\n",
      "Loss: 0.000460  [ 6464/ 7049]\n",
      "At step count 11423\n",
      "Test Error: \n",
      " Avg loss: 0.001059 \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "Loss: 0.000266  [   64/ 7049]\n",
      "At step count 11434\n",
      "Loss: 0.000227  [ 6464/ 7049]\n",
      "At step count 11534\n",
      "Test Error: \n",
      " Avg loss: 0.000337 \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "Loss: 0.000201  [   64/ 7049]\n",
      "At step count 11545\n",
      "Loss: 0.000351  [ 6464/ 7049]\n",
      "At step count 11645\n",
      "Test Error: \n",
      " Avg loss: 0.000654 \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "Loss: 0.000221  [   64/ 7049]\n",
      "At step count 11656\n",
      "Loss: 0.000255  [ 6464/ 7049]\n",
      "At step count 11756\n",
      "Test Error: \n",
      " Avg loss: 0.000699 \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "Loss: 0.000341  [   64/ 7049]\n",
      "At step count 11767\n",
      "Loss: 0.000268  [ 6464/ 7049]\n",
      "At step count 11867\n",
      "Test Error: \n",
      " Avg loss: 0.000923 \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "Loss: 0.000245  [   64/ 7049]\n",
      "At step count 11878\n",
      "Loss: 0.000441  [ 6464/ 7049]\n",
      "At step count 11978\n",
      "Test Error: \n",
      " Avg loss: 0.001514 \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "Loss: 0.000287  [   64/ 7049]\n",
      "At step count 11989\n",
      "Loss: 0.000325  [ 6464/ 7049]\n",
      "At step count 12089\n",
      "Test Error: \n",
      " Avg loss: 0.001478 \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "Loss: 0.000258  [   64/ 7049]\n",
      "At step count 12100\n",
      "Loss: 0.000439  [ 6464/ 7049]\n",
      "At step count 12200\n",
      "Test Error: \n",
      " Avg loss: 0.001662 \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "Loss: 0.000371  [   64/ 7049]\n",
      "At step count 12211\n",
      "Loss: 0.000460  [ 6464/ 7049]\n",
      "At step count 12311\n",
      "Test Error: \n",
      " Avg loss: 0.001126 \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "Loss: 0.000331  [   64/ 7049]\n",
      "At step count 12322\n",
      "Loss: 0.000238  [ 6464/ 7049]\n",
      "At step count 12422\n",
      "Test Error: \n",
      " Avg loss: 0.001343 \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "Loss: 0.000427  [   64/ 7049]\n",
      "At step count 12433\n",
      "Loss: 0.000327  [ 6464/ 7049]\n",
      "At step count 12533\n",
      "Test Error: \n",
      " Avg loss: 0.001111 \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "Loss: 0.000386  [   64/ 7049]\n",
      "At step count 12544\n",
      "Loss: 0.000208  [ 6464/ 7049]\n",
      "At step count 12644\n",
      "Test Error: \n",
      " Avg loss: 0.000949 \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "Loss: 0.000278  [   64/ 7049]\n",
      "At step count 12655\n",
      "Loss: 0.000265  [ 6464/ 7049]\n",
      "At step count 12755\n",
      "Test Error: \n",
      " Avg loss: 0.001010 \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "Loss: 0.000344  [   64/ 7049]\n",
      "At step count 12766\n",
      "Loss: 0.000541  [ 6464/ 7049]\n",
      "At step count 12866\n",
      "Test Error: \n",
      " Avg loss: 0.000779 \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "Loss: 0.000329  [   64/ 7049]\n",
      "At step count 12877\n",
      "Loss: 0.000283  [ 6464/ 7049]\n",
      "At step count 12977\n",
      "Test Error: \n",
      " Avg loss: 0.000856 \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "Loss: 0.000422  [   64/ 7049]\n",
      "At step count 12988\n",
      "Loss: 0.000186  [ 6464/ 7049]\n",
      "At step count 13088\n",
      "Test Error: \n",
      " Avg loss: 0.001074 \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "Loss: 0.000531  [   64/ 7049]\n",
      "At step count 13099\n",
      "Loss: 0.000298  [ 6464/ 7049]\n",
      "At step count 13199\n",
      "Test Error: \n",
      " Avg loss: 0.002231 \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "Loss: 0.000243  [   64/ 7049]\n",
      "At step count 13210\n",
      "Loss: 0.000223  [ 6464/ 7049]\n",
      "At step count 13310\n",
      "Test Error: \n",
      " Avg loss: 0.001336 \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "Loss: 0.000243  [   64/ 7049]\n",
      "At step count 13321\n",
      "Loss: 0.000201  [ 6464/ 7049]\n",
      "At step count 13421\n",
      "Test Error: \n",
      " Avg loss: 0.000956 \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "Loss: 0.000499  [   64/ 7049]\n",
      "At step count 13432\n",
      "Loss: 0.000416  [ 6464/ 7049]\n",
      "At step count 13532\n",
      "Test Error: \n",
      " Avg loss: 0.000656 \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "Loss: 0.000158  [   64/ 7049]\n",
      "At step count 13543\n",
      "Loss: 0.000203  [ 6464/ 7049]\n",
      "At step count 13643\n",
      "Test Error: \n",
      " Avg loss: 0.000639 \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "Loss: 0.000244  [   64/ 7049]\n",
      "At step count 13654\n",
      "Loss: 0.000237  [ 6464/ 7049]\n",
      "At step count 13754\n",
      "Test Error: \n",
      " Avg loss: 0.001196 \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "Loss: 0.000239  [   64/ 7049]\n",
      "At step count 13765\n",
      "Loss: 0.000241  [ 6464/ 7049]\n",
      "At step count 13865\n",
      "Test Error: \n",
      " Avg loss: 0.001005 \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "Loss: 0.000317  [   64/ 7049]\n",
      "At step count 13876\n",
      "Loss: 0.000215  [ 6464/ 7049]\n",
      "At step count 13976\n",
      "Test Error: \n",
      " Avg loss: 0.000508 \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "Loss: 0.000274  [   64/ 7049]\n",
      "At step count 13987\n",
      "Loss: 0.000378  [ 6464/ 7049]\n",
      "At step count 14087\n",
      "Test Error: \n",
      " Avg loss: 0.000558 \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "Loss: 0.000214  [   64/ 7049]\n",
      "At step count 14098\n",
      "Loss: 0.000211  [ 6464/ 7049]\n",
      "At step count 14198\n",
      "Test Error: \n",
      " Avg loss: 0.001562 \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "Loss: 0.000213  [   64/ 7049]\n",
      "At step count 14209\n",
      "Loss: 0.000719  [ 6464/ 7049]\n",
      "At step count 14309\n",
      "Test Error: \n",
      " Avg loss: 0.001354 \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "Loss: 0.000214  [   64/ 7049]\n",
      "At step count 14320\n",
      "Loss: 0.000568  [ 6464/ 7049]\n",
      "At step count 14420\n",
      "Test Error: \n",
      " Avg loss: 0.001031 \n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "Loss: 0.001254  [   64/ 7049]\n",
      "At step count 14431\n",
      "Loss: 0.000228  [ 6464/ 7049]\n",
      "At step count 14531\n",
      "Test Error: \n",
      " Avg loss: 0.001038 \n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "Loss: 0.000273  [   64/ 7049]\n",
      "At step count 14542\n",
      "Loss: 0.000233  [ 6464/ 7049]\n",
      "At step count 14642\n",
      "Test Error: \n",
      " Avg loss: 0.000830 \n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "Loss: 0.000297  [   64/ 7049]\n",
      "At step count 14653\n",
      "Loss: 0.000375  [ 6464/ 7049]\n",
      "At step count 14753\n",
      "Test Error: \n",
      " Avg loss: 0.000806 \n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "Loss: 0.000375  [   64/ 7049]\n",
      "At step count 14764\n",
      "Loss: 0.000259  [ 6464/ 7049]\n",
      "At step count 14864\n",
      "Test Error: \n",
      " Avg loss: 0.000690 \n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "Loss: 0.000250  [   64/ 7049]\n",
      "At step count 14875\n",
      "Loss: 0.000194  [ 6464/ 7049]\n",
      "At step count 14975\n",
      "Test Error: \n",
      " Avg loss: 0.000723 \n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "Loss: 0.000153  [   64/ 7049]\n",
      "At step count 14986\n",
      "Loss: 0.000421  [ 6464/ 7049]\n",
      "At step count 15086\n",
      "Test Error: \n",
      " Avg loss: 0.000952 \n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "Loss: 0.000233  [   64/ 7049]\n",
      "At step count 15097\n",
      "Loss: 0.001152  [ 6464/ 7049]\n",
      "At step count 15197\n",
      "Test Error: \n",
      " Avg loss: 0.001183 \n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "Loss: 0.000136  [   64/ 7049]\n",
      "At step count 15208\n",
      "Loss: 0.000252  [ 6464/ 7049]\n",
      "At step count 15308\n",
      "Test Error: \n",
      " Avg loss: 0.001168 \n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "Loss: 0.000257  [   64/ 7049]\n",
      "At step count 15319\n",
      "Loss: 0.000161  [ 6464/ 7049]\n",
      "At step count 15419\n",
      "Test Error: \n",
      " Avg loss: 0.001359 \n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "Loss: 0.000130  [   64/ 7049]\n",
      "At step count 15430\n",
      "Loss: 0.000269  [ 6464/ 7049]\n",
      "At step count 15530\n",
      "Test Error: \n",
      " Avg loss: 0.000603 \n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "Loss: 0.000462  [   64/ 7049]\n",
      "At step count 15541\n",
      "Loss: 0.000721  [ 6464/ 7049]\n",
      "At step count 15641\n",
      "Test Error: \n",
      " Avg loss: 0.001051 \n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "Loss: 0.000286  [   64/ 7049]\n",
      "At step count 15652\n",
      "Loss: 0.000179  [ 6464/ 7049]\n",
      "At step count 15752\n",
      "Test Error: \n",
      " Avg loss: 0.001753 \n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "Loss: 0.000332  [   64/ 7049]\n",
      "At step count 15763\n",
      "Loss: 0.000203  [ 6464/ 7049]\n",
      "At step count 15863\n",
      "Test Error: \n",
      " Avg loss: 0.000854 \n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "Loss: 0.000184  [   64/ 7049]\n",
      "At step count 15874\n",
      "Loss: 0.000206  [ 6464/ 7049]\n",
      "At step count 15974\n",
      "Test Error: \n",
      " Avg loss: 0.000525 \n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "Loss: 0.000156  [   64/ 7049]\n",
      "At step count 15985\n",
      "Loss: 0.000172  [ 6464/ 7049]\n",
      "At step count 16085\n",
      "Test Error: \n",
      " Avg loss: 0.000867 \n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "Loss: 0.000166  [   64/ 7049]\n",
      "At step count 16096\n",
      "Loss: 0.000165  [ 6464/ 7049]\n",
      "At step count 16196\n",
      "Test Error: \n",
      " Avg loss: 0.001213 \n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "Loss: 0.000121  [   64/ 7049]\n",
      "At step count 16207\n",
      "Loss: 0.000152  [ 6464/ 7049]\n",
      "At step count 16307\n",
      "Test Error: \n",
      " Avg loss: 0.000817 \n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "Loss: 0.000106  [   64/ 7049]\n",
      "At step count 16318\n",
      "Loss: 0.000151  [ 6464/ 7049]\n",
      "At step count 16418\n",
      "Test Error: \n",
      " Avg loss: 0.001296 \n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "Loss: 0.000147  [   64/ 7049]\n",
      "At step count 16429\n",
      "Loss: 0.000140  [ 6464/ 7049]\n",
      "At step count 16529\n",
      "Test Error: \n",
      " Avg loss: 0.000874 \n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "Loss: 0.000157  [   64/ 7049]\n",
      "At step count 16540\n",
      "Loss: 0.000139  [ 6464/ 7049]\n",
      "At step count 16640\n",
      "Test Error: \n",
      " Avg loss: 0.001709 \n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "Loss: 0.000158  [   64/ 7049]\n",
      "At step count 16651\n",
      "Loss: 0.000173  [ 6464/ 7049]\n",
      "At step count 16751\n",
      "Test Error: \n",
      " Avg loss: 0.000891 \n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "Loss: 0.000161  [   64/ 7049]\n",
      "At step count 16762\n",
      "Loss: 0.000184  [ 6464/ 7049]\n",
      "At step count 16862\n",
      "Test Error: \n",
      " Avg loss: 0.001005 \n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "Loss: 0.001430  [   64/ 7049]\n",
      "At step count 16873\n",
      "Loss: 0.000158  [ 6464/ 7049]\n",
      "At step count 16973\n",
      "Test Error: \n",
      " Avg loss: 0.001059 \n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "Loss: 0.000252  [   64/ 7049]\n",
      "At step count 16984\n",
      "Loss: 0.000145  [ 6464/ 7049]\n",
      "At step count 17084\n",
      "Test Error: \n",
      " Avg loss: 0.000816 \n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "Loss: 0.000139  [   64/ 7049]\n",
      "At step count 17095\n",
      "Loss: 0.000156  [ 6464/ 7049]\n",
      "At step count 17195\n",
      "Test Error: \n",
      " Avg loss: 0.001875 \n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "Loss: 0.000758  [   64/ 7049]\n",
      "At step count 17206\n",
      "Loss: 0.000201  [ 6464/ 7049]\n",
      "At step count 17306\n",
      "Test Error: \n",
      " Avg loss: 0.002278 \n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "Loss: 0.000215  [   64/ 7049]\n",
      "At step count 17317\n",
      "Loss: 0.000172  [ 6464/ 7049]\n",
      "At step count 17417\n",
      "Test Error: \n",
      " Avg loss: 0.001435 \n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "Loss: 0.000169  [   64/ 7049]\n",
      "At step count 17428\n",
      "Loss: 0.000119  [ 6464/ 7049]\n",
      "At step count 17528\n",
      "Test Error: \n",
      " Avg loss: 0.001444 \n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "Loss: 0.000130  [   64/ 7049]\n",
      "At step count 17539\n",
      "Loss: 0.000472  [ 6464/ 7049]\n",
      "At step count 17639\n",
      "Test Error: \n",
      " Avg loss: 0.000997 \n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "Loss: 0.000265  [   64/ 7049]\n",
      "At step count 17650\n",
      "Loss: 0.000215  [ 6464/ 7049]\n",
      "At step count 17750\n",
      "Test Error: \n",
      " Avg loss: 0.002008 \n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "Loss: 0.000194  [   64/ 7049]\n",
      "At step count 17761\n",
      "Loss: 0.000280  [ 6464/ 7049]\n",
      "At step count 17861\n",
      "Test Error: \n",
      " Avg loss: 0.001426 \n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "Loss: 0.000436  [   64/ 7049]\n",
      "At step count 17872\n",
      "Loss: 0.000206  [ 6464/ 7049]\n",
      "At step count 17972\n",
      "Test Error: \n",
      " Avg loss: 0.001341 \n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "Loss: 0.000446  [   64/ 7049]\n",
      "At step count 17983\n",
      "Loss: 0.000175  [ 6464/ 7049]\n",
      "At step count 18083\n",
      "Test Error: \n",
      " Avg loss: 0.001413 \n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "Loss: 0.000229  [   64/ 7049]\n",
      "At step count 18094\n",
      "Loss: 0.000148  [ 6464/ 7049]\n",
      "At step count 18194\n",
      "Test Error: \n",
      " Avg loss: 0.001311 \n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "Loss: 0.000166  [   64/ 7049]\n",
      "At step count 18205\n",
      "Loss: 0.000131  [ 6464/ 7049]\n",
      "At step count 18305\n",
      "Test Error: \n",
      " Avg loss: 0.001046 \n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "Loss: 0.000211  [   64/ 7049]\n",
      "At step count 18316\n",
      "Loss: 0.000163  [ 6464/ 7049]\n",
      "At step count 18416\n",
      "Test Error: \n",
      " Avg loss: 0.001044 \n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "Loss: 0.000134  [   64/ 7049]\n",
      "At step count 18427\n",
      "Loss: 0.000275  [ 6464/ 7049]\n",
      "At step count 18527\n",
      "Test Error: \n",
      " Avg loss: 0.001218 \n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "Loss: 0.000119  [   64/ 7049]\n",
      "At step count 18538\n",
      "Loss: 0.000123  [ 6464/ 7049]\n",
      "At step count 18638\n",
      "Test Error: \n",
      " Avg loss: 0.000668 \n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "Loss: 0.000141  [   64/ 7049]\n",
      "At step count 18649\n",
      "Loss: 0.000143  [ 6464/ 7049]\n",
      "At step count 18749\n",
      "Test Error: \n",
      " Avg loss: 0.002036 \n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "Loss: 0.000174  [   64/ 7049]\n",
      "At step count 18760\n",
      "Loss: 0.000110  [ 6464/ 7049]\n",
      "At step count 18860\n",
      "Test Error: \n",
      " Avg loss: 0.000676 \n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "Loss: 0.000547  [   64/ 7049]\n",
      "At step count 18871\n",
      "Loss: 0.000128  [ 6464/ 7049]\n",
      "At step count 18971\n",
      "Test Error: \n",
      " Avg loss: 0.000641 \n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "Loss: 0.000241  [   64/ 7049]\n",
      "At step count 18982\n",
      "Loss: 0.000131  [ 6464/ 7049]\n",
      "At step count 19082\n",
      "Test Error: \n",
      " Avg loss: 0.001193 \n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "Loss: 0.000127  [   64/ 7049]\n",
      "At step count 19093\n",
      "Loss: 0.000115  [ 6464/ 7049]\n",
      "At step count 19193\n",
      "Test Error: \n",
      " Avg loss: 0.001345 \n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "Loss: 0.000197  [   64/ 7049]\n",
      "At step count 19204\n",
      "Loss: 0.000181  [ 6464/ 7049]\n",
      "At step count 19304\n",
      "Test Error: \n",
      " Avg loss: 0.001135 \n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "Loss: 0.000116  [   64/ 7049]\n",
      "At step count 19315\n",
      "Loss: 0.000087  [ 6464/ 7049]\n",
      "At step count 19415\n",
      "Test Error: \n",
      " Avg loss: 0.001166 \n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "Loss: 0.000114  [   64/ 7049]\n",
      "At step count 19426\n",
      "Loss: 0.000118  [ 6464/ 7049]\n",
      "At step count 19526\n",
      "Test Error: \n",
      " Avg loss: 0.001083 \n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "Loss: 0.000091  [   64/ 7049]\n",
      "At step count 19537\n",
      "Loss: 0.000323  [ 6464/ 7049]\n",
      "At step count 19637\n",
      "Test Error: \n",
      " Avg loss: 0.000948 \n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "Loss: 0.000135  [   64/ 7049]\n",
      "At step count 19648\n",
      "Loss: 0.000166  [ 6464/ 7049]\n",
      "At step count 19748\n",
      "Test Error: \n",
      " Avg loss: 0.001117 \n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "Loss: 0.000182  [   64/ 7049]\n",
      "At step count 19759\n",
      "Loss: 0.000173  [ 6464/ 7049]\n",
      "At step count 19859\n",
      "Test Error: \n",
      " Avg loss: 0.002692 \n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "Loss: 0.000171  [   64/ 7049]\n",
      "At step count 19870\n",
      "Loss: 0.000249  [ 6464/ 7049]\n",
      "At step count 19970\n",
      "Test Error: \n",
      " Avg loss: 0.000965 \n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "Loss: 0.000117  [   64/ 7049]\n",
      "At step count 19981\n",
      "Loss: 0.000206  [ 6464/ 7049]\n",
      "At step count 20081\n",
      "Test Error: \n",
      " Avg loss: 0.001119 \n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "Loss: 0.000128  [   64/ 7049]\n",
      "At step count 20092\n",
      "Loss: 0.000104  [ 6464/ 7049]\n",
      "At step count 20192\n",
      "Test Error: \n",
      " Avg loss: 0.000861 \n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "Loss: 0.000284  [   64/ 7049]\n",
      "At step count 20203\n",
      "Loss: 0.000430  [ 6464/ 7049]\n",
      "At step count 20303\n",
      "Test Error: \n",
      " Avg loss: 0.001002 \n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "Loss: 0.000188  [   64/ 7049]\n",
      "At step count 20314\n",
      "Loss: 0.000082  [ 6464/ 7049]\n",
      "At step count 20414\n",
      "Test Error: \n",
      " Avg loss: 0.000584 \n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "Loss: 0.000109  [   64/ 7049]\n",
      "At step count 20425\n",
      "Loss: 0.000116  [ 6464/ 7049]\n",
      "At step count 20525\n",
      "Test Error: \n",
      " Avg loss: 0.000721 \n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "Loss: 0.000164  [   64/ 7049]\n",
      "At step count 20536\n",
      "Loss: 0.000102  [ 6464/ 7049]\n",
      "At step count 20636\n",
      "Test Error: \n",
      " Avg loss: 0.000428 \n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "Loss: 0.000116  [   64/ 7049]\n",
      "At step count 20647\n",
      "Loss: 0.000263  [ 6464/ 7049]\n",
      "At step count 20747\n",
      "Test Error: \n",
      " Avg loss: 0.000610 \n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "Loss: 0.000696  [   64/ 7049]\n",
      "At step count 20758\n",
      "Loss: 0.000125  [ 6464/ 7049]\n",
      "At step count 20858\n",
      "Test Error: \n",
      " Avg loss: 0.000793 \n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "Loss: 0.000182  [   64/ 7049]\n",
      "At step count 20869\n",
      "Loss: 0.000097  [ 6464/ 7049]\n",
      "At step count 20969\n",
      "Test Error: \n",
      " Avg loss: 0.000623 \n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "Loss: 0.000177  [   64/ 7049]\n",
      "At step count 20980\n",
      "Loss: 0.000107  [ 6464/ 7049]\n",
      "At step count 21080\n",
      "Test Error: \n",
      " Avg loss: 0.001095 \n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "Loss: 0.000106  [   64/ 7049]\n",
      "At step count 21091\n",
      "Loss: 0.000688  [ 6464/ 7049]\n",
      "At step count 21191\n",
      "Test Error: \n",
      " Avg loss: 0.000937 \n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "Loss: 0.000133  [   64/ 7049]\n",
      "At step count 21202\n",
      "Loss: 0.001351  [ 6464/ 7049]\n",
      "At step count 21302\n",
      "Test Error: \n",
      " Avg loss: 0.000787 \n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "Loss: 0.000103  [   64/ 7049]\n",
      "At step count 21313\n",
      "Loss: 0.000298  [ 6464/ 7049]\n",
      "At step count 21413\n",
      "Test Error: \n",
      " Avg loss: 0.001295 \n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "Loss: 0.000118  [   64/ 7049]\n",
      "At step count 21424\n",
      "Loss: 0.000264  [ 6464/ 7049]\n",
      "At step count 21524\n",
      "Test Error: \n",
      " Avg loss: 0.001519 \n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "Loss: 0.000461  [   64/ 7049]\n",
      "At step count 21535\n",
      "Loss: 0.000113  [ 6464/ 7049]\n",
      "At step count 21635\n",
      "Test Error: \n",
      " Avg loss: 0.001090 \n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "Loss: 0.000460  [   64/ 7049]\n",
      "At step count 21646\n",
      "Loss: 0.000127  [ 6464/ 7049]\n",
      "At step count 21746\n",
      "Test Error: \n",
      " Avg loss: 0.001556 \n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "Loss: 0.001161  [   64/ 7049]\n",
      "At step count 21757\n",
      "Loss: 0.000092  [ 6464/ 7049]\n",
      "At step count 21857\n",
      "Test Error: \n",
      " Avg loss: 0.001060 \n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "Loss: 0.000170  [   64/ 7049]\n",
      "At step count 21868\n",
      "Loss: 0.000235  [ 6464/ 7049]\n",
      "At step count 21968\n",
      "Test Error: \n",
      " Avg loss: 0.000460 \n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "Loss: 0.000138  [   64/ 7049]\n",
      "At step count 21979\n",
      "Loss: 0.000184  [ 6464/ 7049]\n",
      "At step count 22079\n",
      "Test Error: \n",
      " Avg loss: 0.000916 \n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "Loss: 0.000150  [   64/ 7049]\n",
      "At step count 22090\n",
      "Loss: 0.000097  [ 6464/ 7049]\n",
      "At step count 22190\n",
      "Test Error: \n",
      " Avg loss: 0.001482 \n",
      "\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "Loss: 0.000156  [   64/ 7049]\n",
      "At step count 22201\n",
      "Loss: 0.000728  [ 6464/ 7049]\n",
      "At step count 22301\n",
      "Test Error: \n",
      " Avg loss: 0.000665 \n",
      "\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "Loss: 0.000789  [   64/ 7049]\n",
      "At step count 22312\n",
      "Loss: 0.000095  [ 6464/ 7049]\n",
      "At step count 22412\n",
      "Test Error: \n",
      " Avg loss: 0.000947 \n",
      "\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "Loss: 0.000110  [   64/ 7049]\n",
      "At step count 22423\n",
      "Loss: 0.000121  [ 6464/ 7049]\n",
      "At step count 22523\n",
      "Test Error: \n",
      " Avg loss: 0.001135 \n",
      "\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "Loss: 0.000098  [   64/ 7049]\n",
      "At step count 22534\n",
      "Loss: 0.000134  [ 6464/ 7049]\n",
      "At step count 22634\n",
      "Test Error: \n",
      " Avg loss: 0.000994 \n",
      "\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "Loss: 0.000200  [   64/ 7049]\n",
      "At step count 22645\n",
      "Loss: 0.000128  [ 6464/ 7049]\n",
      "At step count 22745\n",
      "Test Error: \n",
      " Avg loss: 0.000608 \n",
      "\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "Loss: 0.000122  [   64/ 7049]\n",
      "At step count 22756\n",
      "Loss: 0.000100  [ 6464/ 7049]\n",
      "At step count 22856\n",
      "Test Error: \n",
      " Avg loss: 0.001285 \n",
      "\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "Loss: 0.000098  [   64/ 7049]\n",
      "At step count 22867\n",
      "Loss: 0.000101  [ 6464/ 7049]\n",
      "At step count 22967\n",
      "Test Error: \n",
      " Avg loss: 0.001331 \n",
      "\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "Loss: 0.000546  [   64/ 7049]\n",
      "At step count 22978\n",
      "Loss: 0.000376  [ 6464/ 7049]\n",
      "At step count 23078\n",
      "Test Error: \n",
      " Avg loss: 0.001088 \n",
      "\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "Loss: 0.000111  [   64/ 7049]\n",
      "At step count 23089\n",
      "Loss: 0.000707  [ 6464/ 7049]\n",
      "At step count 23189\n",
      "Test Error: \n",
      " Avg loss: 0.001386 \n",
      "\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "Loss: 0.000182  [   64/ 7049]\n",
      "At step count 23200\n",
      "Loss: 0.000145  [ 6464/ 7049]\n",
      "At step count 23300\n",
      "Test Error: \n",
      " Avg loss: 0.000693 \n",
      "\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "Loss: 0.000100  [   64/ 7049]\n",
      "At step count 23311\n",
      "Loss: 0.001054  [ 6464/ 7049]\n",
      "At step count 23411\n",
      "Test Error: \n",
      " Avg loss: 0.001081 \n",
      "\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "Loss: 0.000088  [   64/ 7049]\n",
      "At step count 23422\n",
      "Loss: 0.000329  [ 6464/ 7049]\n",
      "At step count 23522\n",
      "Test Error: \n",
      " Avg loss: 0.000847 \n",
      "\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "Loss: 0.000959  [   64/ 7049]\n",
      "At step count 23533\n",
      "Loss: 0.000811  [ 6464/ 7049]\n",
      "At step count 23633\n",
      "Test Error: \n",
      " Avg loss: 0.000854 \n",
      "\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "Loss: 0.000099  [   64/ 7049]\n",
      "At step count 23644\n",
      "Loss: 0.000077  [ 6464/ 7049]\n",
      "At step count 23744\n",
      "Test Error: \n",
      " Avg loss: 0.000929 \n",
      "\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "Loss: 0.000114  [   64/ 7049]\n",
      "At step count 23755\n",
      "Loss: 0.000091  [ 6464/ 7049]\n",
      "At step count 23855\n",
      "Test Error: \n",
      " Avg loss: 0.000578 \n",
      "\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "Loss: 0.000102  [   64/ 7049]\n",
      "At step count 23866\n",
      "Loss: 0.000451  [ 6464/ 7049]\n",
      "At step count 23966\n",
      "Test Error: \n",
      " Avg loss: 0.001320 \n",
      "\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "Loss: 0.000071  [   64/ 7049]\n",
      "At step count 23977\n",
      "Loss: 0.000072  [ 6464/ 7049]\n",
      "At step count 24077\n",
      "Test Error: \n",
      " Avg loss: 0.002012 \n",
      "\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "Loss: 0.000072  [   64/ 7049]\n",
      "At step count 24088\n",
      "Loss: 0.000124  [ 6464/ 7049]\n",
      "At step count 24188\n",
      "Test Error: \n",
      " Avg loss: 0.000670 \n",
      "\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "Loss: 0.000109  [   64/ 7049]\n",
      "At step count 24199\n",
      "Loss: 0.000134  [ 6464/ 7049]\n",
      "At step count 24299\n",
      "Test Error: \n",
      " Avg loss: 0.001107 \n",
      "\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "Loss: 0.000108  [   64/ 7049]\n",
      "At step count 24310\n",
      "Loss: 0.000104  [ 6464/ 7049]\n",
      "At step count 24410\n",
      "Test Error: \n",
      " Avg loss: 0.001086 \n",
      "\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "Loss: 0.000147  [   64/ 7049]\n",
      "At step count 24421\n",
      "Loss: 0.000079  [ 6464/ 7049]\n",
      "At step count 24521\n",
      "Test Error: \n",
      " Avg loss: 0.001131 \n",
      "\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "Loss: 0.000105  [   64/ 7049]\n",
      "At step count 24532\n",
      "Loss: 0.000138  [ 6464/ 7049]\n",
      "At step count 24632\n",
      "Test Error: \n",
      " Avg loss: 0.001436 \n",
      "\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "Loss: 0.000080  [   64/ 7049]\n",
      "At step count 24643\n",
      "Loss: 0.000229  [ 6464/ 7049]\n",
      "At step count 24743\n",
      "Test Error: \n",
      " Avg loss: 0.000858 \n",
      "\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "Loss: 0.000087  [   64/ 7049]\n",
      "At step count 24754\n",
      "Loss: 0.000088  [ 6464/ 7049]\n",
      "At step count 24854\n",
      "Test Error: \n",
      " Avg loss: 0.000812 \n",
      "\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "Loss: 0.000128  [   64/ 7049]\n",
      "At step count 24865\n",
      "Loss: 0.000087  [ 6464/ 7049]\n",
      "At step count 24965\n",
      "Test Error: \n",
      " Avg loss: 0.001163 \n",
      "\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "Loss: 0.000103  [   64/ 7049]\n",
      "At step count 24976\n",
      "Loss: 0.000124  [ 6464/ 7049]\n",
      "At step count 25076\n",
      "Test Error: \n",
      " Avg loss: 0.001517 \n",
      "\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "Loss: 0.000097  [   64/ 7049]\n",
      "At step count 25087\n",
      "Loss: 0.000108  [ 6464/ 7049]\n",
      "At step count 25187\n",
      "Test Error: \n",
      " Avg loss: 0.000998 \n",
      "\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "Loss: 0.000142  [   64/ 7049]\n",
      "At step count 25198\n",
      "Loss: 0.000192  [ 6464/ 7049]\n",
      "At step count 25298\n",
      "Test Error: \n",
      " Avg loss: 0.001236 \n",
      "\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "Loss: 0.000130  [   64/ 7049]\n",
      "At step count 25309\n",
      "Loss: 0.000093  [ 6464/ 7049]\n",
      "At step count 25409\n",
      "Test Error: \n",
      " Avg loss: 0.001119 \n",
      "\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "Loss: 0.000251  [   64/ 7049]\n",
      "At step count 25420\n",
      "Loss: 0.000133  [ 6464/ 7049]\n",
      "At step count 25520\n",
      "Test Error: \n",
      " Avg loss: 0.000526 \n",
      "\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "Loss: 0.000105  [   64/ 7049]\n",
      "At step count 25531\n",
      "Loss: 0.000152  [ 6464/ 7049]\n",
      "At step count 25631\n",
      "Test Error: \n",
      " Avg loss: 0.000675 \n",
      "\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "Loss: 0.000097  [   64/ 7049]\n",
      "At step count 25642\n",
      "Loss: 0.000114  [ 6464/ 7049]\n",
      "At step count 25742\n",
      "Test Error: \n",
      " Avg loss: 0.000849 \n",
      "\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "Loss: 0.000062  [   64/ 7049]\n",
      "At step count 25753\n",
      "Loss: 0.000146  [ 6464/ 7049]\n",
      "At step count 25853\n",
      "Test Error: \n",
      " Avg loss: 0.000984 \n",
      "\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "Loss: 0.000112  [   64/ 7049]\n",
      "At step count 25864\n",
      "Loss: 0.000127  [ 6464/ 7049]\n",
      "At step count 25964\n",
      "Test Error: \n",
      " Avg loss: 0.001719 \n",
      "\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "Loss: 0.000094  [   64/ 7049]\n",
      "At step count 25975\n",
      "Loss: 0.000338  [ 6464/ 7049]\n",
      "At step count 26075\n",
      "Test Error: \n",
      " Avg loss: 0.000954 \n",
      "\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "Loss: 0.000194  [   64/ 7049]\n",
      "At step count 26086\n",
      "Loss: 0.000784  [ 6464/ 7049]\n",
      "At step count 26186\n",
      "Test Error: \n",
      " Avg loss: 0.001210 \n",
      "\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "Loss: 0.000131  [   64/ 7049]\n",
      "At step count 26197\n",
      "Loss: 0.000240  [ 6464/ 7049]\n",
      "At step count 26297\n",
      "Test Error: \n",
      " Avg loss: 0.000951 \n",
      "\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "Loss: 0.000169  [   64/ 7049]\n",
      "At step count 26308\n",
      "Loss: 0.000120  [ 6464/ 7049]\n",
      "At step count 26408\n",
      "Test Error: \n",
      " Avg loss: 0.002087 \n",
      "\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "Loss: 0.000112  [   64/ 7049]\n",
      "At step count 26419\n",
      "Loss: 0.000100  [ 6464/ 7049]\n",
      "At step count 26519\n",
      "Test Error: \n",
      " Avg loss: 0.001373 \n",
      "\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "Loss: 0.000310  [   64/ 7049]\n",
      "At step count 26530\n",
      "Loss: 0.000108  [ 6464/ 7049]\n",
      "At step count 26630\n",
      "Test Error: \n",
      " Avg loss: 0.000698 \n",
      "\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "Loss: 0.000110  [   64/ 7049]\n",
      "At step count 26641\n",
      "Loss: 0.000194  [ 6464/ 7049]\n",
      "At step count 26741\n",
      "Test Error: \n",
      " Avg loss: 0.001895 \n",
      "\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "Loss: 0.000117  [   64/ 7049]\n",
      "At step count 26752\n",
      "Loss: 0.000219  [ 6464/ 7049]\n",
      "At step count 26852\n",
      "Test Error: \n",
      " Avg loss: 0.001642 \n",
      "\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "Loss: 0.000272  [   64/ 7049]\n",
      "At step count 26863\n",
      "Loss: 0.000121  [ 6464/ 7049]\n",
      "At step count 26963\n",
      "Test Error: \n",
      " Avg loss: 0.002089 \n",
      "\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "Loss: 0.000099  [   64/ 7049]\n",
      "At step count 26974\n",
      "Loss: 0.000105  [ 6464/ 7049]\n",
      "At step count 27074\n",
      "Test Error: \n",
      " Avg loss: 0.001786 \n",
      "\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "Loss: 0.000131  [   64/ 7049]\n",
      "At step count 27085\n",
      "Loss: 0.000153  [ 6464/ 7049]\n",
      "At step count 27185\n",
      "Test Error: \n",
      " Avg loss: 0.001124 \n",
      "\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "Loss: 0.000119  [   64/ 7049]\n",
      "At step count 27196\n",
      "Loss: 0.000080  [ 6464/ 7049]\n",
      "At step count 27296\n",
      "Test Error: \n",
      " Avg loss: 0.000996 \n",
      "\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "Loss: 0.000075  [   64/ 7049]\n",
      "At step count 27307\n",
      "Loss: 0.000077  [ 6464/ 7049]\n",
      "At step count 27407\n",
      "Test Error: \n",
      " Avg loss: 0.000978 \n",
      "\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "Loss: 0.000215  [   64/ 7049]\n",
      "At step count 27418\n",
      "Loss: 0.000101  [ 6464/ 7049]\n",
      "At step count 27518\n",
      "Test Error: \n",
      " Avg loss: 0.001066 \n",
      "\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "Loss: 0.000359  [   64/ 7049]\n",
      "At step count 27529\n",
      "Loss: 0.000267  [ 6464/ 7049]\n",
      "At step count 27629\n",
      "Test Error: \n",
      " Avg loss: 0.001002 \n",
      "\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "Loss: 0.000116  [   64/ 7049]\n",
      "At step count 27640\n",
      "Loss: 0.000208  [ 6464/ 7049]\n",
      "At step count 27740\n",
      "Test Error: \n",
      " Avg loss: 0.000975 \n",
      "\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "Loss: 0.000208  [   64/ 7049]\n",
      "At step count 27751\n",
      "Loss: 0.000092  [ 6464/ 7049]\n",
      "At step count 27851\n",
      "Test Error: \n",
      " Avg loss: 0.001067 \n",
      "\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "Loss: 0.000155  [   64/ 7049]\n",
      "At step count 27862\n",
      "Loss: 0.000136  [ 6464/ 7049]\n",
      "At step count 27962\n",
      "Test Error: \n",
      " Avg loss: 0.000919 \n",
      "\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "Loss: 0.000110  [   64/ 7049]\n",
      "At step count 27973\n",
      "Loss: 0.000133  [ 6464/ 7049]\n",
      "At step count 28073\n",
      "Test Error: \n",
      " Avg loss: 0.000944 \n",
      "\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "Loss: 0.000155  [   64/ 7049]\n",
      "At step count 28084\n",
      "Loss: 0.000195  [ 6464/ 7049]\n",
      "At step count 28184\n",
      "Test Error: \n",
      " Avg loss: 0.001053 \n",
      "\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "Loss: 0.000082  [   64/ 7049]\n",
      "At step count 28195\n",
      "Loss: 0.000111  [ 6464/ 7049]\n",
      "At step count 28295\n",
      "Test Error: \n",
      " Avg loss: 0.001214 \n",
      "\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "Loss: 0.000078  [   64/ 7049]\n",
      "At step count 28306\n",
      "Loss: 0.000198  [ 6464/ 7049]\n",
      "At step count 28406\n",
      "Test Error: \n",
      " Avg loss: 0.000788 \n",
      "\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "Loss: 0.000078  [   64/ 7049]\n",
      "At step count 28417\n",
      "Loss: 0.000112  [ 6464/ 7049]\n",
      "At step count 28517\n",
      "Test Error: \n",
      " Avg loss: 0.000877 \n",
      "\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "Loss: 0.000150  [   64/ 7049]\n",
      "At step count 28528\n",
      "Loss: 0.000082  [ 6464/ 7049]\n",
      "At step count 28628\n",
      "Test Error: \n",
      " Avg loss: 0.001428 \n",
      "\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "Loss: 0.000073  [   64/ 7049]\n",
      "At step count 28639\n",
      "Loss: 0.000093  [ 6464/ 7049]\n",
      "At step count 28739\n",
      "Test Error: \n",
      " Avg loss: 0.001637 \n",
      "\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "Loss: 0.000113  [   64/ 7049]\n",
      "At step count 28750\n",
      "Loss: 0.000112  [ 6464/ 7049]\n",
      "At step count 28850\n",
      "Test Error: \n",
      " Avg loss: 0.001433 \n",
      "\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "Loss: 0.000213  [   64/ 7049]\n",
      "At step count 28861\n",
      "Loss: 0.000096  [ 6464/ 7049]\n",
      "At step count 28961\n",
      "Test Error: \n",
      " Avg loss: 0.000589 \n",
      "\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "Loss: 0.000064  [   64/ 7049]\n",
      "At step count 28972\n",
      "Loss: 0.000082  [ 6464/ 7049]\n",
      "At step count 29072\n",
      "Test Error: \n",
      " Avg loss: 0.001369 \n",
      "\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "Loss: 0.000169  [   64/ 7049]\n",
      "At step count 29083\n",
      "Loss: 0.000066  [ 6464/ 7049]\n",
      "At step count 29183\n",
      "Test Error: \n",
      " Avg loss: 0.000794 \n",
      "\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "Loss: 0.000099  [   64/ 7049]\n",
      "At step count 29194\n",
      "Loss: 0.000087  [ 6464/ 7049]\n",
      "At step count 29294\n",
      "Test Error: \n",
      " Avg loss: 0.001621 \n",
      "\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "Loss: 0.000107  [   64/ 7049]\n",
      "At step count 29305\n",
      "Loss: 0.000092  [ 6464/ 7049]\n",
      "At step count 29405\n",
      "Test Error: \n",
      " Avg loss: 0.000826 \n",
      "\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "Loss: 0.000068  [   64/ 7049]\n",
      "At step count 29416\n",
      "Loss: 0.000092  [ 6464/ 7049]\n",
      "At step count 29516\n",
      "Test Error: \n",
      " Avg loss: 0.000994 \n",
      "\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "Loss: 0.000126  [   64/ 7049]\n",
      "At step count 29527\n",
      "Loss: 0.000060  [ 6464/ 7049]\n",
      "At step count 29627\n",
      "Test Error: \n",
      " Avg loss: 0.000919 \n",
      "\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "Loss: 0.000061  [   64/ 7049]\n",
      "At step count 29638\n",
      "Loss: 0.000130  [ 6464/ 7049]\n",
      "At step count 29738\n",
      "Test Error: \n",
      " Avg loss: 0.000855 \n",
      "\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "Loss: 0.000136  [   64/ 7049]\n",
      "At step count 29749\n",
      "Loss: 0.000105  [ 6464/ 7049]\n",
      "At step count 29849\n",
      "Test Error: \n",
      " Avg loss: 0.000691 \n",
      "\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "Loss: 0.000082  [   64/ 7049]\n",
      "At step count 29860\n",
      "Loss: 0.000088  [ 6464/ 7049]\n",
      "At step count 29960\n",
      "Test Error: \n",
      " Avg loss: 0.000680 \n",
      "\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "Loss: 0.000060  [   64/ 7049]\n",
      "At step count 29971\n",
      "Loss: 0.000104  [ 6464/ 7049]\n",
      "At step count 30071\n",
      "Test Error: \n",
      " Avg loss: 0.000713 \n",
      "\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "Loss: 0.000073  [   64/ 7049]\n",
      "At step count 30082\n",
      "Loss: 0.000074  [ 6464/ 7049]\n",
      "At step count 30182\n",
      "Test Error: \n",
      " Avg loss: 0.001701 \n",
      "\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "Loss: 0.000085  [   64/ 7049]\n",
      "At step count 30193\n",
      "Loss: 0.000115  [ 6464/ 7049]\n",
      "At step count 30293\n",
      "Test Error: \n",
      " Avg loss: 0.001240 \n",
      "\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "Loss: 0.000118  [   64/ 7049]\n",
      "At step count 30304\n",
      "Loss: 0.000067  [ 6464/ 7049]\n",
      "At step count 30404\n",
      "Test Error: \n",
      " Avg loss: 0.001089 \n",
      "\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "Loss: 0.000100  [   64/ 7049]\n",
      "At step count 30415\n",
      "Loss: 0.000067  [ 6464/ 7049]\n",
      "At step count 30515\n",
      "Test Error: \n",
      " Avg loss: 0.001513 \n",
      "\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "Loss: 0.000095  [   64/ 7049]\n",
      "At step count 30526\n",
      "Loss: 0.000108  [ 6464/ 7049]\n",
      "At step count 30626\n",
      "Test Error: \n",
      " Avg loss: 0.000924 \n",
      "\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "Loss: 0.000068  [   64/ 7049]\n",
      "At step count 30637\n",
      "Loss: 0.000103  [ 6464/ 7049]\n",
      "At step count 30737\n",
      "Test Error: \n",
      " Avg loss: 0.001012 \n",
      "\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "Loss: 0.000815  [   64/ 7049]\n",
      "At step count 30748\n",
      "Loss: 0.000067  [ 6464/ 7049]\n",
      "At step count 30848\n",
      "Test Error: \n",
      " Avg loss: 0.000936 \n",
      "\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "Loss: 0.000182  [   64/ 7049]\n",
      "At step count 30859\n",
      "Loss: 0.000071  [ 6464/ 7049]\n",
      "At step count 30959\n",
      "Test Error: \n",
      " Avg loss: 0.000489 \n",
      "\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "Loss: 0.000092  [   64/ 7049]\n",
      "At step count 30970\n",
      "Loss: 0.000074  [ 6464/ 7049]\n",
      "At step count 31070\n",
      "Test Error: \n",
      " Avg loss: 0.000621 \n",
      "\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "Loss: 0.000071  [   64/ 7049]\n",
      "At step count 31081\n",
      "Loss: 0.000108  [ 6464/ 7049]\n",
      "At step count 31181\n",
      "Test Error: \n",
      " Avg loss: 0.000477 \n",
      "\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "Loss: 0.000075  [   64/ 7049]\n",
      "At step count 31192\n",
      "Loss: 0.000973  [ 6464/ 7049]\n",
      "At step count 31292\n",
      "Test Error: \n",
      " Avg loss: 0.000754 \n",
      "\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "Loss: 0.000240  [   64/ 7049]\n",
      "At step count 31303\n",
      "Loss: 0.000074  [ 6464/ 7049]\n",
      "At step count 31403\n",
      "Test Error: \n",
      " Avg loss: 0.000423 \n",
      "\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "Loss: 0.000086  [   64/ 7049]\n",
      "At step count 31414\n",
      "Loss: 0.000072  [ 6464/ 7049]\n",
      "At step count 31514\n",
      "Test Error: \n",
      " Avg loss: 0.000768 \n",
      "\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "Loss: 0.000086  [   64/ 7049]\n",
      "At step count 31525\n",
      "Loss: 0.000111  [ 6464/ 7049]\n",
      "At step count 31625\n",
      "Test Error: \n",
      " Avg loss: 0.001345 \n",
      "\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "Loss: 0.000080  [   64/ 7049]\n",
      "At step count 31636\n",
      "Loss: 0.000120  [ 6464/ 7049]\n",
      "At step count 31736\n",
      "Test Error: \n",
      " Avg loss: 0.001147 \n",
      "\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "Loss: 0.000105  [   64/ 7049]\n",
      "At step count 31747\n",
      "Loss: 0.000105  [ 6464/ 7049]\n",
      "At step count 31847\n",
      "Test Error: \n",
      " Avg loss: 0.000520 \n",
      "\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "Loss: 0.000141  [   64/ 7049]\n",
      "At step count 31858\n",
      "Loss: 0.000087  [ 6464/ 7049]\n",
      "At step count 31958\n",
      "Test Error: \n",
      " Avg loss: 0.001289 \n",
      "\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "Loss: 0.000109  [   64/ 7049]\n",
      "At step count 31969\n",
      "Loss: 0.000144  [ 6464/ 7049]\n",
      "At step count 32069\n",
      "Test Error: \n",
      " Avg loss: 0.001388 \n",
      "\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "Loss: 0.000053  [   64/ 7049]\n",
      "At step count 32080\n",
      "Loss: 0.000138  [ 6464/ 7049]\n",
      "At step count 32180\n",
      "Test Error: \n",
      " Avg loss: 0.000656 \n",
      "\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "Loss: 0.000635  [   64/ 7049]\n",
      "At step count 32191\n",
      "Loss: 0.000052  [ 6464/ 7049]\n",
      "At step count 32291\n",
      "Test Error: \n",
      " Avg loss: 0.001104 \n",
      "\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "Loss: 0.000176  [   64/ 7049]\n",
      "At step count 32302\n",
      "Loss: 0.000117  [ 6464/ 7049]\n",
      "At step count 32402\n",
      "Test Error: \n",
      " Avg loss: 0.000888 \n",
      "\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "Loss: 0.000076  [   64/ 7049]\n",
      "At step count 32413\n",
      "Loss: 0.000111  [ 6464/ 7049]\n",
      "At step count 32513\n",
      "Test Error: \n",
      " Avg loss: 0.000830 \n",
      "\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "Loss: 0.000069  [   64/ 7049]\n",
      "At step count 32524\n",
      "Loss: 0.000224  [ 6464/ 7049]\n",
      "At step count 32624\n",
      "Test Error: \n",
      " Avg loss: 0.001065 \n",
      "\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "Loss: 0.000061  [   64/ 7049]\n",
      "At step count 32635\n",
      "Loss: 0.000054  [ 6464/ 7049]\n",
      "At step count 32735\n",
      "Test Error: \n",
      " Avg loss: 0.000964 \n",
      "\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "Loss: 0.000083  [   64/ 7049]\n",
      "At step count 32746\n",
      "Loss: 0.000173  [ 6464/ 7049]\n",
      "At step count 32846\n",
      "Test Error: \n",
      " Avg loss: 0.001109 \n",
      "\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "Loss: 0.000076  [   64/ 7049]\n",
      "At step count 32857\n",
      "Loss: 0.000137  [ 6464/ 7049]\n",
      "At step count 32957\n",
      "Test Error: \n",
      " Avg loss: 0.000733 \n",
      "\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "Loss: 0.000170  [   64/ 7049]\n",
      "At step count 32968\n",
      "Loss: 0.000095  [ 6464/ 7049]\n",
      "At step count 33068\n",
      "Test Error: \n",
      " Avg loss: 0.000706 \n",
      "\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "Loss: 0.000110  [   64/ 7049]\n",
      "At step count 33079\n",
      "Loss: 0.000150  [ 6464/ 7049]\n",
      "At step count 33179\n",
      "Test Error: \n",
      " Avg loss: 0.001194 \n",
      "\n",
      "Epoch 300\n",
      "-------------------------------\n",
      "Loss: 0.000058  [   64/ 7049]\n",
      "At step count 33190\n",
      "Loss: 0.000084  [ 6464/ 7049]\n",
      "At step count 33290\n",
      "Test Error: \n",
      " Avg loss: 0.001057 \n",
      "\n",
      "Epoch 301\n",
      "-------------------------------\n",
      "Loss: 0.000106  [   64/ 7049]\n",
      "At step count 33301\n",
      "Loss: 0.000113  [ 6464/ 7049]\n",
      "At step count 33401\n",
      "Test Error: \n",
      " Avg loss: 0.001183 \n",
      "\n",
      "Epoch 302\n",
      "-------------------------------\n",
      "Loss: 0.000085  [   64/ 7049]\n",
      "At step count 33412\n",
      "Loss: 0.000527  [ 6464/ 7049]\n",
      "At step count 33512\n",
      "Test Error: \n",
      " Avg loss: 0.000572 \n",
      "\n",
      "Epoch 303\n",
      "-------------------------------\n",
      "Loss: 0.000119  [   64/ 7049]\n",
      "At step count 33523\n",
      "Loss: 0.001073  [ 6464/ 7049]\n",
      "At step count 33623\n",
      "Test Error: \n",
      " Avg loss: 0.000743 \n",
      "\n",
      "Epoch 304\n",
      "-------------------------------\n",
      "Loss: 0.001638  [   64/ 7049]\n",
      "At step count 33634\n",
      "Loss: 0.000893  [ 6464/ 7049]\n",
      "At step count 33734\n",
      "Test Error: \n",
      " Avg loss: 0.000498 \n",
      "\n",
      "Epoch 305\n",
      "-------------------------------\n",
      "Loss: 0.000514  [   64/ 7049]\n",
      "At step count 33745\n",
      "Loss: 0.000371  [ 6464/ 7049]\n",
      "At step count 33845\n",
      "Test Error: \n",
      " Avg loss: 0.000377 \n",
      "\n",
      "Epoch 306\n",
      "-------------------------------\n",
      "Loss: 0.000425  [   64/ 7049]\n",
      "At step count 33856\n",
      "Loss: 0.000474  [ 6464/ 7049]\n",
      "At step count 33956\n",
      "Test Error: \n",
      " Avg loss: 0.000391 \n",
      "\n",
      "Epoch 307\n",
      "-------------------------------\n",
      "Loss: 0.000291  [   64/ 7049]\n",
      "At step count 33967\n",
      "Loss: 0.000430  [ 6464/ 7049]\n",
      "At step count 34067\n",
      "Test Error: \n",
      " Avg loss: 0.000342 \n",
      "\n",
      "Epoch 308\n",
      "-------------------------------\n",
      "Loss: 0.000460  [   64/ 7049]\n",
      "At step count 34078\n",
      "Loss: 0.000248  [ 6464/ 7049]\n",
      "At step count 34178\n",
      "Test Error: \n",
      " Avg loss: 0.000361 \n",
      "\n",
      "Epoch 309\n",
      "-------------------------------\n",
      "Loss: 0.000394  [   64/ 7049]\n",
      "At step count 34189\n",
      "Loss: 0.000267  [ 6464/ 7049]\n",
      "At step count 34289\n",
      "Test Error: \n",
      " Avg loss: 0.000398 \n",
      "\n",
      "Epoch 310\n",
      "-------------------------------\n",
      "Loss: 0.000227  [   64/ 7049]\n",
      "At step count 34300\n",
      "Loss: 0.000681  [ 6464/ 7049]\n",
      "At step count 34400\n",
      "Test Error: \n",
      " Avg loss: 0.000403 \n",
      "\n",
      "Epoch 311\n",
      "-------------------------------\n",
      "Loss: 0.000187  [   64/ 7049]\n",
      "At step count 34411\n",
      "Loss: 0.000240  [ 6464/ 7049]\n",
      "At step count 34511\n",
      "Test Error: \n",
      " Avg loss: 0.000425 \n",
      "\n",
      "Epoch 312\n",
      "-------------------------------\n",
      "Loss: 0.000193  [   64/ 7049]\n",
      "At step count 34522\n",
      "Loss: 0.000353  [ 6464/ 7049]\n",
      "At step count 34622\n",
      "Test Error: \n",
      " Avg loss: 0.000563 \n",
      "\n",
      "Epoch 313\n",
      "-------------------------------\n",
      "Loss: 0.000178  [   64/ 7049]\n",
      "At step count 34633\n",
      "Loss: 0.000216  [ 6464/ 7049]\n",
      "At step count 34733\n",
      "Test Error: \n",
      " Avg loss: 0.000753 \n",
      "\n",
      "Epoch 314\n",
      "-------------------------------\n",
      "Loss: 0.000188  [   64/ 7049]\n",
      "At step count 34744\n",
      "Loss: 0.000193  [ 6464/ 7049]\n",
      "At step count 34844\n",
      "Test Error: \n",
      " Avg loss: 0.000876 \n",
      "\n",
      "Epoch 315\n",
      "-------------------------------\n",
      "Loss: 0.000226  [   64/ 7049]\n",
      "At step count 34855\n",
      "Loss: 0.000173  [ 6464/ 7049]\n",
      "At step count 34955\n",
      "Test Error: \n",
      " Avg loss: 0.000625 \n",
      "\n",
      "Epoch 316\n",
      "-------------------------------\n",
      "Loss: 0.000180  [   64/ 7049]\n",
      "At step count 34966\n",
      "Loss: 0.000206  [ 6464/ 7049]\n",
      "At step count 35066\n",
      "Test Error: \n",
      " Avg loss: 0.000870 \n",
      "\n",
      "Epoch 317\n",
      "-------------------------------\n",
      "Loss: 0.000138  [   64/ 7049]\n",
      "At step count 35077\n",
      "Loss: 0.000207  [ 6464/ 7049]\n",
      "At step count 35177\n",
      "Test Error: \n",
      " Avg loss: 0.000680 \n",
      "\n",
      "Epoch 318\n",
      "-------------------------------\n",
      "Loss: 0.000254  [   64/ 7049]\n",
      "At step count 35188\n",
      "Loss: 0.000218  [ 6464/ 7049]\n",
      "At step count 35288\n",
      "Test Error: \n",
      " Avg loss: 0.000633 \n",
      "\n",
      "Epoch 319\n",
      "-------------------------------\n",
      "Loss: 0.000222  [   64/ 7049]\n",
      "At step count 35299\n",
      "Loss: 0.000278  [ 6464/ 7049]\n",
      "At step count 35399\n",
      "Test Error: \n",
      " Avg loss: 0.001184 \n",
      "\n",
      "Epoch 320\n",
      "-------------------------------\n",
      "Loss: 0.000136  [   64/ 7049]\n",
      "At step count 35410\n",
      "Loss: 0.000274  [ 6464/ 7049]\n",
      "At step count 35510\n",
      "Test Error: \n",
      " Avg loss: 0.000895 \n",
      "\n",
      "Epoch 321\n",
      "-------------------------------\n",
      "Loss: 0.000381  [   64/ 7049]\n",
      "At step count 35521\n",
      "Loss: 0.000160  [ 6464/ 7049]\n",
      "At step count 35621\n",
      "Test Error: \n",
      " Avg loss: 0.000927 \n",
      "\n",
      "Epoch 322\n",
      "-------------------------------\n",
      "Loss: 0.000132  [   64/ 7049]\n",
      "At step count 35632\n",
      "Loss: 0.000143  [ 6464/ 7049]\n",
      "At step count 35732\n",
      "Test Error: \n",
      " Avg loss: 0.000990 \n",
      "\n",
      "Epoch 323\n",
      "-------------------------------\n",
      "Loss: 0.000150  [   64/ 7049]\n",
      "At step count 35743\n",
      "Loss: 0.000114  [ 6464/ 7049]\n",
      "At step count 35843\n",
      "Test Error: \n",
      " Avg loss: 0.000646 \n",
      "\n",
      "Epoch 324\n",
      "-------------------------------\n",
      "Loss: 0.000146  [   64/ 7049]\n",
      "At step count 35854\n",
      "Loss: 0.000117  [ 6464/ 7049]\n",
      "At step count 35954\n",
      "Test Error: \n",
      " Avg loss: 0.000713 \n",
      "\n",
      "Epoch 325\n",
      "-------------------------------\n",
      "Loss: 0.000143  [   64/ 7049]\n",
      "At step count 35965\n",
      "Loss: 0.000317  [ 6464/ 7049]\n",
      "At step count 36065\n",
      "Test Error: \n",
      " Avg loss: 0.000725 \n",
      "\n",
      "Epoch 326\n",
      "-------------------------------\n",
      "Loss: 0.000141  [   64/ 7049]\n",
      "At step count 36076\n",
      "Loss: 0.000187  [ 6464/ 7049]\n",
      "At step count 36176\n",
      "Test Error: \n",
      " Avg loss: 0.001262 \n",
      "\n",
      "Epoch 327\n",
      "-------------------------------\n",
      "Loss: 0.000154  [   64/ 7049]\n",
      "At step count 36187\n",
      "Loss: 0.000190  [ 6464/ 7049]\n",
      "At step count 36287\n",
      "Test Error: \n",
      " Avg loss: 0.000811 \n",
      "\n",
      "Epoch 328\n",
      "-------------------------------\n",
      "Loss: 0.000123  [   64/ 7049]\n",
      "At step count 36298\n",
      "Loss: 0.000130  [ 6464/ 7049]\n",
      "At step count 36398\n",
      "Test Error: \n",
      " Avg loss: 0.000821 \n",
      "\n",
      "Epoch 329\n",
      "-------------------------------\n",
      "Loss: 0.000140  [   64/ 7049]\n",
      "At step count 36409\n",
      "Loss: 0.000152  [ 6464/ 7049]\n",
      "At step count 36509\n",
      "Test Error: \n",
      " Avg loss: 0.000649 \n",
      "\n",
      "Epoch 330\n",
      "-------------------------------\n",
      "Loss: 0.000214  [   64/ 7049]\n",
      "At step count 36520\n",
      "Loss: 0.000130  [ 6464/ 7049]\n",
      "At step count 36620\n",
      "Test Error: \n",
      " Avg loss: 0.000678 \n",
      "\n",
      "Epoch 331\n",
      "-------------------------------\n",
      "Loss: 0.000115  [   64/ 7049]\n",
      "At step count 36631\n",
      "Loss: 0.000122  [ 6464/ 7049]\n",
      "At step count 36731\n",
      "Test Error: \n",
      " Avg loss: 0.000735 \n",
      "\n",
      "Epoch 332\n",
      "-------------------------------\n",
      "Loss: 0.000104  [   64/ 7049]\n",
      "At step count 36742\n",
      "Loss: 0.000135  [ 6464/ 7049]\n",
      "At step count 36842\n",
      "Test Error: \n",
      " Avg loss: 0.000440 \n",
      "\n",
      "Epoch 333\n",
      "-------------------------------\n",
      "Loss: 0.000109  [   64/ 7049]\n",
      "At step count 36853\n",
      "Loss: 0.000178  [ 6464/ 7049]\n",
      "At step count 36953\n",
      "Test Error: \n",
      " Avg loss: 0.001119 \n",
      "\n",
      "Epoch 334\n",
      "-------------------------------\n",
      "Loss: 0.000135  [   64/ 7049]\n",
      "At step count 36964\n",
      "Loss: 0.000127  [ 6464/ 7049]\n",
      "At step count 37064\n",
      "Test Error: \n",
      " Avg loss: 0.000960 \n",
      "\n",
      "Epoch 335\n",
      "-------------------------------\n",
      "Loss: 0.000201  [   64/ 7049]\n",
      "At step count 37075\n",
      "Loss: 0.000088  [ 6464/ 7049]\n",
      "At step count 37175\n",
      "Test Error: \n",
      " Avg loss: 0.000542 \n",
      "\n",
      "Epoch 336\n",
      "-------------------------------\n",
      "Loss: 0.000211  [   64/ 7049]\n",
      "At step count 37186\n",
      "Loss: 0.000161  [ 6464/ 7049]\n",
      "At step count 37286\n",
      "Test Error: \n",
      " Avg loss: 0.000598 \n",
      "\n",
      "Epoch 337\n",
      "-------------------------------\n",
      "Loss: 0.000106  [   64/ 7049]\n",
      "At step count 37297\n",
      "Loss: 0.000138  [ 6464/ 7049]\n",
      "At step count 37397\n",
      "Test Error: \n",
      " Avg loss: 0.000745 \n",
      "\n",
      "Epoch 338\n",
      "-------------------------------\n",
      "Loss: 0.000088  [   64/ 7049]\n",
      "At step count 37408\n",
      "Loss: 0.000096  [ 6464/ 7049]\n",
      "At step count 37508\n",
      "Test Error: \n",
      " Avg loss: 0.001045 \n",
      "\n",
      "Epoch 339\n",
      "-------------------------------\n",
      "Loss: 0.000179  [   64/ 7049]\n",
      "At step count 37519\n",
      "Loss: 0.000129  [ 6464/ 7049]\n",
      "At step count 37619\n",
      "Test Error: \n",
      " Avg loss: 0.000810 \n",
      "\n",
      "Epoch 340\n",
      "-------------------------------\n",
      "Loss: 0.000079  [   64/ 7049]\n",
      "At step count 37630\n",
      "Loss: 0.000109  [ 6464/ 7049]\n",
      "At step count 37730\n",
      "Test Error: \n",
      " Avg loss: 0.001036 \n",
      "\n",
      "Epoch 341\n",
      "-------------------------------\n",
      "Loss: 0.000144  [   64/ 7049]\n",
      "At step count 37741\n",
      "Loss: 0.000091  [ 6464/ 7049]\n",
      "At step count 37841\n",
      "Test Error: \n",
      " Avg loss: 0.000840 \n",
      "\n",
      "Epoch 342\n",
      "-------------------------------\n",
      "Loss: 0.000125  [   64/ 7049]\n",
      "At step count 37852\n",
      "Loss: 0.000382  [ 6464/ 7049]\n",
      "At step count 37952\n",
      "Test Error: \n",
      " Avg loss: 0.000791 \n",
      "\n",
      "Epoch 343\n",
      "-------------------------------\n",
      "Loss: 0.001187  [   64/ 7049]\n",
      "At step count 37963\n",
      "Loss: 0.000086  [ 6464/ 7049]\n",
      "At step count 38063\n",
      "Test Error: \n",
      " Avg loss: 0.000550 \n",
      "\n",
      "Epoch 344\n",
      "-------------------------------\n",
      "Loss: 0.000127  [   64/ 7049]\n",
      "At step count 38074\n",
      "Loss: 0.000092  [ 6464/ 7049]\n",
      "At step count 38174\n",
      "Test Error: \n",
      " Avg loss: 0.001025 \n",
      "\n",
      "Epoch 345\n",
      "-------------------------------\n",
      "Loss: 0.000094  [   64/ 7049]\n",
      "At step count 38185\n",
      "Loss: 0.000081  [ 6464/ 7049]\n",
      "At step count 38285\n",
      "Test Error: \n",
      " Avg loss: 0.000416 \n",
      "\n",
      "Epoch 346\n",
      "-------------------------------\n",
      "Loss: 0.000082  [   64/ 7049]\n",
      "At step count 38296\n",
      "Loss: 0.000092  [ 6464/ 7049]\n",
      "At step count 38396\n",
      "Test Error: \n",
      " Avg loss: 0.001867 \n",
      "\n",
      "Epoch 347\n",
      "-------------------------------\n",
      "Loss: 0.000087  [   64/ 7049]\n",
      "At step count 38407\n",
      "Loss: 0.000102  [ 6464/ 7049]\n",
      "At step count 38507\n",
      "Test Error: \n",
      " Avg loss: 0.001025 \n",
      "\n",
      "Epoch 348\n",
      "-------------------------------\n",
      "Loss: 0.000081  [   64/ 7049]\n",
      "At step count 38518\n",
      "Loss: 0.000083  [ 6464/ 7049]\n",
      "At step count 38618\n",
      "Test Error: \n",
      " Avg loss: 0.001902 \n",
      "\n",
      "Epoch 349\n",
      "-------------------------------\n",
      "Loss: 0.000238  [   64/ 7049]\n",
      "At step count 38629\n",
      "Loss: 0.000119  [ 6464/ 7049]\n",
      "At step count 38729\n",
      "Test Error: \n",
      " Avg loss: 0.002872 \n",
      "\n",
      "Epoch 350\n",
      "-------------------------------\n",
      "Loss: 0.000114  [   64/ 7049]\n",
      "At step count 38740\n",
      "Loss: 0.000074  [ 6464/ 7049]\n",
      "At step count 38840\n",
      "Test Error: \n",
      " Avg loss: 0.000918 \n",
      "\n",
      "Epoch 351\n",
      "-------------------------------\n",
      "Loss: 0.000093  [   64/ 7049]\n",
      "At step count 38851\n",
      "Loss: 0.000085  [ 6464/ 7049]\n",
      "At step count 38951\n",
      "Test Error: \n",
      " Avg loss: 0.001797 \n",
      "\n",
      "Epoch 352\n",
      "-------------------------------\n",
      "Loss: 0.000078  [   64/ 7049]\n",
      "At step count 38962\n",
      "Loss: 0.000122  [ 6464/ 7049]\n",
      "At step count 39062\n",
      "Test Error: \n",
      " Avg loss: 0.000681 \n",
      "\n",
      "Epoch 353\n",
      "-------------------------------\n",
      "Loss: 0.000055  [   64/ 7049]\n",
      "At step count 39073\n",
      "Loss: 0.000145  [ 6464/ 7049]\n",
      "At step count 39173\n",
      "Test Error: \n",
      " Avg loss: 0.001302 \n",
      "\n",
      "Epoch 354\n",
      "-------------------------------\n",
      "Loss: 0.000436  [   64/ 7049]\n",
      "At step count 39184\n",
      "Loss: 0.000135  [ 6464/ 7049]\n",
      "At step count 39284\n",
      "Test Error: \n",
      " Avg loss: 0.000729 \n",
      "\n",
      "Epoch 355\n",
      "-------------------------------\n",
      "Loss: 0.000077  [   64/ 7049]\n",
      "At step count 39295\n",
      "Loss: 0.000124  [ 6464/ 7049]\n",
      "At step count 39395\n",
      "Test Error: \n",
      " Avg loss: 0.001313 \n",
      "\n",
      "Epoch 356\n",
      "-------------------------------\n",
      "Loss: 0.000111  [   64/ 7049]\n",
      "At step count 39406\n",
      "Loss: 0.000132  [ 6464/ 7049]\n",
      "At step count 39506\n",
      "Test Error: \n",
      " Avg loss: 0.000800 \n",
      "\n",
      "Epoch 357\n",
      "-------------------------------\n",
      "Loss: 0.000082  [   64/ 7049]\n",
      "At step count 39517\n",
      "Loss: 0.000104  [ 6464/ 7049]\n",
      "At step count 39617\n",
      "Test Error: \n",
      " Avg loss: 0.000639 \n",
      "\n",
      "Epoch 358\n",
      "-------------------------------\n",
      "Loss: 0.000101  [   64/ 7049]\n",
      "At step count 39628\n",
      "Loss: 0.000311  [ 6464/ 7049]\n",
      "At step count 39728\n",
      "Test Error: \n",
      " Avg loss: 0.000969 \n",
      "\n",
      "Epoch 359\n",
      "-------------------------------\n",
      "Loss: 0.000090  [   64/ 7049]\n",
      "At step count 39739\n",
      "Loss: 0.000121  [ 6464/ 7049]\n",
      "At step count 39839\n",
      "Test Error: \n",
      " Avg loss: 0.000846 \n",
      "\n",
      "Epoch 360\n",
      "-------------------------------\n",
      "Loss: 0.000270  [   64/ 7049]\n",
      "At step count 39850\n",
      "Loss: 0.000083  [ 6464/ 7049]\n",
      "At step count 39950\n",
      "Test Error: \n",
      " Avg loss: 0.000768 \n",
      "\n",
      "Epoch 361\n",
      "-------------------------------\n",
      "Loss: 0.000057  [   64/ 7049]\n",
      "At step count 39961\n",
      "Loss: 0.000081  [ 6464/ 7049]\n",
      "At step count 40061\n",
      "Test Error: \n",
      " Avg loss: 0.000590 \n",
      "\n",
      "Epoch 362\n",
      "-------------------------------\n",
      "Loss: 0.000153  [   64/ 7049]\n",
      "At step count 40072\n",
      "Loss: 0.000090  [ 6464/ 7049]\n",
      "At step count 40172\n",
      "Test Error: \n",
      " Avg loss: 0.000614 \n",
      "\n",
      "Epoch 363\n",
      "-------------------------------\n",
      "Loss: 0.000107  [   64/ 7049]\n",
      "At step count 40183\n",
      "Loss: 0.000156  [ 6464/ 7049]\n",
      "At step count 40283\n",
      "Test Error: \n",
      " Avg loss: 0.001326 \n",
      "\n",
      "Epoch 364\n",
      "-------------------------------\n",
      "Loss: 0.000049  [   64/ 7049]\n",
      "At step count 40294\n",
      "Loss: 0.000089  [ 6464/ 7049]\n",
      "At step count 40394\n",
      "Test Error: \n",
      " Avg loss: 0.000828 \n",
      "\n",
      "Epoch 365\n",
      "-------------------------------\n",
      "Loss: 0.000102  [   64/ 7049]\n",
      "At step count 40405\n",
      "Loss: 0.000121  [ 6464/ 7049]\n",
      "At step count 40505\n",
      "Test Error: \n",
      " Avg loss: 0.000914 \n",
      "\n",
      "Epoch 366\n",
      "-------------------------------\n",
      "Loss: 0.000096  [   64/ 7049]\n",
      "At step count 40516\n",
      "Loss: 0.000115  [ 6464/ 7049]\n",
      "At step count 40616\n",
      "Test Error: \n",
      " Avg loss: 0.000690 \n",
      "\n",
      "Epoch 367\n",
      "-------------------------------\n",
      "Loss: 0.000111  [   64/ 7049]\n",
      "At step count 40627\n",
      "Loss: 0.000091  [ 6464/ 7049]\n",
      "At step count 40727\n",
      "Test Error: \n",
      " Avg loss: 0.000407 \n",
      "\n",
      "Epoch 368\n",
      "-------------------------------\n",
      "Loss: 0.000069  [   64/ 7049]\n",
      "At step count 40738\n",
      "Loss: 0.000079  [ 6464/ 7049]\n",
      "At step count 40838\n",
      "Test Error: \n",
      " Avg loss: 0.000902 \n",
      "\n",
      "Epoch 369\n",
      "-------------------------------\n",
      "Loss: 0.000102  [   64/ 7049]\n",
      "At step count 40849\n",
      "Loss: 0.000100  [ 6464/ 7049]\n",
      "At step count 40949\n",
      "Test Error: \n",
      " Avg loss: 0.001338 \n",
      "\n",
      "Epoch 370\n",
      "-------------------------------\n",
      "Loss: 0.000230  [   64/ 7049]\n",
      "At step count 40960\n",
      "Loss: 0.000073  [ 6464/ 7049]\n",
      "At step count 41060\n",
      "Test Error: \n",
      " Avg loss: 0.001340 \n",
      "\n",
      "Epoch 371\n",
      "-------------------------------\n",
      "Loss: 0.000101  [   64/ 7049]\n",
      "At step count 41071\n",
      "Loss: 0.000106  [ 6464/ 7049]\n",
      "At step count 41171\n",
      "Test Error: \n",
      " Avg loss: 0.001078 \n",
      "\n",
      "Epoch 372\n",
      "-------------------------------\n",
      "Loss: 0.000056  [   64/ 7049]\n",
      "At step count 41182\n",
      "Loss: 0.000129  [ 6464/ 7049]\n",
      "At step count 41282\n",
      "Test Error: \n",
      " Avg loss: 0.001297 \n",
      "\n",
      "Epoch 373\n",
      "-------------------------------\n",
      "Loss: 0.000081  [   64/ 7049]\n",
      "At step count 41293\n",
      "Loss: 0.000092  [ 6464/ 7049]\n",
      "At step count 41393\n",
      "Test Error: \n",
      " Avg loss: 0.001463 \n",
      "\n",
      "Epoch 374\n",
      "-------------------------------\n",
      "Loss: 0.000078  [   64/ 7049]\n",
      "At step count 41404\n",
      "Loss: 0.000081  [ 6464/ 7049]\n",
      "At step count 41504\n",
      "Test Error: \n",
      " Avg loss: 0.001069 \n",
      "\n",
      "Epoch 375\n",
      "-------------------------------\n",
      "Loss: 0.000105  [   64/ 7049]\n",
      "At step count 41515\n",
      "Loss: 0.000094  [ 6464/ 7049]\n",
      "At step count 41615\n",
      "Test Error: \n",
      " Avg loss: 0.001566 \n",
      "\n",
      "Epoch 376\n",
      "-------------------------------\n",
      "Loss: 0.000138  [   64/ 7049]\n",
      "At step count 41626\n",
      "Loss: 0.000096  [ 6464/ 7049]\n",
      "At step count 41726\n",
      "Test Error: \n",
      " Avg loss: 0.002218 \n",
      "\n",
      "Epoch 377\n",
      "-------------------------------\n",
      "Loss: 0.000067  [   64/ 7049]\n",
      "At step count 41737\n",
      "Loss: 0.000070  [ 6464/ 7049]\n",
      "At step count 41837\n",
      "Test Error: \n",
      " Avg loss: 0.001045 \n",
      "\n",
      "Epoch 378\n",
      "-------------------------------\n",
      "Loss: 0.000585  [   64/ 7049]\n",
      "At step count 41848\n",
      "Loss: 0.000064  [ 6464/ 7049]\n",
      "At step count 41948\n",
      "Test Error: \n",
      " Avg loss: 0.001013 \n",
      "\n",
      "Epoch 379\n",
      "-------------------------------\n",
      "Loss: 0.000068  [   64/ 7049]\n",
      "At step count 41959\n",
      "Loss: 0.000111  [ 6464/ 7049]\n",
      "At step count 42059\n",
      "Test Error: \n",
      " Avg loss: 0.000976 \n",
      "\n",
      "Epoch 380\n",
      "-------------------------------\n",
      "Loss: 0.000064  [   64/ 7049]\n",
      "At step count 42070\n",
      "Loss: 0.000073  [ 6464/ 7049]\n",
      "At step count 42170\n",
      "Test Error: \n",
      " Avg loss: 0.000986 \n",
      "\n",
      "Epoch 381\n",
      "-------------------------------\n",
      "Loss: 0.000136  [   64/ 7049]\n",
      "At step count 42181\n",
      "Loss: 0.000122  [ 6464/ 7049]\n",
      "At step count 42281\n",
      "Test Error: \n",
      " Avg loss: 0.000884 \n",
      "\n",
      "Epoch 382\n",
      "-------------------------------\n",
      "Loss: 0.000180  [   64/ 7049]\n",
      "At step count 42292\n",
      "Loss: 0.000093  [ 6464/ 7049]\n",
      "At step count 42392\n",
      "Test Error: \n",
      " Avg loss: 0.000998 \n",
      "\n",
      "Epoch 383\n",
      "-------------------------------\n",
      "Loss: 0.000071  [   64/ 7049]\n",
      "At step count 42403\n",
      "Loss: 0.000071  [ 6464/ 7049]\n",
      "At step count 42503\n",
      "Test Error: \n",
      " Avg loss: 0.000967 \n",
      "\n",
      "Epoch 384\n",
      "-------------------------------\n",
      "Loss: 0.000178  [   64/ 7049]\n",
      "At step count 42514\n",
      "Loss: 0.000110  [ 6464/ 7049]\n",
      "At step count 42614\n",
      "Test Error: \n",
      " Avg loss: 0.000570 \n",
      "\n",
      "Epoch 385\n",
      "-------------------------------\n",
      "Loss: 0.000239  [   64/ 7049]\n",
      "At step count 42625\n",
      "Loss: 0.000184  [ 6464/ 7049]\n",
      "At step count 42725\n",
      "Test Error: \n",
      " Avg loss: 0.000737 \n",
      "\n",
      "Epoch 386\n",
      "-------------------------------\n",
      "Loss: 0.000068  [   64/ 7049]\n",
      "At step count 42736\n",
      "Loss: 0.000062  [ 6464/ 7049]\n",
      "At step count 42836\n",
      "Test Error: \n",
      " Avg loss: 0.000712 \n",
      "\n",
      "Epoch 387\n",
      "-------------------------------\n",
      "Loss: 0.000121  [   64/ 7049]\n",
      "At step count 42847\n",
      "Loss: 0.000663  [ 6464/ 7049]\n",
      "At step count 42947\n",
      "Test Error: \n",
      " Avg loss: 0.000725 \n",
      "\n",
      "Epoch 388\n",
      "-------------------------------\n",
      "Loss: 0.000096  [   64/ 7049]\n",
      "At step count 42958\n",
      "Loss: 0.000077  [ 6464/ 7049]\n",
      "At step count 43058\n",
      "Test Error: \n",
      " Avg loss: 0.001436 \n",
      "\n",
      "Epoch 389\n",
      "-------------------------------\n",
      "Loss: 0.000076  [   64/ 7049]\n",
      "At step count 43069\n",
      "Loss: 0.000176  [ 6464/ 7049]\n",
      "At step count 43169\n",
      "Test Error: \n",
      " Avg loss: 0.000779 \n",
      "\n",
      "Epoch 390\n",
      "-------------------------------\n",
      "Loss: 0.000070  [   64/ 7049]\n",
      "At step count 43180\n",
      "Loss: 0.000298  [ 6464/ 7049]\n",
      "At step count 43280\n",
      "Test Error: \n",
      " Avg loss: 0.000774 \n",
      "\n",
      "Epoch 391\n",
      "-------------------------------\n",
      "Loss: 0.000196  [   64/ 7049]\n",
      "At step count 43291\n",
      "Loss: 0.000104  [ 6464/ 7049]\n",
      "At step count 43391\n",
      "Test Error: \n",
      " Avg loss: 0.001116 \n",
      "\n",
      "Epoch 392\n",
      "-------------------------------\n",
      "Loss: 0.000080  [   64/ 7049]\n",
      "At step count 43402\n",
      "Loss: 0.000086  [ 6464/ 7049]\n",
      "At step count 43502\n",
      "Test Error: \n",
      " Avg loss: 0.001243 \n",
      "\n",
      "Epoch 393\n",
      "-------------------------------\n",
      "Loss: 0.000113  [   64/ 7049]\n",
      "At step count 43513\n",
      "Loss: 0.000073  [ 6464/ 7049]\n",
      "At step count 43613\n",
      "Test Error: \n",
      " Avg loss: 0.001185 \n",
      "\n",
      "Epoch 394\n",
      "-------------------------------\n",
      "Loss: 0.000073  [   64/ 7049]\n",
      "At step count 43624\n",
      "Loss: 0.000109  [ 6464/ 7049]\n",
      "At step count 43724\n",
      "Test Error: \n",
      " Avg loss: 0.000877 \n",
      "\n",
      "Epoch 395\n",
      "-------------------------------\n",
      "Loss: 0.000115  [   64/ 7049]\n",
      "At step count 43735\n",
      "Loss: 0.000087  [ 6464/ 7049]\n",
      "At step count 43835\n",
      "Test Error: \n",
      " Avg loss: 0.000852 \n",
      "\n",
      "Epoch 396\n",
      "-------------------------------\n",
      "Loss: 0.000067  [   64/ 7049]\n",
      "At step count 43846\n",
      "Loss: 0.000067  [ 6464/ 7049]\n",
      "At step count 43946\n",
      "Test Error: \n",
      " Avg loss: 0.000620 \n",
      "\n",
      "Epoch 397\n",
      "-------------------------------\n",
      "Loss: 0.000095  [   64/ 7049]\n",
      "At step count 43957\n",
      "Loss: 0.000355  [ 6464/ 7049]\n",
      "At step count 44057\n",
      "Test Error: \n",
      " Avg loss: 0.001392 \n",
      "\n",
      "Epoch 398\n",
      "-------------------------------\n",
      "Loss: 0.000101  [   64/ 7049]\n",
      "At step count 44068\n",
      "Loss: 0.000079  [ 6464/ 7049]\n",
      "At step count 44168\n",
      "Test Error: \n",
      " Avg loss: 0.000997 \n",
      "\n",
      "Epoch 399\n",
      "-------------------------------\n",
      "Loss: 0.000110  [   64/ 7049]\n",
      "At step count 44179\n",
      "Loss: 0.000091  [ 6464/ 7049]\n",
      "At step count 44279\n",
      "Test Error: \n",
      " Avg loss: 0.000967 \n",
      "\n",
      "Epoch 400\n",
      "-------------------------------\n",
      "Loss: 0.000069  [   64/ 7049]\n",
      "At step count 44290\n",
      "Loss: 0.000080  [ 6464/ 7049]\n",
      "At step count 44390\n",
      "Test Error: \n",
      " Avg loss: 0.001512 \n",
      "\n",
      "Epoch 401\n",
      "-------------------------------\n",
      "Loss: 0.000104  [   64/ 7049]\n",
      "At step count 44401\n",
      "Loss: 0.000143  [ 6464/ 7049]\n",
      "At step count 44501\n",
      "Test Error: \n",
      " Avg loss: 0.001042 \n",
      "\n",
      "Epoch 402\n",
      "-------------------------------\n",
      "Loss: 0.000064  [   64/ 7049]\n",
      "At step count 44512\n",
      "Loss: 0.000104  [ 6464/ 7049]\n",
      "At step count 44612\n",
      "Test Error: \n",
      " Avg loss: 0.000931 \n",
      "\n",
      "Epoch 403\n",
      "-------------------------------\n",
      "Loss: 0.000090  [   64/ 7049]\n",
      "At step count 44623\n",
      "Loss: 0.000094  [ 6464/ 7049]\n",
      "At step count 44723\n",
      "Test Error: \n",
      " Avg loss: 0.000801 \n",
      "\n",
      "Epoch 404\n",
      "-------------------------------\n",
      "Loss: 0.000088  [   64/ 7049]\n",
      "At step count 44734\n",
      "Loss: 0.000245  [ 6464/ 7049]\n",
      "At step count 44834\n",
      "Test Error: \n",
      " Avg loss: 0.000441 \n",
      "\n",
      "Epoch 405\n",
      "-------------------------------\n",
      "Loss: 0.000181  [   64/ 7049]\n",
      "At step count 44845\n",
      "Loss: 0.000068  [ 6464/ 7049]\n",
      "At step count 44945\n",
      "Test Error: \n",
      " Avg loss: 0.001445 \n",
      "\n",
      "Epoch 406\n",
      "-------------------------------\n",
      "Loss: 0.000077  [   64/ 7049]\n",
      "At step count 44956\n",
      "Loss: 0.000116  [ 6464/ 7049]\n",
      "At step count 45056\n",
      "Test Error: \n",
      " Avg loss: 0.000968 \n",
      "\n",
      "Epoch 407\n",
      "-------------------------------\n",
      "Loss: 0.000106  [   64/ 7049]\n",
      "At step count 45067\n",
      "Loss: 0.000071  [ 6464/ 7049]\n",
      "At step count 45167\n",
      "Test Error: \n",
      " Avg loss: 0.000546 \n",
      "\n",
      "Epoch 408\n",
      "-------------------------------\n",
      "Loss: 0.000065  [   64/ 7049]\n",
      "At step count 45178\n",
      "Loss: 0.000159  [ 6464/ 7049]\n",
      "At step count 45278\n",
      "Test Error: \n",
      " Avg loss: 0.000564 \n",
      "\n",
      "Epoch 409\n",
      "-------------------------------\n",
      "Loss: 0.000074  [   64/ 7049]\n",
      "At step count 45289\n",
      "Loss: 0.000075  [ 6464/ 7049]\n",
      "At step count 45389\n",
      "Test Error: \n",
      " Avg loss: 0.001399 \n",
      "\n",
      "Epoch 410\n",
      "-------------------------------\n",
      "Loss: 0.000184  [   64/ 7049]\n",
      "At step count 45400\n",
      "Loss: 0.000126  [ 6464/ 7049]\n",
      "At step count 45500\n",
      "Test Error: \n",
      " Avg loss: 0.001300 \n",
      "\n",
      "Epoch 411\n",
      "-------------------------------\n",
      "Loss: 0.000241  [   64/ 7049]\n",
      "At step count 45511\n",
      "Loss: 0.000050  [ 6464/ 7049]\n",
      "At step count 45611\n",
      "Test Error: \n",
      " Avg loss: 0.001453 \n",
      "\n",
      "Epoch 412\n",
      "-------------------------------\n",
      "Loss: 0.000078  [   64/ 7049]\n",
      "At step count 45622\n",
      "Loss: 0.000120  [ 6464/ 7049]\n",
      "At step count 45722\n",
      "Test Error: \n",
      " Avg loss: 0.000869 \n",
      "\n",
      "Epoch 413\n",
      "-------------------------------\n",
      "Loss: 0.000098  [   64/ 7049]\n",
      "At step count 45733\n",
      "Loss: 0.000814  [ 6464/ 7049]\n",
      "At step count 45833\n",
      "Test Error: \n",
      " Avg loss: 0.001173 \n",
      "\n",
      "Epoch 414\n",
      "-------------------------------\n",
      "Loss: 0.000171  [   64/ 7049]\n",
      "At step count 45844\n",
      "Loss: 0.000348  [ 6464/ 7049]\n",
      "At step count 45944\n",
      "Test Error: \n",
      " Avg loss: 0.001029 \n",
      "\n",
      "Epoch 415\n",
      "-------------------------------\n",
      "Loss: 0.000112  [   64/ 7049]\n",
      "At step count 45955\n",
      "Loss: 0.000084  [ 6464/ 7049]\n",
      "At step count 46055\n",
      "Test Error: \n",
      " Avg loss: 0.000969 \n",
      "\n",
      "Epoch 416\n",
      "-------------------------------\n",
      "Loss: 0.000077  [   64/ 7049]\n",
      "At step count 46066\n",
      "Loss: 0.000067  [ 6464/ 7049]\n",
      "At step count 46166\n",
      "Test Error: \n",
      " Avg loss: 0.000715 \n",
      "\n",
      "Epoch 417\n",
      "-------------------------------\n",
      "Loss: 0.000089  [   64/ 7049]\n",
      "At step count 46177\n",
      "Loss: 0.000097  [ 6464/ 7049]\n",
      "At step count 46277\n",
      "Test Error: \n",
      " Avg loss: 0.001462 \n",
      "\n",
      "Epoch 418\n",
      "-------------------------------\n",
      "Loss: 0.000087  [   64/ 7049]\n",
      "At step count 46288\n",
      "Loss: 0.000147  [ 6464/ 7049]\n",
      "At step count 46388\n",
      "Test Error: \n",
      " Avg loss: 0.001469 \n",
      "\n",
      "Epoch 419\n",
      "-------------------------------\n",
      "Loss: 0.000052  [   64/ 7049]\n",
      "At step count 46399\n",
      "Loss: 0.000084  [ 6464/ 7049]\n",
      "At step count 46499\n",
      "Test Error: \n",
      " Avg loss: 0.000880 \n",
      "\n",
      "Epoch 420\n",
      "-------------------------------\n",
      "Loss: 0.000058  [   64/ 7049]\n",
      "At step count 46510\n",
      "Loss: 0.000096  [ 6464/ 7049]\n",
      "At step count 46610\n",
      "Test Error: \n",
      " Avg loss: 0.000842 \n",
      "\n",
      "Epoch 421\n",
      "-------------------------------\n",
      "Loss: 0.000172  [   64/ 7049]\n",
      "At step count 46621\n",
      "Loss: 0.000083  [ 6464/ 7049]\n",
      "At step count 46721\n",
      "Test Error: \n",
      " Avg loss: 0.000960 \n",
      "\n",
      "Epoch 422\n",
      "-------------------------------\n",
      "Loss: 0.000191  [   64/ 7049]\n",
      "At step count 46732\n",
      "Loss: 0.000067  [ 6464/ 7049]\n",
      "At step count 46832\n",
      "Test Error: \n",
      " Avg loss: 0.001137 \n",
      "\n",
      "Epoch 423\n",
      "-------------------------------\n",
      "Loss: 0.000082  [   64/ 7049]\n",
      "At step count 46843\n",
      "Loss: 0.000063  [ 6464/ 7049]\n",
      "At step count 46943\n",
      "Test Error: \n",
      " Avg loss: 0.000991 \n",
      "\n",
      "Epoch 424\n",
      "-------------------------------\n",
      "Loss: 0.000172  [   64/ 7049]\n",
      "At step count 46954\n",
      "Loss: 0.000134  [ 6464/ 7049]\n",
      "At step count 47054\n",
      "Test Error: \n",
      " Avg loss: 0.000820 \n",
      "\n",
      "Epoch 425\n",
      "-------------------------------\n",
      "Loss: 0.000063  [   64/ 7049]\n",
      "At step count 47065\n",
      "Loss: 0.000154  [ 6464/ 7049]\n",
      "At step count 47165\n",
      "Test Error: \n",
      " Avg loss: 0.000820 \n",
      "\n",
      "Epoch 426\n",
      "-------------------------------\n",
      "Loss: 0.000096  [   64/ 7049]\n",
      "At step count 47176\n",
      "Loss: 0.000080  [ 6464/ 7049]\n",
      "At step count 47276\n",
      "Test Error: \n",
      " Avg loss: 0.001238 \n",
      "\n",
      "Epoch 427\n",
      "-------------------------------\n",
      "Loss: 0.000077  [   64/ 7049]\n",
      "At step count 47287\n",
      "Loss: 0.000236  [ 6464/ 7049]\n",
      "At step count 47387\n",
      "Test Error: \n",
      " Avg loss: 0.001479 \n",
      "\n",
      "Epoch 428\n",
      "-------------------------------\n",
      "Loss: 0.000089  [   64/ 7049]\n",
      "At step count 47398\n",
      "Loss: 0.000111  [ 6464/ 7049]\n",
      "At step count 47498\n",
      "Test Error: \n",
      " Avg loss: 0.001256 \n",
      "\n",
      "Epoch 429\n",
      "-------------------------------\n",
      "Loss: 0.000043  [   64/ 7049]\n",
      "At step count 47509\n",
      "Loss: 0.000074  [ 6464/ 7049]\n",
      "At step count 47609\n",
      "Test Error: \n",
      " Avg loss: 0.001408 \n",
      "\n",
      "Epoch 430\n",
      "-------------------------------\n",
      "Loss: 0.000066  [   64/ 7049]\n",
      "At step count 47620\n",
      "Loss: 0.000062  [ 6464/ 7049]\n",
      "At step count 47720\n",
      "Test Error: \n",
      " Avg loss: 0.001020 \n",
      "\n",
      "Epoch 431\n",
      "-------------------------------\n",
      "Loss: 0.000089  [   64/ 7049]\n",
      "At step count 47731\n",
      "Loss: 0.000170  [ 6464/ 7049]\n",
      "At step count 47831\n",
      "Test Error: \n",
      " Avg loss: 0.001311 \n",
      "\n",
      "Epoch 432\n",
      "-------------------------------\n",
      "Loss: 0.000081  [   64/ 7049]\n",
      "At step count 47842\n",
      "Loss: 0.000292  [ 6464/ 7049]\n",
      "At step count 47942\n",
      "Test Error: \n",
      " Avg loss: 0.000836 \n",
      "\n",
      "Epoch 433\n",
      "-------------------------------\n",
      "Loss: 0.000127  [   64/ 7049]\n",
      "At step count 47953\n",
      "Loss: 0.000140  [ 6464/ 7049]\n",
      "At step count 48053\n",
      "Test Error: \n",
      " Avg loss: 0.001070 \n",
      "\n",
      "Epoch 434\n",
      "-------------------------------\n",
      "Loss: 0.000108  [   64/ 7049]\n",
      "At step count 48064\n",
      "Loss: 0.000101  [ 6464/ 7049]\n",
      "At step count 48164\n",
      "Test Error: \n",
      " Avg loss: 0.000654 \n",
      "\n",
      "Epoch 435\n",
      "-------------------------------\n",
      "Loss: 0.000073  [   64/ 7049]\n",
      "At step count 48175\n",
      "Loss: 0.000116  [ 6464/ 7049]\n",
      "At step count 48275\n",
      "Test Error: \n",
      " Avg loss: 0.001020 \n",
      "\n",
      "Epoch 436\n",
      "-------------------------------\n",
      "Loss: 0.000104  [   64/ 7049]\n",
      "At step count 48286\n",
      "Loss: 0.000087  [ 6464/ 7049]\n",
      "At step count 48386\n",
      "Test Error: \n",
      " Avg loss: 0.001063 \n",
      "\n",
      "Epoch 437\n",
      "-------------------------------\n",
      "Loss: 0.000100  [   64/ 7049]\n",
      "At step count 48397\n",
      "Loss: 0.000116  [ 6464/ 7049]\n",
      "At step count 48497\n",
      "Test Error: \n",
      " Avg loss: 0.001569 \n",
      "\n",
      "Epoch 438\n",
      "-------------------------------\n",
      "Loss: 0.000081  [   64/ 7049]\n",
      "At step count 48508\n",
      "Loss: 0.000062  [ 6464/ 7049]\n",
      "At step count 48608\n",
      "Test Error: \n",
      " Avg loss: 0.001406 \n",
      "\n",
      "Epoch 439\n",
      "-------------------------------\n",
      "Loss: 0.000052  [   64/ 7049]\n",
      "At step count 48619\n",
      "Loss: 0.000078  [ 6464/ 7049]\n",
      "At step count 48719\n",
      "Test Error: \n",
      " Avg loss: 0.001356 \n",
      "\n",
      "Epoch 440\n",
      "-------------------------------\n",
      "Loss: 0.000077  [   64/ 7049]\n",
      "At step count 48730\n",
      "Loss: 0.000069  [ 6464/ 7049]\n",
      "At step count 48830\n",
      "Test Error: \n",
      " Avg loss: 0.001289 \n",
      "\n",
      "Epoch 441\n",
      "-------------------------------\n",
      "Loss: 0.000076  [   64/ 7049]\n",
      "At step count 48841\n",
      "Loss: 0.000047  [ 6464/ 7049]\n",
      "At step count 48941\n",
      "Test Error: \n",
      " Avg loss: 0.000156 \n",
      "\n",
      "Epoch 442\n",
      "-------------------------------\n",
      "Loss: 0.000084  [   64/ 7049]\n",
      "At step count 48952\n",
      "Loss: 0.000115  [ 6464/ 7049]\n",
      "At step count 49052\n",
      "Test Error: \n",
      " Avg loss: 0.000963 \n",
      "\n",
      "Epoch 443\n",
      "-------------------------------\n",
      "Loss: 0.000132  [   64/ 7049]\n",
      "At step count 49063\n",
      "Loss: 0.000076  [ 6464/ 7049]\n",
      "At step count 49163\n",
      "Test Error: \n",
      " Avg loss: 0.000874 \n",
      "\n",
      "Epoch 444\n",
      "-------------------------------\n",
      "Loss: 0.000061  [   64/ 7049]\n",
      "At step count 49174\n",
      "Loss: 0.000147  [ 6464/ 7049]\n",
      "At step count 49274\n",
      "Test Error: \n",
      " Avg loss: 0.001079 \n",
      "\n",
      "Epoch 445\n",
      "-------------------------------\n",
      "Loss: 0.000083  [   64/ 7049]\n",
      "At step count 49285\n",
      "Loss: 0.000158  [ 6464/ 7049]\n",
      "At step count 49385\n",
      "Test Error: \n",
      " Avg loss: 0.000538 \n",
      "\n",
      "Epoch 446\n",
      "-------------------------------\n",
      "Loss: 0.000067  [   64/ 7049]\n",
      "At step count 49396\n",
      "Loss: 0.000285  [ 6464/ 7049]\n",
      "At step count 49496\n",
      "Test Error: \n",
      " Avg loss: 0.000630 \n",
      "\n",
      "Epoch 447\n",
      "-------------------------------\n",
      "Loss: 0.000071  [   64/ 7049]\n",
      "At step count 49507\n",
      "Loss: 0.000080  [ 6464/ 7049]\n",
      "At step count 49607\n",
      "Test Error: \n",
      " Avg loss: 0.001445 \n",
      "\n",
      "Epoch 448\n",
      "-------------------------------\n",
      "Loss: 0.000062  [   64/ 7049]\n",
      "At step count 49618\n",
      "Loss: 0.000048  [ 6464/ 7049]\n",
      "At step count 49718\n",
      "Test Error: \n",
      " Avg loss: 0.001814 \n",
      "\n",
      "Epoch 449\n",
      "-------------------------------\n",
      "Loss: 0.000073  [   64/ 7049]\n",
      "At step count 49729\n",
      "Loss: 0.000104  [ 6464/ 7049]\n",
      "At step count 49829\n",
      "Test Error: \n",
      " Avg loss: 0.001609 \n",
      "\n",
      "Epoch 450\n",
      "-------------------------------\n",
      "Loss: 0.000049  [   64/ 7049]\n",
      "At step count 49840\n",
      "Loss: 0.000184  [ 6464/ 7049]\n",
      "At step count 49940\n",
      "Test Error: \n",
      " Avg loss: 0.001160 \n",
      "\n",
      "Epoch 451\n",
      "-------------------------------\n",
      "Loss: 0.000074  [   64/ 7049]\n",
      "At step count 49951\n",
      "Loss: 0.000114  [ 6464/ 7049]\n",
      "At step count 50051\n",
      "Test Error: \n",
      " Avg loss: 0.001011 \n",
      "\n",
      "Epoch 452\n",
      "-------------------------------\n",
      "Loss: 0.000068  [   64/ 7049]\n",
      "At step count 50062\n",
      "Loss: 0.000076  [ 6464/ 7049]\n",
      "At step count 50162\n",
      "Test Error: \n",
      " Avg loss: 0.000761 \n",
      "\n",
      "Epoch 453\n",
      "-------------------------------\n",
      "Loss: 0.000065  [   64/ 7049]\n",
      "At step count 50173\n",
      "Loss: 0.000242  [ 6464/ 7049]\n",
      "At step count 50273\n",
      "Test Error: \n",
      " Avg loss: 0.000711 \n",
      "\n",
      "Epoch 454\n",
      "-------------------------------\n",
      "Loss: 0.000082  [   64/ 7049]\n",
      "At step count 50284\n",
      "Loss: 0.000126  [ 6464/ 7049]\n",
      "At step count 50384\n",
      "Test Error: \n",
      " Avg loss: 0.000853 \n",
      "\n",
      "Epoch 455\n",
      "-------------------------------\n",
      "Loss: 0.000065  [   64/ 7049]\n",
      "At step count 50395\n",
      "Loss: 0.000168  [ 6464/ 7049]\n",
      "At step count 50495\n",
      "Test Error: \n",
      " Avg loss: 0.001326 \n",
      "\n",
      "Epoch 456\n",
      "-------------------------------\n",
      "Loss: 0.000080  [   64/ 7049]\n",
      "At step count 50506\n",
      "Loss: 0.000099  [ 6464/ 7049]\n",
      "At step count 50606\n",
      "Test Error: \n",
      " Avg loss: 0.000862 \n",
      "\n",
      "Epoch 457\n",
      "-------------------------------\n",
      "Loss: 0.000418  [   64/ 7049]\n",
      "At step count 50617\n",
      "Loss: 0.000094  [ 6464/ 7049]\n",
      "At step count 50717\n",
      "Test Error: \n",
      " Avg loss: 0.001170 \n",
      "\n",
      "Epoch 458\n",
      "-------------------------------\n",
      "Loss: 0.000052  [   64/ 7049]\n",
      "At step count 50728\n",
      "Loss: 0.000181  [ 6464/ 7049]\n",
      "At step count 50828\n",
      "Test Error: \n",
      " Avg loss: 0.000755 \n",
      "\n",
      "Epoch 459\n",
      "-------------------------------\n",
      "Loss: 0.000075  [   64/ 7049]\n",
      "At step count 50839\n",
      "Loss: 0.000045  [ 6464/ 7049]\n",
      "At step count 50939\n",
      "Test Error: \n",
      " Avg loss: 0.000619 \n",
      "\n",
      "Epoch 460\n",
      "-------------------------------\n",
      "Loss: 0.000143  [   64/ 7049]\n",
      "At step count 50950\n",
      "Loss: 0.000194  [ 6464/ 7049]\n",
      "At step count 51050\n",
      "Test Error: \n",
      " Avg loss: 0.000754 \n",
      "\n",
      "Epoch 461\n",
      "-------------------------------\n",
      "Loss: 0.000071  [   64/ 7049]\n",
      "At step count 51061\n",
      "Loss: 0.000116  [ 6464/ 7049]\n",
      "At step count 51161\n",
      "Test Error: \n",
      " Avg loss: 0.001119 \n",
      "\n",
      "Epoch 462\n",
      "-------------------------------\n",
      "Loss: 0.000048  [   64/ 7049]\n",
      "At step count 51172\n",
      "Loss: 0.000092  [ 6464/ 7049]\n",
      "At step count 51272\n",
      "Test Error: \n",
      " Avg loss: 0.000743 \n",
      "\n",
      "Epoch 463\n",
      "-------------------------------\n",
      "Loss: 0.000070  [   64/ 7049]\n",
      "At step count 51283\n",
      "Loss: 0.000495  [ 6464/ 7049]\n",
      "At step count 51383\n",
      "Test Error: \n",
      " Avg loss: 0.001000 \n",
      "\n",
      "Epoch 464\n",
      "-------------------------------\n",
      "Loss: 0.000081  [   64/ 7049]\n",
      "At step count 51394\n",
      "Loss: 0.000063  [ 6464/ 7049]\n",
      "At step count 51494\n",
      "Test Error: \n",
      " Avg loss: 0.000849 \n",
      "\n",
      "Epoch 465\n",
      "-------------------------------\n",
      "Loss: 0.000039  [   64/ 7049]\n",
      "At step count 51505\n",
      "Loss: 0.000071  [ 6464/ 7049]\n",
      "At step count 51605\n",
      "Test Error: \n",
      " Avg loss: 0.001533 \n",
      "\n",
      "Epoch 466\n",
      "-------------------------------\n",
      "Loss: 0.000059  [   64/ 7049]\n",
      "At step count 51616\n",
      "Loss: 0.000053  [ 6464/ 7049]\n",
      "At step count 51716\n",
      "Test Error: \n",
      " Avg loss: 0.001510 \n",
      "\n",
      "Epoch 467\n",
      "-------------------------------\n",
      "Loss: 0.000179  [   64/ 7049]\n",
      "At step count 51727\n",
      "Loss: 0.000070  [ 6464/ 7049]\n",
      "At step count 51827\n",
      "Test Error: \n",
      " Avg loss: 0.001156 \n",
      "\n",
      "Epoch 468\n",
      "-------------------------------\n",
      "Loss: 0.000304  [   64/ 7049]\n",
      "At step count 51838\n",
      "Loss: 0.000108  [ 6464/ 7049]\n",
      "At step count 51938\n",
      "Test Error: \n",
      " Avg loss: 0.000971 \n",
      "\n",
      "Epoch 469\n",
      "-------------------------------\n",
      "Loss: 0.000063  [   64/ 7049]\n",
      "At step count 51949\n",
      "Loss: 0.000060  [ 6464/ 7049]\n",
      "At step count 52049\n",
      "Test Error: \n",
      " Avg loss: 0.001887 \n",
      "\n",
      "Epoch 470\n",
      "-------------------------------\n",
      "Loss: 0.000602  [   64/ 7049]\n",
      "At step count 52060\n",
      "Loss: 0.000062  [ 6464/ 7049]\n",
      "At step count 52160\n",
      "Test Error: \n",
      " Avg loss: 0.000862 \n",
      "\n",
      "Epoch 471\n",
      "-------------------------------\n",
      "Loss: 0.000094  [   64/ 7049]\n",
      "At step count 52171\n",
      "Loss: 0.000214  [ 6464/ 7049]\n",
      "At step count 52271\n",
      "Test Error: \n",
      " Avg loss: 0.000939 \n",
      "\n",
      "Epoch 472\n",
      "-------------------------------\n",
      "Loss: 0.000077  [   64/ 7049]\n",
      "At step count 52282\n",
      "Loss: 0.000090  [ 6464/ 7049]\n",
      "At step count 52382\n",
      "Test Error: \n",
      " Avg loss: 0.001489 \n",
      "\n",
      "Epoch 473\n",
      "-------------------------------\n",
      "Loss: 0.000092  [   64/ 7049]\n",
      "At step count 52393\n",
      "Loss: 0.000082  [ 6464/ 7049]\n",
      "At step count 52493\n",
      "Test Error: \n",
      " Avg loss: 0.001627 \n",
      "\n",
      "Epoch 474\n",
      "-------------------------------\n",
      "Loss: 0.000145  [   64/ 7049]\n",
      "At step count 52504\n",
      "Loss: 0.000073  [ 6464/ 7049]\n",
      "At step count 52604\n",
      "Test Error: \n",
      " Avg loss: 0.000969 \n",
      "\n",
      "Epoch 475\n",
      "-------------------------------\n",
      "Loss: 0.000066  [   64/ 7049]\n",
      "At step count 52615\n",
      "Loss: 0.000088  [ 6464/ 7049]\n",
      "At step count 52715\n",
      "Test Error: \n",
      " Avg loss: 0.000931 \n",
      "\n",
      "Epoch 476\n",
      "-------------------------------\n",
      "Loss: 0.000077  [   64/ 7049]\n",
      "At step count 52726\n",
      "Loss: 0.000085  [ 6464/ 7049]\n",
      "At step count 52826\n",
      "Test Error: \n",
      " Avg loss: 0.000915 \n",
      "\n",
      "Epoch 477\n",
      "-------------------------------\n",
      "Loss: 0.000134  [   64/ 7049]\n",
      "At step count 52837\n",
      "Loss: 0.000062  [ 6464/ 7049]\n",
      "At step count 52937\n",
      "Test Error: \n",
      " Avg loss: 0.000968 \n",
      "\n",
      "Epoch 478\n",
      "-------------------------------\n",
      "Loss: 0.000066  [   64/ 7049]\n",
      "At step count 52948\n",
      "Loss: 0.000048  [ 6464/ 7049]\n",
      "At step count 53048\n",
      "Test Error: \n",
      " Avg loss: 0.000517 \n",
      "\n",
      "Epoch 479\n",
      "-------------------------------\n",
      "Loss: 0.000092  [   64/ 7049]\n",
      "At step count 53059\n",
      "Loss: 0.000059  [ 6464/ 7049]\n",
      "At step count 53159\n",
      "Test Error: \n",
      " Avg loss: 0.000906 \n",
      "\n",
      "Epoch 480\n",
      "-------------------------------\n",
      "Loss: 0.000077  [   64/ 7049]\n",
      "At step count 53170\n",
      "Loss: 0.000092  [ 6464/ 7049]\n",
      "At step count 53270\n",
      "Test Error: \n",
      " Avg loss: 0.000969 \n",
      "\n",
      "Epoch 481\n",
      "-------------------------------\n",
      "Loss: 0.000118  [   64/ 7049]\n",
      "At step count 53281\n",
      "Loss: 0.000200  [ 6464/ 7049]\n",
      "At step count 53381\n",
      "Test Error: \n",
      " Avg loss: 0.001683 \n",
      "\n",
      "Epoch 482\n",
      "-------------------------------\n",
      "Loss: 0.000061  [   64/ 7049]\n",
      "At step count 53392\n",
      "Loss: 0.000116  [ 6464/ 7049]\n",
      "At step count 53492\n",
      "Test Error: \n",
      " Avg loss: 0.002085 \n",
      "\n",
      "Epoch 483\n",
      "-------------------------------\n",
      "Loss: 0.000098  [   64/ 7049]\n",
      "At step count 53503\n",
      "Loss: 0.000186  [ 6464/ 7049]\n",
      "At step count 53603\n",
      "Test Error: \n",
      " Avg loss: 0.001258 \n",
      "\n",
      "Epoch 484\n",
      "-------------------------------\n",
      "Loss: 0.000134  [   64/ 7049]\n",
      "At step count 53614\n",
      "Loss: 0.000052  [ 6464/ 7049]\n",
      "At step count 53714\n",
      "Test Error: \n",
      " Avg loss: 0.000856 \n",
      "\n",
      "Epoch 485\n",
      "-------------------------------\n",
      "Loss: 0.000054  [   64/ 7049]\n",
      "At step count 53725\n",
      "Loss: 0.000076  [ 6464/ 7049]\n",
      "At step count 53825\n",
      "Test Error: \n",
      " Avg loss: 0.001655 \n",
      "\n",
      "Epoch 486\n",
      "-------------------------------\n",
      "Loss: 0.000063  [   64/ 7049]\n",
      "At step count 53836\n",
      "Loss: 0.000107  [ 6464/ 7049]\n",
      "At step count 53936\n",
      "Test Error: \n",
      " Avg loss: 0.000883 \n",
      "\n",
      "Epoch 487\n",
      "-------------------------------\n",
      "Loss: 0.000091  [   64/ 7049]\n",
      "At step count 53947\n",
      "Loss: 0.000086  [ 6464/ 7049]\n",
      "At step count 54047\n",
      "Test Error: \n",
      " Avg loss: 0.000665 \n",
      "\n",
      "Epoch 488\n",
      "-------------------------------\n",
      "Loss: 0.000084  [   64/ 7049]\n",
      "At step count 54058\n",
      "Loss: 0.000122  [ 6464/ 7049]\n",
      "At step count 54158\n",
      "Test Error: \n",
      " Avg loss: 0.001584 \n",
      "\n",
      "Epoch 489\n",
      "-------------------------------\n",
      "Loss: 0.000071  [   64/ 7049]\n",
      "At step count 54169\n",
      "Loss: 0.000106  [ 6464/ 7049]\n",
      "At step count 54269\n",
      "Test Error: \n",
      " Avg loss: 0.001091 \n",
      "\n",
      "Epoch 490\n",
      "-------------------------------\n",
      "Loss: 0.000081  [   64/ 7049]\n",
      "At step count 54280\n",
      "Loss: 0.000481  [ 6464/ 7049]\n",
      "At step count 54380\n",
      "Test Error: \n",
      " Avg loss: 0.000853 \n",
      "\n",
      "Epoch 491\n",
      "-------------------------------\n",
      "Loss: 0.000070  [   64/ 7049]\n",
      "At step count 54391\n",
      "Loss: 0.000079  [ 6464/ 7049]\n",
      "At step count 54491\n",
      "Test Error: \n",
      " Avg loss: 0.001025 \n",
      "\n",
      "Epoch 492\n",
      "-------------------------------\n",
      "Loss: 0.000051  [   64/ 7049]\n",
      "At step count 54502\n",
      "Loss: 0.000084  [ 6464/ 7049]\n",
      "At step count 54602\n",
      "Test Error: \n",
      " Avg loss: 0.001169 \n",
      "\n",
      "Epoch 493\n",
      "-------------------------------\n",
      "Loss: 0.000082  [   64/ 7049]\n",
      "At step count 54613\n",
      "Loss: 0.000056  [ 6464/ 7049]\n",
      "At step count 54713\n",
      "Test Error: \n",
      " Avg loss: 0.001344 \n",
      "\n",
      "Epoch 494\n",
      "-------------------------------\n",
      "Loss: 0.000059  [   64/ 7049]\n",
      "At step count 54724\n",
      "Loss: 0.000058  [ 6464/ 7049]\n",
      "At step count 54824\n",
      "Test Error: \n",
      " Avg loss: 0.001580 \n",
      "\n",
      "Epoch 495\n",
      "-------------------------------\n",
      "Loss: 0.000175  [   64/ 7049]\n",
      "At step count 54835\n",
      "Loss: 0.001181  [ 6464/ 7049]\n",
      "At step count 54935\n",
      "Test Error: \n",
      " Avg loss: 0.001544 \n",
      "\n",
      "Epoch 496\n",
      "-------------------------------\n",
      "Loss: 0.000193  [   64/ 7049]\n",
      "At step count 54946\n",
      "Loss: 0.000102  [ 6464/ 7049]\n",
      "At step count 55046\n",
      "Test Error: \n",
      " Avg loss: 0.000799 \n",
      "\n",
      "Epoch 497\n",
      "-------------------------------\n",
      "Loss: 0.000044  [   64/ 7049]\n",
      "At step count 55057\n",
      "Loss: 0.000097  [ 6464/ 7049]\n",
      "At step count 55157\n",
      "Test Error: \n",
      " Avg loss: 0.000633 \n",
      "\n",
      "Epoch 498\n",
      "-------------------------------\n",
      "Loss: 0.000051  [   64/ 7049]\n",
      "At step count 55168\n",
      "Loss: 0.000098  [ 6464/ 7049]\n",
      "At step count 55268\n",
      "Test Error: \n",
      " Avg loss: 0.000621 \n",
      "\n",
      "Epoch 499\n",
      "-------------------------------\n",
      "Loss: 0.000097  [   64/ 7049]\n",
      "At step count 55279\n",
      "Loss: 0.000149  [ 6464/ 7049]\n",
      "At step count 55379\n",
      "Test Error: \n",
      " Avg loss: 0.001011 \n",
      "\n",
      "Epoch 500\n",
      "-------------------------------\n",
      "Loss: 0.000063  [   64/ 7049]\n",
      "At step count 55390\n",
      "Loss: 0.000060  [ 6464/ 7049]\n",
      "At step count 55490\n",
      "Test Error: \n",
      " Avg loss: 0.001014 \n",
      "\n",
      "Epoch 501\n",
      "-------------------------------\n",
      "Loss: 0.000180  [   64/ 7049]\n",
      "At step count 55501\n",
      "Loss: 0.000075  [ 6464/ 7049]\n",
      "At step count 55601\n",
      "Test Error: \n",
      " Avg loss: 0.001106 \n",
      "\n",
      "Epoch 502\n",
      "-------------------------------\n",
      "Loss: 0.000050  [   64/ 7049]\n",
      "At step count 55612\n",
      "Loss: 0.000066  [ 6464/ 7049]\n",
      "At step count 55712\n",
      "Test Error: \n",
      " Avg loss: 0.000942 \n",
      "\n",
      "Epoch 503\n",
      "-------------------------------\n",
      "Loss: 0.000079  [   64/ 7049]\n",
      "At step count 55723\n",
      "Loss: 0.000082  [ 6464/ 7049]\n",
      "At step count 55823\n",
      "Test Error: \n",
      " Avg loss: 0.000621 \n",
      "\n",
      "Epoch 504\n",
      "-------------------------------\n",
      "Loss: 0.000171  [   64/ 7049]\n",
      "At step count 55834\n",
      "Loss: 0.000062  [ 6464/ 7049]\n",
      "At step count 55934\n",
      "Test Error: \n",
      " Avg loss: 0.001505 \n",
      "\n",
      "Epoch 505\n",
      "-------------------------------\n",
      "Loss: 0.000069  [   64/ 7049]\n",
      "At step count 55945\n",
      "Loss: 0.000069  [ 6464/ 7049]\n",
      "At step count 56045\n",
      "Test Error: \n",
      " Avg loss: 0.000902 \n",
      "\n",
      "Epoch 506\n",
      "-------------------------------\n",
      "Loss: 0.000086  [   64/ 7049]\n",
      "At step count 56056\n",
      "Loss: 0.000056  [ 6464/ 7049]\n",
      "At step count 56156\n",
      "Test Error: \n",
      " Avg loss: 0.001357 \n",
      "\n",
      "Epoch 507\n",
      "-------------------------------\n",
      "Loss: 0.000055  [   64/ 7049]\n",
      "At step count 56167\n",
      "Loss: 0.000125  [ 6464/ 7049]\n",
      "At step count 56267\n",
      "Test Error: \n",
      " Avg loss: 0.000826 \n",
      "\n",
      "Epoch 508\n",
      "-------------------------------\n",
      "Loss: 0.000060  [   64/ 7049]\n",
      "At step count 56278\n",
      "Loss: 0.000071  [ 6464/ 7049]\n",
      "At step count 56378\n",
      "Test Error: \n",
      " Avg loss: 0.000608 \n",
      "\n",
      "Epoch 509\n",
      "-------------------------------\n",
      "Loss: 0.000166  [   64/ 7049]\n",
      "At step count 56389\n",
      "Loss: 0.000402  [ 6464/ 7049]\n",
      "At step count 56489\n",
      "Test Error: \n",
      " Avg loss: 0.000792 \n",
      "\n",
      "Epoch 510\n",
      "-------------------------------\n",
      "Loss: 0.000094  [   64/ 7049]\n",
      "At step count 56500\n",
      "Loss: 0.000303  [ 6464/ 7049]\n",
      "At step count 56600\n",
      "Test Error: \n",
      " Avg loss: 0.001476 \n",
      "\n",
      "Epoch 511\n",
      "-------------------------------\n",
      "Loss: 0.000058  [   64/ 7049]\n",
      "At step count 56611\n",
      "Loss: 0.000106  [ 6464/ 7049]\n",
      "At step count 56711\n",
      "Test Error: \n",
      " Avg loss: 0.001394 \n",
      "\n",
      "Epoch 512\n",
      "-------------------------------\n",
      "Loss: 0.000063  [   64/ 7049]\n",
      "At step count 56722\n",
      "Loss: 0.000065  [ 6464/ 7049]\n",
      "At step count 56822\n",
      "Test Error: \n",
      " Avg loss: 0.001893 \n",
      "\n",
      "Epoch 513\n",
      "-------------------------------\n",
      "Loss: 0.000077  [   64/ 7049]\n",
      "At step count 56833\n",
      "Loss: 0.000052  [ 6464/ 7049]\n",
      "At step count 56933\n",
      "Test Error: \n",
      " Avg loss: 0.000921 \n",
      "\n",
      "Epoch 514\n",
      "-------------------------------\n",
      "Loss: 0.000077  [   64/ 7049]\n",
      "At step count 56944\n",
      "Loss: 0.000050  [ 6464/ 7049]\n",
      "At step count 57044\n",
      "Test Error: \n",
      " Avg loss: 0.001149 \n",
      "\n",
      "Epoch 515\n",
      "-------------------------------\n",
      "Loss: 0.000097  [   64/ 7049]\n",
      "At step count 57055\n",
      "Loss: 0.000152  [ 6464/ 7049]\n",
      "At step count 57155\n",
      "Test Error: \n",
      " Avg loss: 0.001428 \n",
      "\n",
      "Epoch 516\n",
      "-------------------------------\n",
      "Loss: 0.000126  [   64/ 7049]\n",
      "At step count 57166\n",
      "Loss: 0.000066  [ 6464/ 7049]\n",
      "At step count 57266\n",
      "Test Error: \n",
      " Avg loss: 0.000620 \n",
      "\n",
      "Epoch 517\n",
      "-------------------------------\n",
      "Loss: 0.000057  [   64/ 7049]\n",
      "At step count 57277\n",
      "Loss: 0.000169  [ 6464/ 7049]\n",
      "At step count 57377\n",
      "Test Error: \n",
      " Avg loss: 0.001680 \n",
      "\n",
      "Epoch 518\n",
      "-------------------------------\n",
      "Loss: 0.000054  [   64/ 7049]\n",
      "At step count 57388\n",
      "Loss: 0.000038  [ 6464/ 7049]\n",
      "At step count 57488\n",
      "Test Error: \n",
      " Avg loss: 0.000711 \n",
      "\n",
      "Epoch 519\n",
      "-------------------------------\n",
      "Loss: 0.000076  [   64/ 7049]\n",
      "At step count 57499\n",
      "Loss: 0.000067  [ 6464/ 7049]\n",
      "At step count 57599\n",
      "Test Error: \n",
      " Avg loss: 0.001013 \n",
      "\n",
      "Epoch 520\n",
      "-------------------------------\n",
      "Loss: 0.000086  [   64/ 7049]\n",
      "At step count 57610\n",
      "Loss: 0.000539  [ 6464/ 7049]\n",
      "At step count 57710\n",
      "Test Error: \n",
      " Avg loss: 0.000931 \n",
      "\n",
      "Epoch 521\n",
      "-------------------------------\n",
      "Loss: 0.000052  [   64/ 7049]\n",
      "At step count 57721\n",
      "Loss: 0.000076  [ 6464/ 7049]\n",
      "At step count 57821\n",
      "Test Error: \n",
      " Avg loss: 0.001428 \n",
      "\n",
      "Epoch 522\n",
      "-------------------------------\n",
      "Loss: 0.000521  [   64/ 7049]\n",
      "At step count 57832\n",
      "Loss: 0.000069  [ 6464/ 7049]\n",
      "At step count 57932\n",
      "Test Error: \n",
      " Avg loss: 0.001604 \n",
      "\n",
      "Epoch 523\n",
      "-------------------------------\n",
      "Loss: 0.000056  [   64/ 7049]\n",
      "At step count 57943\n",
      "Loss: 0.000058  [ 6464/ 7049]\n",
      "At step count 58043\n",
      "Test Error: \n",
      " Avg loss: 0.000941 \n",
      "\n",
      "Epoch 524\n",
      "-------------------------------\n",
      "Loss: 0.000267  [   64/ 7049]\n",
      "At step count 58054\n",
      "Loss: 0.000073  [ 6464/ 7049]\n",
      "At step count 58154\n",
      "Test Error: \n",
      " Avg loss: 0.015270 \n",
      "\n",
      "Epoch 525\n",
      "-------------------------------\n",
      "Loss: 0.000091  [   64/ 7049]\n",
      "At step count 58165\n",
      "Loss: 0.000040  [ 6464/ 7049]\n",
      "At step count 58265\n",
      "Test Error: \n",
      " Avg loss: 0.001165 \n",
      "\n",
      "Epoch 526\n",
      "-------------------------------\n",
      "Loss: 0.000075  [   64/ 7049]\n",
      "At step count 58276\n",
      "Loss: 0.000111  [ 6464/ 7049]\n",
      "At step count 58376\n",
      "Test Error: \n",
      " Avg loss: 0.001517 \n",
      "\n",
      "Epoch 527\n",
      "-------------------------------\n",
      "Loss: 0.000167  [   64/ 7049]\n",
      "At step count 58387\n",
      "Loss: 0.000067  [ 6464/ 7049]\n",
      "At step count 58487\n",
      "Test Error: \n",
      " Avg loss: 0.000788 \n",
      "\n",
      "Epoch 528\n",
      "-------------------------------\n",
      "Loss: 0.000197  [   64/ 7049]\n",
      "At step count 58498\n",
      "Loss: 0.000070  [ 6464/ 7049]\n",
      "At step count 58598\n",
      "Test Error: \n",
      " Avg loss: 0.001670 \n",
      "\n",
      "Epoch 529\n",
      "-------------------------------\n",
      "Loss: 0.000065  [   64/ 7049]\n",
      "At step count 58609\n",
      "Loss: 0.000061  [ 6464/ 7049]\n",
      "At step count 58709\n",
      "Test Error: \n",
      " Avg loss: 0.001309 \n",
      "\n",
      "Epoch 530\n",
      "-------------------------------\n",
      "Loss: 0.000110  [   64/ 7049]\n",
      "At step count 58720\n",
      "Loss: 0.000074  [ 6464/ 7049]\n",
      "At step count 58820\n",
      "Test Error: \n",
      " Avg loss: 0.002040 \n",
      "\n",
      "Epoch 531\n",
      "-------------------------------\n",
      "Loss: 0.000044  [   64/ 7049]\n",
      "At step count 58831\n",
      "Loss: 0.000125  [ 6464/ 7049]\n",
      "At step count 58931\n",
      "Test Error: \n",
      " Avg loss: 0.001598 \n",
      "\n",
      "Epoch 532\n",
      "-------------------------------\n",
      "Loss: 0.000070  [   64/ 7049]\n",
      "At step count 58942\n",
      "Loss: 0.000082  [ 6464/ 7049]\n",
      "At step count 59042\n",
      "Test Error: \n",
      " Avg loss: 0.000778 \n",
      "\n",
      "Epoch 533\n",
      "-------------------------------\n",
      "Loss: 0.000036  [   64/ 7049]\n",
      "At step count 59053\n",
      "Loss: 0.000068  [ 6464/ 7049]\n",
      "At step count 59153\n",
      "Test Error: \n",
      " Avg loss: 0.001238 \n",
      "\n",
      "Epoch 534\n",
      "-------------------------------\n",
      "Loss: 0.000082  [   64/ 7049]\n",
      "At step count 59164\n",
      "Loss: 0.000530  [ 6464/ 7049]\n",
      "At step count 59264\n",
      "Test Error: \n",
      " Avg loss: 0.001011 \n",
      "\n",
      "Epoch 535\n",
      "-------------------------------\n",
      "Loss: 0.000113  [   64/ 7049]\n",
      "At step count 59275\n",
      "Loss: 0.000039  [ 6464/ 7049]\n",
      "At step count 59375\n",
      "Test Error: \n",
      " Avg loss: 0.001409 \n",
      "\n",
      "Epoch 536\n",
      "-------------------------------\n",
      "Loss: 0.000042  [   64/ 7049]\n",
      "At step count 59386\n",
      "Loss: 0.000046  [ 6464/ 7049]\n",
      "At step count 59486\n",
      "Test Error: \n",
      " Avg loss: 0.001939 \n",
      "\n",
      "Epoch 537\n",
      "-------------------------------\n",
      "Loss: 0.000919  [   64/ 7049]\n",
      "At step count 59497\n",
      "Loss: 0.000203  [ 6464/ 7049]\n",
      "At step count 59597\n",
      "Test Error: \n",
      " Avg loss: 0.001532 \n",
      "\n",
      "Epoch 538\n",
      "-------------------------------\n",
      "Loss: 0.000072  [   64/ 7049]\n",
      "At step count 59608\n",
      "Loss: 0.000078  [ 6464/ 7049]\n",
      "At step count 59708\n",
      "Test Error: \n",
      " Avg loss: 0.001419 \n",
      "\n",
      "Epoch 539\n",
      "-------------------------------\n",
      "Loss: 0.000069  [   64/ 7049]\n",
      "At step count 59719\n",
      "Loss: 0.000065  [ 6464/ 7049]\n",
      "At step count 59819\n",
      "Test Error: \n",
      " Avg loss: 0.000884 \n",
      "\n",
      "Epoch 540\n",
      "-------------------------------\n",
      "Loss: 0.000493  [   64/ 7049]\n",
      "At step count 59830\n",
      "Loss: 0.000198  [ 6464/ 7049]\n",
      "At step count 59930\n",
      "Test Error: \n",
      " Avg loss: 0.001292 \n",
      "\n",
      "Epoch 541\n",
      "-------------------------------\n",
      "Loss: 0.000184  [   64/ 7049]\n",
      "At step count 59941\n",
      "Loss: 0.000075  [ 6464/ 7049]\n",
      "At step count 60041\n",
      "Test Error: \n",
      " Avg loss: 0.001707 \n",
      "\n",
      "Epoch 542\n",
      "-------------------------------\n",
      "Loss: 0.000242  [   64/ 7049]\n",
      "At step count 60052\n",
      "Loss: 0.000089  [ 6464/ 7049]\n",
      "At step count 60152\n",
      "Test Error: \n",
      " Avg loss: 0.001627 \n",
      "\n",
      "Epoch 543\n",
      "-------------------------------\n",
      "Loss: 0.000064  [   64/ 7049]\n",
      "At step count 60163\n",
      "Loss: 0.000091  [ 6464/ 7049]\n",
      "At step count 60263\n",
      "Test Error: \n",
      " Avg loss: 0.001686 \n",
      "\n",
      "Epoch 544\n",
      "-------------------------------\n",
      "Loss: 0.000055  [   64/ 7049]\n",
      "At step count 60274\n",
      "Loss: 0.000060  [ 6464/ 7049]\n",
      "At step count 60374\n",
      "Test Error: \n",
      " Avg loss: 0.001047 \n",
      "\n",
      "Epoch 545\n",
      "-------------------------------\n",
      "Loss: 0.000060  [   64/ 7049]\n",
      "At step count 60385\n",
      "Loss: 0.000053  [ 6464/ 7049]\n",
      "At step count 60485\n",
      "Test Error: \n",
      " Avg loss: 0.001223 \n",
      "\n",
      "Epoch 546\n",
      "-------------------------------\n",
      "Loss: 0.000114  [   64/ 7049]\n",
      "At step count 60496\n",
      "Loss: 0.000171  [ 6464/ 7049]\n",
      "At step count 60596\n",
      "Test Error: \n",
      " Avg loss: 0.001367 \n",
      "\n",
      "Epoch 547\n",
      "-------------------------------\n",
      "Loss: 0.000118  [   64/ 7049]\n",
      "At step count 60607\n",
      "Loss: 0.000090  [ 6464/ 7049]\n",
      "At step count 60707\n",
      "Test Error: \n",
      " Avg loss: 0.001413 \n",
      "\n",
      "Epoch 548\n",
      "-------------------------------\n",
      "Loss: 0.000113  [   64/ 7049]\n",
      "At step count 60718\n",
      "Loss: 0.000085  [ 6464/ 7049]\n",
      "At step count 60818\n",
      "Test Error: \n",
      " Avg loss: 0.001731 \n",
      "\n",
      "Epoch 549\n",
      "-------------------------------\n",
      "Loss: 0.000066  [   64/ 7049]\n",
      "At step count 60829\n",
      "Loss: 0.000138  [ 6464/ 7049]\n",
      "At step count 60929\n",
      "Test Error: \n",
      " Avg loss: 0.001039 \n",
      "\n",
      "Epoch 550\n",
      "-------------------------------\n",
      "Loss: 0.000161  [   64/ 7049]\n",
      "At step count 60940\n",
      "Loss: 0.000065  [ 6464/ 7049]\n",
      "At step count 61040\n",
      "Test Error: \n",
      " Avg loss: 0.000987 \n",
      "\n",
      "Epoch 551\n",
      "-------------------------------\n",
      "Loss: 0.000085  [   64/ 7049]\n",
      "At step count 61051\n",
      "Loss: 0.000047  [ 6464/ 7049]\n",
      "At step count 61151\n",
      "Test Error: \n",
      " Avg loss: 0.001594 \n",
      "\n",
      "Epoch 552\n",
      "-------------------------------\n",
      "Loss: 0.000046  [   64/ 7049]\n",
      "At step count 61162\n",
      "Loss: 0.000084  [ 6464/ 7049]\n",
      "At step count 61262\n",
      "Test Error: \n",
      " Avg loss: 0.001266 \n",
      "\n",
      "Epoch 553\n",
      "-------------------------------\n",
      "Loss: 0.000049  [   64/ 7049]\n",
      "At step count 61273\n",
      "Loss: 0.000042  [ 6464/ 7049]\n",
      "At step count 61373\n",
      "Test Error: \n",
      " Avg loss: 0.000754 \n",
      "\n",
      "Epoch 554\n",
      "-------------------------------\n",
      "Loss: 0.000047  [   64/ 7049]\n",
      "At step count 61384\n",
      "Loss: 0.000057  [ 6464/ 7049]\n",
      "At step count 61484\n",
      "Test Error: \n",
      " Avg loss: 0.001324 \n",
      "\n",
      "Epoch 555\n",
      "-------------------------------\n",
      "Loss: 0.000063  [   64/ 7049]\n",
      "At step count 61495\n",
      "Loss: 0.000075  [ 6464/ 7049]\n",
      "At step count 61595\n",
      "Test Error: \n",
      " Avg loss: 0.001196 \n",
      "\n",
      "Epoch 556\n",
      "-------------------------------\n",
      "Loss: 0.000048  [   64/ 7049]\n",
      "At step count 61606\n",
      "Loss: 0.000062  [ 6464/ 7049]\n",
      "At step count 61706\n",
      "Test Error: \n",
      " Avg loss: 0.001043 \n",
      "\n",
      "Epoch 557\n",
      "-------------------------------\n",
      "Loss: 0.000084  [   64/ 7049]\n",
      "At step count 61717\n",
      "Loss: 0.000751  [ 6464/ 7049]\n",
      "At step count 61817\n",
      "Test Error: \n",
      " Avg loss: 0.001387 \n",
      "\n",
      "Epoch 558\n",
      "-------------------------------\n",
      "Loss: 0.000061  [   64/ 7049]\n",
      "At step count 61828\n",
      "Loss: 0.000081  [ 6464/ 7049]\n",
      "At step count 61928\n",
      "Test Error: \n",
      " Avg loss: 0.001340 \n",
      "\n",
      "Epoch 559\n",
      "-------------------------------\n",
      "Loss: 0.000135  [   64/ 7049]\n",
      "At step count 61939\n",
      "Loss: 0.000109  [ 6464/ 7049]\n",
      "At step count 62039\n",
      "Test Error: \n",
      " Avg loss: 0.001166 \n",
      "\n",
      "Epoch 560\n",
      "-------------------------------\n",
      "Loss: 0.000057  [   64/ 7049]\n",
      "At step count 62050\n",
      "Loss: 0.000051  [ 6464/ 7049]\n",
      "At step count 62150\n",
      "Test Error: \n",
      " Avg loss: 0.001154 \n",
      "\n",
      "Epoch 561\n",
      "-------------------------------\n",
      "Loss: 0.000036  [   64/ 7049]\n",
      "At step count 62161\n",
      "Loss: 0.000055  [ 6464/ 7049]\n",
      "At step count 62261\n",
      "Test Error: \n",
      " Avg loss: 0.001545 \n",
      "\n",
      "Epoch 562\n",
      "-------------------------------\n",
      "Loss: 0.000046  [   64/ 7049]\n",
      "At step count 62272\n",
      "Loss: 0.000100  [ 6464/ 7049]\n",
      "At step count 62372\n",
      "Test Error: \n",
      " Avg loss: 0.000804 \n",
      "\n",
      "Epoch 563\n",
      "-------------------------------\n",
      "Loss: 0.000061  [   64/ 7049]\n",
      "At step count 62383\n",
      "Loss: 0.000212  [ 6464/ 7049]\n",
      "At step count 62483\n",
      "Test Error: \n",
      " Avg loss: 0.001061 \n",
      "\n",
      "Epoch 564\n",
      "-------------------------------\n",
      "Loss: 0.000102  [   64/ 7049]\n",
      "At step count 62494\n",
      "Loss: 0.000065  [ 6464/ 7049]\n",
      "At step count 62594\n",
      "Test Error: \n",
      " Avg loss: 0.000846 \n",
      "\n",
      "Epoch 565\n",
      "-------------------------------\n",
      "Loss: 0.000061  [   64/ 7049]\n",
      "At step count 62605\n",
      "Loss: 0.000070  [ 6464/ 7049]\n",
      "At step count 62705\n",
      "Test Error: \n",
      " Avg loss: 0.001887 \n",
      "\n",
      "Epoch 566\n",
      "-------------------------------\n",
      "Loss: 0.000152  [   64/ 7049]\n",
      "At step count 62716\n",
      "Loss: 0.000053  [ 6464/ 7049]\n",
      "At step count 62816\n",
      "Test Error: \n",
      " Avg loss: 0.001037 \n",
      "\n",
      "Epoch 567\n",
      "-------------------------------\n",
      "Loss: 0.000366  [   64/ 7049]\n",
      "At step count 62827\n",
      "Loss: 0.000115  [ 6464/ 7049]\n",
      "At step count 62927\n",
      "Test Error: \n",
      " Avg loss: 0.001992 \n",
      "\n",
      "Epoch 568\n",
      "-------------------------------\n",
      "Loss: 0.000045  [   64/ 7049]\n",
      "At step count 62938\n",
      "Loss: 0.000061  [ 6464/ 7049]\n",
      "At step count 63038\n",
      "Test Error: \n",
      " Avg loss: 0.001091 \n",
      "\n",
      "Epoch 569\n",
      "-------------------------------\n",
      "Loss: 0.000068  [   64/ 7049]\n",
      "At step count 63049\n",
      "Loss: 0.000061  [ 6464/ 7049]\n",
      "At step count 63149\n",
      "Test Error: \n",
      " Avg loss: 0.000829 \n",
      "\n",
      "Epoch 570\n",
      "-------------------------------\n",
      "Loss: 0.000066  [   64/ 7049]\n",
      "At step count 63160\n",
      "Loss: 0.000084  [ 6464/ 7049]\n",
      "At step count 63260\n",
      "Test Error: \n",
      " Avg loss: 0.001595 \n",
      "\n",
      "Epoch 571\n",
      "-------------------------------\n",
      "Loss: 0.000125  [   64/ 7049]\n",
      "At step count 63271\n",
      "Loss: 0.000150  [ 6464/ 7049]\n",
      "At step count 63371\n",
      "Test Error: \n",
      " Avg loss: 0.001097 \n",
      "\n",
      "Epoch 572\n",
      "-------------------------------\n",
      "Loss: 0.000046  [   64/ 7049]\n",
      "At step count 63382\n",
      "Loss: 0.000063  [ 6464/ 7049]\n",
      "At step count 63482\n",
      "Test Error: \n",
      " Avg loss: 0.001433 \n",
      "\n",
      "Epoch 573\n",
      "-------------------------------\n",
      "Loss: 0.000122  [   64/ 7049]\n",
      "At step count 63493\n",
      "Loss: 0.000089  [ 6464/ 7049]\n",
      "At step count 63593\n",
      "Test Error: \n",
      " Avg loss: 0.000820 \n",
      "\n",
      "Epoch 574\n",
      "-------------------------------\n",
      "Loss: 0.000063  [   64/ 7049]\n",
      "At step count 63604\n",
      "Loss: 0.000147  [ 6464/ 7049]\n",
      "At step count 63704\n",
      "Test Error: \n",
      " Avg loss: 0.000925 \n",
      "\n",
      "Epoch 575\n",
      "-------------------------------\n",
      "Loss: 0.000086  [   64/ 7049]\n",
      "At step count 63715\n",
      "Loss: 0.000045  [ 6464/ 7049]\n",
      "At step count 63815\n",
      "Test Error: \n",
      " Avg loss: 0.000975 \n",
      "\n",
      "Epoch 576\n",
      "-------------------------------\n",
      "Loss: 0.000114  [   64/ 7049]\n",
      "At step count 63826\n",
      "Loss: 0.000059  [ 6464/ 7049]\n",
      "At step count 63926\n",
      "Test Error: \n",
      " Avg loss: 0.000970 \n",
      "\n",
      "Epoch 577\n",
      "-------------------------------\n",
      "Loss: 0.000264  [   64/ 7049]\n",
      "At step count 63937\n",
      "Loss: 0.000068  [ 6464/ 7049]\n",
      "At step count 64037\n",
      "Test Error: \n",
      " Avg loss: 0.000877 \n",
      "\n",
      "Epoch 578\n",
      "-------------------------------\n",
      "Loss: 0.000089  [   64/ 7049]\n",
      "At step count 64048\n",
      "Loss: 0.000053  [ 6464/ 7049]\n",
      "At step count 64148\n",
      "Test Error: \n",
      " Avg loss: 0.000861 \n",
      "\n",
      "Epoch 579\n",
      "-------------------------------\n",
      "Loss: 0.000109  [   64/ 7049]\n",
      "At step count 64159\n",
      "Loss: 0.000051  [ 6464/ 7049]\n",
      "At step count 64259\n",
      "Test Error: \n",
      " Avg loss: 0.000702 \n",
      "\n",
      "Epoch 580\n",
      "-------------------------------\n",
      "Loss: 0.000059  [   64/ 7049]\n",
      "At step count 64270\n",
      "Loss: 0.000069  [ 6464/ 7049]\n",
      "At step count 64370\n",
      "Test Error: \n",
      " Avg loss: 0.001212 \n",
      "\n",
      "Epoch 581\n",
      "-------------------------------\n",
      "Loss: 0.000171  [   64/ 7049]\n",
      "At step count 64381\n",
      "Loss: 0.000087  [ 6464/ 7049]\n",
      "At step count 64481\n",
      "Test Error: \n",
      " Avg loss: 0.000720 \n",
      "\n",
      "Epoch 582\n",
      "-------------------------------\n",
      "Loss: 0.000089  [   64/ 7049]\n",
      "At step count 64492\n",
      "Loss: 0.000038  [ 6464/ 7049]\n",
      "At step count 64592\n",
      "Test Error: \n",
      " Avg loss: 0.001918 \n",
      "\n",
      "Epoch 583\n",
      "-------------------------------\n",
      "Loss: 0.000062  [   64/ 7049]\n",
      "At step count 64603\n",
      "Loss: 0.000054  [ 6464/ 7049]\n",
      "At step count 64703\n",
      "Test Error: \n",
      " Avg loss: 0.000588 \n",
      "\n",
      "Epoch 584\n",
      "-------------------------------\n",
      "Loss: 0.000063  [   64/ 7049]\n",
      "At step count 64714\n",
      "Loss: 0.000065  [ 6464/ 7049]\n",
      "At step count 64814\n",
      "Test Error: \n",
      " Avg loss: 0.001048 \n",
      "\n",
      "Epoch 585\n",
      "-------------------------------\n",
      "Loss: 0.000063  [   64/ 7049]\n",
      "At step count 64825\n",
      "Loss: 0.000050  [ 6464/ 7049]\n",
      "At step count 64925\n",
      "Test Error: \n",
      " Avg loss: 0.000795 \n",
      "\n",
      "Epoch 586\n",
      "-------------------------------\n",
      "Loss: 0.000061  [   64/ 7049]\n",
      "At step count 64936\n",
      "Loss: 0.000072  [ 6464/ 7049]\n",
      "At step count 65036\n",
      "Test Error: \n",
      " Avg loss: 0.000590 \n",
      "\n",
      "Epoch 587\n",
      "-------------------------------\n",
      "Loss: 0.000071  [   64/ 7049]\n",
      "At step count 65047\n",
      "Loss: 0.000066  [ 6464/ 7049]\n",
      "At step count 65147\n",
      "Test Error: \n",
      " Avg loss: 0.001384 \n",
      "\n",
      "Epoch 588\n",
      "-------------------------------\n",
      "Loss: 0.000083  [   64/ 7049]\n",
      "At step count 65158\n",
      "Loss: 0.000063  [ 6464/ 7049]\n",
      "At step count 65258\n",
      "Test Error: \n",
      " Avg loss: 0.001668 \n",
      "\n",
      "Epoch 589\n",
      "-------------------------------\n",
      "Loss: 0.000071  [   64/ 7049]\n",
      "At step count 65269\n",
      "Loss: 0.000878  [ 6464/ 7049]\n",
      "At step count 65369\n",
      "Test Error: \n",
      " Avg loss: 0.000809 \n",
      "\n",
      "Epoch 590\n",
      "-------------------------------\n",
      "Loss: 0.000046  [   64/ 7049]\n",
      "At step count 65380\n",
      "Loss: 0.000713  [ 6464/ 7049]\n",
      "At step count 65480\n",
      "Test Error: \n",
      " Avg loss: 0.001504 \n",
      "\n",
      "Epoch 591\n",
      "-------------------------------\n",
      "Loss: 0.000064  [   64/ 7049]\n",
      "At step count 65491\n",
      "Loss: 0.000060  [ 6464/ 7049]\n",
      "At step count 65591\n",
      "Test Error: \n",
      " Avg loss: 0.001339 \n",
      "\n",
      "Epoch 592\n",
      "-------------------------------\n",
      "Loss: 0.000059  [   64/ 7049]\n",
      "At step count 65602\n",
      "Loss: 0.000086  [ 6464/ 7049]\n",
      "At step count 65702\n",
      "Test Error: \n",
      " Avg loss: 0.001802 \n",
      "\n",
      "Epoch 593\n",
      "-------------------------------\n",
      "Loss: 0.000041  [   64/ 7049]\n",
      "At step count 65713\n",
      "Loss: 0.000092  [ 6464/ 7049]\n",
      "At step count 65813\n",
      "Test Error: \n",
      " Avg loss: 0.000949 \n",
      "\n",
      "Epoch 594\n",
      "-------------------------------\n",
      "Loss: 0.000078  [   64/ 7049]\n",
      "At step count 65824\n",
      "Loss: 0.000145  [ 6464/ 7049]\n",
      "At step count 65924\n",
      "Test Error: \n",
      " Avg loss: 0.001044 \n",
      "\n",
      "Epoch 595\n",
      "-------------------------------\n",
      "Loss: 0.000040  [   64/ 7049]\n",
      "At step count 65935\n",
      "Loss: 0.000067  [ 6464/ 7049]\n",
      "At step count 66035\n",
      "Test Error: \n",
      " Avg loss: 0.000787 \n",
      "\n",
      "Epoch 596\n",
      "-------------------------------\n",
      "Loss: 0.000074  [   64/ 7049]\n",
      "At step count 66046\n",
      "Loss: 0.000079  [ 6464/ 7049]\n",
      "At step count 66146\n",
      "Test Error: \n",
      " Avg loss: 0.001061 \n",
      "\n",
      "Epoch 597\n",
      "-------------------------------\n",
      "Loss: 0.000087  [   64/ 7049]\n",
      "At step count 66157\n",
      "Loss: 0.000055  [ 6464/ 7049]\n",
      "At step count 66257\n",
      "Test Error: \n",
      " Avg loss: 0.001436 \n",
      "\n",
      "Epoch 598\n",
      "-------------------------------\n",
      "Loss: 0.000075  [   64/ 7049]\n",
      "At step count 66268\n",
      "Loss: 0.000109  [ 6464/ 7049]\n",
      "At step count 66368\n",
      "Test Error: \n",
      " Avg loss: 0.001179 \n",
      "\n",
      "Epoch 599\n",
      "-------------------------------\n",
      "Loss: 0.000055  [   64/ 7049]\n",
      "At step count 66379\n",
      "Loss: 0.000087  [ 6464/ 7049]\n",
      "At step count 66479\n",
      "Test Error: \n",
      " Avg loss: 0.001627 \n",
      "\n",
      "Epoch 600\n",
      "-------------------------------\n",
      "Loss: 0.000044  [   64/ 7049]\n",
      "At step count 66490\n",
      "Loss: 0.000071  [ 6464/ 7049]\n",
      "At step count 66590\n",
      "Test Error: \n",
      " Avg loss: 0.001283 \n",
      "\n",
      "Epoch 601\n",
      "-------------------------------\n",
      "Loss: 0.000044  [   64/ 7049]\n",
      "At step count 66601\n",
      "Loss: 0.000071  [ 6464/ 7049]\n",
      "At step count 66701\n",
      "Test Error: \n",
      " Avg loss: 0.002099 \n",
      "\n",
      "Epoch 602\n",
      "-------------------------------\n",
      "Loss: 0.000081  [   64/ 7049]\n",
      "At step count 66712\n",
      "Loss: 0.000103  [ 6464/ 7049]\n",
      "At step count 66812\n",
      "Test Error: \n",
      " Avg loss: 0.001042 \n",
      "\n",
      "Epoch 603\n",
      "-------------------------------\n",
      "Loss: 0.000077  [   64/ 7049]\n",
      "At step count 66823\n",
      "Loss: 0.000055  [ 6464/ 7049]\n",
      "At step count 66923\n",
      "Test Error: \n",
      " Avg loss: 0.000512 \n",
      "\n",
      "Epoch 604\n",
      "-------------------------------\n",
      "Loss: 0.000047  [   64/ 7049]\n",
      "At step count 66934\n",
      "Loss: 0.000049  [ 6464/ 7049]\n",
      "At step count 67034\n",
      "Test Error: \n",
      " Avg loss: 0.000478 \n",
      "\n",
      "Epoch 605\n",
      "-------------------------------\n",
      "Loss: 0.000062  [   64/ 7049]\n",
      "At step count 67045\n",
      "Loss: 0.000083  [ 6464/ 7049]\n",
      "At step count 67145\n",
      "Test Error: \n",
      " Avg loss: 0.000685 \n",
      "\n",
      "Epoch 606\n",
      "-------------------------------\n",
      "Loss: 0.000069  [   64/ 7049]\n",
      "At step count 67156\n",
      "Loss: 0.000065  [ 6464/ 7049]\n",
      "At step count 67256\n",
      "Test Error: \n",
      " Avg loss: 0.000977 \n",
      "\n",
      "Epoch 607\n",
      "-------------------------------\n",
      "Loss: 0.000075  [   64/ 7049]\n",
      "At step count 67267\n",
      "Loss: 0.000058  [ 6464/ 7049]\n",
      "At step count 67367\n",
      "Test Error: \n",
      " Avg loss: 0.001063 \n",
      "\n",
      "Epoch 608\n",
      "-------------------------------\n",
      "Loss: 0.000050  [   64/ 7049]\n",
      "At step count 67378\n",
      "Loss: 0.000035  [ 6464/ 7049]\n",
      "At step count 67478\n",
      "Test Error: \n",
      " Avg loss: 0.001479 \n",
      "\n",
      "Epoch 609\n",
      "-------------------------------\n",
      "Loss: 0.000065  [   64/ 7049]\n",
      "At step count 67489\n",
      "Loss: 0.000062  [ 6464/ 7049]\n",
      "At step count 67589\n",
      "Test Error: \n",
      " Avg loss: 0.001225 \n",
      "\n",
      "Epoch 610\n",
      "-------------------------------\n",
      "Loss: 0.000072  [   64/ 7049]\n",
      "At step count 67600\n",
      "Loss: 0.000055  [ 6464/ 7049]\n",
      "At step count 67700\n",
      "Test Error: \n",
      " Avg loss: 0.001538 \n",
      "\n",
      "Epoch 611\n",
      "-------------------------------\n",
      "Loss: 0.000050  [   64/ 7049]\n",
      "At step count 67711\n",
      "Loss: 0.000090  [ 6464/ 7049]\n",
      "At step count 67811\n",
      "Test Error: \n",
      " Avg loss: 0.000983 \n",
      "\n",
      "Epoch 612\n",
      "-------------------------------\n",
      "Loss: 0.000058  [   64/ 7049]\n",
      "At step count 67822\n",
      "Loss: 0.000045  [ 6464/ 7049]\n",
      "At step count 67922\n",
      "Test Error: \n",
      " Avg loss: 0.000889 \n",
      "\n",
      "Epoch 613\n",
      "-------------------------------\n",
      "Loss: 0.000045  [   64/ 7049]\n",
      "At step count 67933\n",
      "Loss: 0.000084  [ 6464/ 7049]\n",
      "At step count 68033\n",
      "Test Error: \n",
      " Avg loss: 0.001320 \n",
      "\n",
      "Epoch 614\n",
      "-------------------------------\n",
      "Loss: 0.000042  [   64/ 7049]\n",
      "At step count 68044\n",
      "Loss: 0.000084  [ 6464/ 7049]\n",
      "At step count 68144\n",
      "Test Error: \n",
      " Avg loss: 0.001561 \n",
      "\n",
      "Epoch 615\n",
      "-------------------------------\n",
      "Loss: 0.000043  [   64/ 7049]\n",
      "At step count 68155\n",
      "Loss: 0.000137  [ 6464/ 7049]\n",
      "At step count 68255\n",
      "Test Error: \n",
      " Avg loss: 0.001033 \n",
      "\n",
      "Epoch 616\n",
      "-------------------------------\n",
      "Loss: 0.000068  [   64/ 7049]\n",
      "At step count 68266\n",
      "Loss: 0.000065  [ 6464/ 7049]\n",
      "At step count 68366\n",
      "Test Error: \n",
      " Avg loss: 0.000918 \n",
      "\n",
      "Epoch 617\n",
      "-------------------------------\n",
      "Loss: 0.000107  [   64/ 7049]\n",
      "At step count 68377\n",
      "Loss: 0.000044  [ 6464/ 7049]\n",
      "At step count 68477\n",
      "Test Error: \n",
      " Avg loss: 0.000954 \n",
      "\n",
      "Epoch 618\n",
      "-------------------------------\n",
      "Loss: 0.000058  [   64/ 7049]\n",
      "At step count 68488\n",
      "Loss: 0.000078  [ 6464/ 7049]\n",
      "At step count 68588\n",
      "Test Error: \n",
      " Avg loss: 0.001320 \n",
      "\n",
      "Epoch 619\n",
      "-------------------------------\n",
      "Loss: 0.000098  [   64/ 7049]\n",
      "At step count 68599\n",
      "Loss: 0.000242  [ 6464/ 7049]\n",
      "At step count 68699\n",
      "Test Error: \n",
      " Avg loss: 0.000933 \n",
      "\n",
      "Epoch 620\n",
      "-------------------------------\n",
      "Loss: 0.000437  [   64/ 7049]\n",
      "At step count 68710\n",
      "Loss: 0.000097  [ 6464/ 7049]\n",
      "At step count 68810\n",
      "Test Error: \n",
      " Avg loss: 0.000996 \n",
      "\n",
      "Epoch 621\n",
      "-------------------------------\n",
      "Loss: 0.000055  [   64/ 7049]\n",
      "At step count 68821\n",
      "Loss: 0.000157  [ 6464/ 7049]\n",
      "At step count 68921\n",
      "Test Error: \n",
      " Avg loss: 0.001118 \n",
      "\n",
      "Epoch 622\n",
      "-------------------------------\n",
      "Loss: 0.000038  [   64/ 7049]\n",
      "At step count 68932\n",
      "Loss: 0.000048  [ 6464/ 7049]\n",
      "At step count 69032\n",
      "Test Error: \n",
      " Avg loss: 0.000968 \n",
      "\n",
      "Epoch 623\n",
      "-------------------------------\n",
      "Loss: 0.000054  [   64/ 7049]\n",
      "At step count 69043\n",
      "Loss: 0.000061  [ 6464/ 7049]\n",
      "At step count 69143\n",
      "Test Error: \n",
      " Avg loss: 0.001180 \n",
      "\n",
      "Epoch 624\n",
      "-------------------------------\n",
      "Loss: 0.000109  [   64/ 7049]\n",
      "At step count 69154\n",
      "Loss: 0.000064  [ 6464/ 7049]\n",
      "At step count 69254\n",
      "Test Error: \n",
      " Avg loss: 0.001130 \n",
      "\n",
      "Epoch 625\n",
      "-------------------------------\n",
      "Loss: 0.000041  [   64/ 7049]\n",
      "At step count 69265\n",
      "Loss: 0.000037  [ 6464/ 7049]\n",
      "At step count 69365\n",
      "Test Error: \n",
      " Avg loss: 0.001246 \n",
      "\n",
      "Epoch 626\n",
      "-------------------------------\n",
      "Loss: 0.000166  [   64/ 7049]\n",
      "At step count 69376\n",
      "Loss: 0.000059  [ 6464/ 7049]\n",
      "At step count 69476\n",
      "Test Error: \n",
      " Avg loss: 0.000951 \n",
      "\n",
      "Epoch 627\n",
      "-------------------------------\n",
      "Loss: 0.000067  [   64/ 7049]\n",
      "At step count 69487\n",
      "Loss: 0.000071  [ 6464/ 7049]\n",
      "At step count 69587\n",
      "Test Error: \n",
      " Avg loss: 0.001202 \n",
      "\n",
      "Epoch 628\n",
      "-------------------------------\n",
      "Loss: 0.000059  [   64/ 7049]\n",
      "At step count 69598\n",
      "Loss: 0.000717  [ 6464/ 7049]\n",
      "At step count 69698\n",
      "Test Error: \n",
      " Avg loss: 0.001700 \n",
      "\n",
      "Epoch 629\n",
      "-------------------------------\n",
      "Loss: 0.000138  [   64/ 7049]\n",
      "At step count 69709\n",
      "Loss: 0.000074  [ 6464/ 7049]\n",
      "At step count 69809\n",
      "Test Error: \n",
      " Avg loss: 0.001466 \n",
      "\n",
      "Epoch 630\n",
      "-------------------------------\n",
      "Loss: 0.000153  [   64/ 7049]\n",
      "At step count 69820\n",
      "Loss: 0.000150  [ 6464/ 7049]\n",
      "At step count 69920\n",
      "Test Error: \n",
      " Avg loss: 0.000697 \n",
      "\n",
      "Epoch 631\n",
      "-------------------------------\n",
      "Loss: 0.000052  [   64/ 7049]\n",
      "At step count 69931\n",
      "Loss: 0.000082  [ 6464/ 7049]\n",
      "At step count 70031\n",
      "Test Error: \n",
      " Avg loss: 0.000405 \n",
      "\n",
      "Epoch 632\n",
      "-------------------------------\n",
      "Loss: 0.000088  [   64/ 7049]\n",
      "At step count 70042\n",
      "Loss: 0.000083  [ 6464/ 7049]\n",
      "At step count 70142\n",
      "Test Error: \n",
      " Avg loss: 0.000804 \n",
      "\n",
      "Epoch 633\n",
      "-------------------------------\n",
      "Loss: 0.000058  [   64/ 7049]\n",
      "At step count 70153\n",
      "Loss: 0.000076  [ 6464/ 7049]\n",
      "At step count 70253\n",
      "Test Error: \n",
      " Avg loss: 0.000936 \n",
      "\n",
      "Epoch 634\n",
      "-------------------------------\n",
      "Loss: 0.000102  [   64/ 7049]\n",
      "At step count 70264\n",
      "Loss: 0.000053  [ 6464/ 7049]\n",
      "At step count 70364\n",
      "Test Error: \n",
      " Avg loss: 0.001347 \n",
      "\n",
      "Epoch 635\n",
      "-------------------------------\n",
      "Loss: 0.000086  [   64/ 7049]\n",
      "At step count 70375\n",
      "Loss: 0.000174  [ 6464/ 7049]\n",
      "At step count 70475\n",
      "Test Error: \n",
      " Avg loss: 0.001375 \n",
      "\n",
      "Epoch 636\n",
      "-------------------------------\n",
      "Loss: 0.000057  [   64/ 7049]\n",
      "At step count 70486\n",
      "Loss: 0.000080  [ 6464/ 7049]\n",
      "At step count 70586\n",
      "Test Error: \n",
      " Avg loss: 0.000749 \n",
      "\n",
      "Epoch 637\n",
      "-------------------------------\n",
      "Loss: 0.000865  [   64/ 7049]\n",
      "At step count 70597\n",
      "Loss: 0.000113  [ 6464/ 7049]\n",
      "At step count 70697\n",
      "Test Error: \n",
      " Avg loss: 0.001018 \n",
      "\n",
      "Epoch 638\n",
      "-------------------------------\n",
      "Loss: 0.000209  [   64/ 7049]\n",
      "At step count 70708\n",
      "Loss: 0.000056  [ 6464/ 7049]\n",
      "At step count 70808\n",
      "Test Error: \n",
      " Avg loss: 0.000919 \n",
      "\n",
      "Epoch 639\n",
      "-------------------------------\n",
      "Loss: 0.000109  [   64/ 7049]\n",
      "At step count 70819\n",
      "Loss: 0.000624  [ 6464/ 7049]\n",
      "At step count 70919\n",
      "Test Error: \n",
      " Avg loss: 0.001098 \n",
      "\n",
      "Epoch 640\n",
      "-------------------------------\n",
      "Loss: 0.000050  [   64/ 7049]\n",
      "At step count 70930\n",
      "Loss: 0.000101  [ 6464/ 7049]\n",
      "At step count 71030\n",
      "Test Error: \n",
      " Avg loss: 0.000971 \n",
      "\n",
      "Epoch 641\n",
      "-------------------------------\n",
      "Loss: 0.000056  [   64/ 7049]\n",
      "At step count 71041\n",
      "Loss: 0.000159  [ 6464/ 7049]\n",
      "At step count 71141\n",
      "Test Error: \n",
      " Avg loss: 0.002142 \n",
      "\n",
      "Epoch 642\n",
      "-------------------------------\n",
      "Loss: 0.000052  [   64/ 7049]\n",
      "At step count 71152\n",
      "Loss: 0.000048  [ 6464/ 7049]\n",
      "At step count 71252\n",
      "Test Error: \n",
      " Avg loss: 0.001015 \n",
      "\n",
      "Epoch 643\n",
      "-------------------------------\n",
      "Loss: 0.000051  [   64/ 7049]\n",
      "At step count 71263\n",
      "Loss: 0.000045  [ 6464/ 7049]\n",
      "At step count 71363\n",
      "Test Error: \n",
      " Avg loss: 0.001157 \n",
      "\n",
      "Epoch 644\n",
      "-------------------------------\n",
      "Loss: 0.000045  [   64/ 7049]\n",
      "At step count 71374\n",
      "Loss: 0.000048  [ 6464/ 7049]\n",
      "At step count 71474\n",
      "Test Error: \n",
      " Avg loss: 0.001875 \n",
      "\n",
      "Epoch 645\n",
      "-------------------------------\n",
      "Loss: 0.000076  [   64/ 7049]\n",
      "At step count 71485\n",
      "Loss: 0.000049  [ 6464/ 7049]\n",
      "At step count 71585\n",
      "Test Error: \n",
      " Avg loss: 0.001057 \n",
      "\n",
      "Epoch 646\n",
      "-------------------------------\n",
      "Loss: 0.000065  [   64/ 7049]\n",
      "At step count 71596\n",
      "Loss: 0.000052  [ 6464/ 7049]\n",
      "At step count 71696\n",
      "Test Error: \n",
      " Avg loss: 0.000934 \n",
      "\n",
      "Epoch 647\n",
      "-------------------------------\n",
      "Loss: 0.000111  [   64/ 7049]\n",
      "At step count 71707\n",
      "Loss: 0.000074  [ 6464/ 7049]\n",
      "At step count 71807\n",
      "Test Error: \n",
      " Avg loss: 0.001176 \n",
      "\n",
      "Epoch 648\n",
      "-------------------------------\n",
      "Loss: 0.000054  [   64/ 7049]\n",
      "At step count 71818\n",
      "Loss: 0.000049  [ 6464/ 7049]\n",
      "At step count 71918\n",
      "Test Error: \n",
      " Avg loss: 0.001270 \n",
      "\n",
      "Epoch 649\n",
      "-------------------------------\n",
      "Loss: 0.000059  [   64/ 7049]\n",
      "At step count 71929\n",
      "Loss: 0.001154  [ 6464/ 7049]\n",
      "At step count 72029\n",
      "Test Error: \n",
      " Avg loss: 0.000987 \n",
      "\n",
      "Epoch 650\n",
      "-------------------------------\n",
      "Loss: 0.000050  [   64/ 7049]\n",
      "At step count 72040\n",
      "Loss: 0.000056  [ 6464/ 7049]\n",
      "At step count 72140\n",
      "Test Error: \n",
      " Avg loss: 0.000976 \n",
      "\n",
      "Epoch 651\n",
      "-------------------------------\n",
      "Loss: 0.000083  [   64/ 7049]\n",
      "At step count 72151\n",
      "Loss: 0.000097  [ 6464/ 7049]\n",
      "At step count 72251\n",
      "Test Error: \n",
      " Avg loss: 0.000942 \n",
      "\n",
      "Epoch 652\n",
      "-------------------------------\n",
      "Loss: 0.000029  [   64/ 7049]\n",
      "At step count 72262\n",
      "Loss: 0.000078  [ 6464/ 7049]\n",
      "At step count 72362\n",
      "Test Error: \n",
      " Avg loss: 0.001488 \n",
      "\n",
      "Epoch 653\n",
      "-------------------------------\n",
      "Loss: 0.000082  [   64/ 7049]\n",
      "At step count 72373\n",
      "Loss: 0.000081  [ 6464/ 7049]\n",
      "At step count 72473\n",
      "Test Error: \n",
      " Avg loss: 0.000903 \n",
      "\n",
      "Epoch 654\n",
      "-------------------------------\n",
      "Loss: 0.000067  [   64/ 7049]\n",
      "At step count 72484\n",
      "Loss: 0.000187  [ 6464/ 7049]\n",
      "At step count 72584\n",
      "Test Error: \n",
      " Avg loss: 0.002215 \n",
      "\n",
      "Epoch 655\n",
      "-------------------------------\n",
      "Loss: 0.000027  [   64/ 7049]\n",
      "At step count 72595\n",
      "Loss: 0.000074  [ 6464/ 7049]\n",
      "At step count 72695\n",
      "Test Error: \n",
      " Avg loss: 0.001134 \n",
      "\n",
      "Epoch 656\n",
      "-------------------------------\n",
      "Loss: 0.000056  [   64/ 7049]\n",
      "At step count 72706\n",
      "Loss: 0.000160  [ 6464/ 7049]\n",
      "At step count 72806\n",
      "Test Error: \n",
      " Avg loss: 0.001028 \n",
      "\n",
      "Epoch 657\n",
      "-------------------------------\n",
      "Loss: 0.000068  [   64/ 7049]\n",
      "At step count 72817\n",
      "Loss: 0.000050  [ 6464/ 7049]\n",
      "At step count 72917\n",
      "Test Error: \n",
      " Avg loss: 0.001157 \n",
      "\n",
      "Epoch 658\n",
      "-------------------------------\n",
      "Loss: 0.000063  [   64/ 7049]\n",
      "At step count 72928\n",
      "Loss: 0.000071  [ 6464/ 7049]\n",
      "At step count 73028\n",
      "Test Error: \n",
      " Avg loss: 0.001110 \n",
      "\n",
      "Epoch 659\n",
      "-------------------------------\n",
      "Loss: 0.000043  [   64/ 7049]\n",
      "At step count 73039\n",
      "Loss: 0.000056  [ 6464/ 7049]\n",
      "At step count 73139\n",
      "Test Error: \n",
      " Avg loss: 0.001951 \n",
      "\n",
      "Epoch 660\n",
      "-------------------------------\n",
      "Loss: 0.000057  [   64/ 7049]\n",
      "At step count 73150\n",
      "Loss: 0.000198  [ 6464/ 7049]\n",
      "At step count 73250\n",
      "Test Error: \n",
      " Avg loss: 0.000888 \n",
      "\n",
      "Epoch 661\n",
      "-------------------------------\n",
      "Loss: 0.000091  [   64/ 7049]\n",
      "At step count 73261\n",
      "Loss: 0.000075  [ 6464/ 7049]\n",
      "At step count 73361\n",
      "Test Error: \n",
      " Avg loss: 0.001030 \n",
      "\n",
      "Epoch 662\n",
      "-------------------------------\n",
      "Loss: 0.000116  [   64/ 7049]\n",
      "At step count 73372\n",
      "Loss: 0.000076  [ 6464/ 7049]\n",
      "At step count 73472\n",
      "Test Error: \n",
      " Avg loss: 0.001065 \n",
      "\n",
      "Epoch 663\n",
      "-------------------------------\n",
      "Loss: 0.000069  [   64/ 7049]\n",
      "At step count 73483\n",
      "Loss: 0.000083  [ 6464/ 7049]\n",
      "At step count 73583\n",
      "Test Error: \n",
      " Avg loss: 0.000595 \n",
      "\n",
      "Epoch 664\n",
      "-------------------------------\n",
      "Loss: 0.000078  [   64/ 7049]\n",
      "At step count 73594\n",
      "Loss: 0.000059  [ 6464/ 7049]\n",
      "At step count 73694\n",
      "Test Error: \n",
      " Avg loss: 0.001357 \n",
      "\n",
      "Epoch 665\n",
      "-------------------------------\n",
      "Loss: 0.000111  [   64/ 7049]\n",
      "At step count 73705\n",
      "Loss: 0.000503  [ 6464/ 7049]\n",
      "At step count 73805\n",
      "Test Error: \n",
      " Avg loss: 0.001208 \n",
      "\n",
      "Epoch 666\n",
      "-------------------------------\n",
      "Loss: 0.000044  [   64/ 7049]\n",
      "At step count 73816\n",
      "Loss: 0.000054  [ 6464/ 7049]\n",
      "At step count 73916\n",
      "Test Error: \n",
      " Avg loss: 0.001105 \n",
      "\n",
      "Epoch 667\n",
      "-------------------------------\n",
      "Loss: 0.000072  [   64/ 7049]\n",
      "At step count 73927\n",
      "Loss: 0.000063  [ 6464/ 7049]\n",
      "At step count 74027\n",
      "Test Error: \n",
      " Avg loss: 0.000927 \n",
      "\n",
      "Epoch 668\n",
      "-------------------------------\n",
      "Loss: 0.000044  [   64/ 7049]\n",
      "At step count 74038\n",
      "Loss: 0.000066  [ 6464/ 7049]\n",
      "At step count 74138\n",
      "Test Error: \n",
      " Avg loss: 0.001111 \n",
      "\n",
      "Epoch 669\n",
      "-------------------------------\n",
      "Loss: 0.000055  [   64/ 7049]\n",
      "At step count 74149\n",
      "Loss: 0.000043  [ 6464/ 7049]\n",
      "At step count 74249\n",
      "Test Error: \n",
      " Avg loss: 0.001063 \n",
      "\n",
      "Epoch 670\n",
      "-------------------------------\n",
      "Loss: 0.000057  [   64/ 7049]\n",
      "At step count 74260\n",
      "Loss: 0.000054  [ 6464/ 7049]\n",
      "At step count 74360\n",
      "Test Error: \n",
      " Avg loss: 0.001076 \n",
      "\n",
      "Epoch 671\n",
      "-------------------------------\n",
      "Loss: 0.000079  [   64/ 7049]\n",
      "At step count 74371\n",
      "Loss: 0.000052  [ 6464/ 7049]\n",
      "At step count 74471\n",
      "Test Error: \n",
      " Avg loss: 0.001100 \n",
      "\n",
      "Epoch 672\n",
      "-------------------------------\n",
      "Loss: 0.000055  [   64/ 7049]\n",
      "At step count 74482\n",
      "Loss: 0.000065  [ 6464/ 7049]\n",
      "At step count 74582\n",
      "Test Error: \n",
      " Avg loss: 0.001095 \n",
      "\n",
      "Epoch 673\n",
      "-------------------------------\n",
      "Loss: 0.000057  [   64/ 7049]\n",
      "At step count 74593\n",
      "Loss: 0.000059  [ 6464/ 7049]\n",
      "At step count 74693\n",
      "Test Error: \n",
      " Avg loss: 0.001431 \n",
      "\n",
      "Epoch 674\n",
      "-------------------------------\n",
      "Loss: 0.000044  [   64/ 7049]\n",
      "At step count 74704\n",
      "Loss: 0.000061  [ 6464/ 7049]\n",
      "At step count 74804\n",
      "Test Error: \n",
      " Avg loss: 0.000673 \n",
      "\n",
      "Epoch 675\n",
      "-------------------------------\n",
      "Loss: 0.000049  [   64/ 7049]\n",
      "At step count 74815\n",
      "Loss: 0.000066  [ 6464/ 7049]\n",
      "At step count 74915\n",
      "Test Error: \n",
      " Avg loss: 0.000976 \n",
      "\n",
      "Epoch 676\n",
      "-------------------------------\n",
      "Loss: 0.000748  [   64/ 7049]\n",
      "At step count 74926\n",
      "Loss: 0.000054  [ 6464/ 7049]\n",
      "At step count 75026\n",
      "Test Error: \n",
      " Avg loss: 0.001183 \n",
      "\n",
      "Epoch 677\n",
      "-------------------------------\n",
      "Loss: 0.000045  [   64/ 7049]\n",
      "At step count 75037\n",
      "Loss: 0.000045  [ 6464/ 7049]\n",
      "At step count 75137\n",
      "Test Error: \n",
      " Avg loss: 0.001037 \n",
      "\n",
      "Epoch 678\n",
      "-------------------------------\n",
      "Loss: 0.000063  [   64/ 7049]\n",
      "At step count 75148\n",
      "Loss: 0.000052  [ 6464/ 7049]\n",
      "At step count 75248\n",
      "Test Error: \n",
      " Avg loss: 0.001410 \n",
      "\n",
      "Epoch 679\n",
      "-------------------------------\n",
      "Loss: 0.000055  [   64/ 7049]\n",
      "At step count 75259\n",
      "Loss: 0.000063  [ 6464/ 7049]\n",
      "At step count 75359\n",
      "Test Error: \n",
      " Avg loss: 0.000852 \n",
      "\n",
      "Epoch 680\n",
      "-------------------------------\n",
      "Loss: 0.000075  [   64/ 7049]\n",
      "At step count 75370\n",
      "Loss: 0.000217  [ 6464/ 7049]\n",
      "At step count 75470\n",
      "Test Error: \n",
      " Avg loss: 0.000965 \n",
      "\n",
      "Epoch 681\n",
      "-------------------------------\n",
      "Loss: 0.000057  [   64/ 7049]\n",
      "At step count 75481\n",
      "Loss: 0.000120  [ 6464/ 7049]\n",
      "At step count 75581\n",
      "Test Error: \n",
      " Avg loss: 0.000734 \n",
      "\n",
      "Epoch 682\n",
      "-------------------------------\n",
      "Loss: 0.000042  [   64/ 7049]\n",
      "At step count 75592\n",
      "Loss: 0.000129  [ 6464/ 7049]\n",
      "At step count 75692\n",
      "Test Error: \n",
      " Avg loss: 0.001067 \n",
      "\n",
      "Epoch 683\n",
      "-------------------------------\n",
      "Loss: 0.000099  [   64/ 7049]\n",
      "At step count 75703\n",
      "Loss: 0.000053  [ 6464/ 7049]\n",
      "At step count 75803\n",
      "Test Error: \n",
      " Avg loss: 0.001577 \n",
      "\n",
      "Epoch 684\n",
      "-------------------------------\n",
      "Loss: 0.000053  [   64/ 7049]\n",
      "At step count 75814\n",
      "Loss: 0.000055  [ 6464/ 7049]\n",
      "At step count 75914\n",
      "Test Error: \n",
      " Avg loss: 0.000866 \n",
      "\n",
      "Epoch 685\n",
      "-------------------------------\n",
      "Loss: 0.000092  [   64/ 7049]\n",
      "At step count 75925\n",
      "Loss: 0.000047  [ 6464/ 7049]\n",
      "At step count 76025\n",
      "Test Error: \n",
      " Avg loss: 0.001165 \n",
      "\n",
      "Epoch 686\n",
      "-------------------------------\n",
      "Loss: 0.000069  [   64/ 7049]\n",
      "At step count 76036\n",
      "Loss: 0.000059  [ 6464/ 7049]\n",
      "At step count 76136\n",
      "Test Error: \n",
      " Avg loss: 0.001365 \n",
      "\n",
      "Epoch 687\n",
      "-------------------------------\n",
      "Loss: 0.000076  [   64/ 7049]\n",
      "At step count 76147\n",
      "Loss: 0.000088  [ 6464/ 7049]\n",
      "At step count 76247\n",
      "Test Error: \n",
      " Avg loss: 0.000995 \n",
      "\n",
      "Epoch 688\n",
      "-------------------------------\n",
      "Loss: 0.000056  [   64/ 7049]\n",
      "At step count 76258\n",
      "Loss: 0.000290  [ 6464/ 7049]\n",
      "At step count 76358\n",
      "Test Error: \n",
      " Avg loss: 0.000872 \n",
      "\n",
      "Epoch 689\n",
      "-------------------------------\n",
      "Loss: 0.000051  [   64/ 7049]\n",
      "At step count 76369\n",
      "Loss: 0.000109  [ 6464/ 7049]\n",
      "At step count 76469\n",
      "Test Error: \n",
      " Avg loss: 0.001408 \n",
      "\n",
      "Epoch 690\n",
      "-------------------------------\n",
      "Loss: 0.000064  [   64/ 7049]\n",
      "At step count 76480\n",
      "Loss: 0.000047  [ 6464/ 7049]\n",
      "At step count 76580\n",
      "Test Error: \n",
      " Avg loss: 0.000680 \n",
      "\n",
      "Epoch 691\n",
      "-------------------------------\n",
      "Loss: 0.000098  [   64/ 7049]\n",
      "At step count 76591\n",
      "Loss: 0.000040  [ 6464/ 7049]\n",
      "At step count 76691\n",
      "Test Error: \n",
      " Avg loss: 0.000864 \n",
      "\n",
      "Epoch 692\n",
      "-------------------------------\n",
      "Loss: 0.000128  [   64/ 7049]\n",
      "At step count 76702\n",
      "Loss: 0.000159  [ 6464/ 7049]\n",
      "At step count 76802\n",
      "Test Error: \n",
      " Avg loss: 0.001056 \n",
      "\n",
      "Epoch 693\n",
      "-------------------------------\n",
      "Loss: 0.000208  [   64/ 7049]\n",
      "At step count 76813\n",
      "Loss: 0.000059  [ 6464/ 7049]\n",
      "At step count 76913\n",
      "Test Error: \n",
      " Avg loss: 0.000777 \n",
      "\n",
      "Epoch 694\n",
      "-------------------------------\n",
      "Loss: 0.000054  [   64/ 7049]\n",
      "At step count 76924\n",
      "Loss: 0.000057  [ 6464/ 7049]\n",
      "At step count 77024\n",
      "Test Error: \n",
      " Avg loss: 0.001234 \n",
      "\n",
      "Epoch 695\n",
      "-------------------------------\n",
      "Loss: 0.000069  [   64/ 7049]\n",
      "At step count 77035\n",
      "Loss: 0.000044  [ 6464/ 7049]\n",
      "At step count 77135\n",
      "Test Error: \n",
      " Avg loss: 0.000718 \n",
      "\n",
      "Epoch 696\n",
      "-------------------------------\n",
      "Loss: 0.000038  [   64/ 7049]\n",
      "At step count 77146\n",
      "Loss: 0.000046  [ 6464/ 7049]\n",
      "At step count 77246\n",
      "Test Error: \n",
      " Avg loss: 0.000859 \n",
      "\n",
      "Epoch 697\n",
      "-------------------------------\n",
      "Loss: 0.000047  [   64/ 7049]\n",
      "At step count 77257\n",
      "Loss: 0.000058  [ 6464/ 7049]\n",
      "At step count 77357\n",
      "Test Error: \n",
      " Avg loss: 0.000763 \n",
      "\n",
      "Epoch 698\n",
      "-------------------------------\n",
      "Loss: 0.000064  [   64/ 7049]\n",
      "At step count 77368\n",
      "Loss: 0.000237  [ 6464/ 7049]\n",
      "At step count 77468\n",
      "Test Error: \n",
      " Avg loss: 0.000952 \n",
      "\n",
      "Epoch 699\n",
      "-------------------------------\n",
      "Loss: 0.000052  [   64/ 7049]\n",
      "At step count 77479\n",
      "Loss: 0.000057  [ 6464/ 7049]\n",
      "At step count 77579\n",
      "Test Error: \n",
      " Avg loss: 0.000934 \n",
      "\n",
      "Epoch 700\n",
      "-------------------------------\n",
      "Loss: 0.000063  [   64/ 7049]\n",
      "At step count 77590\n",
      "Loss: 0.000051  [ 6464/ 7049]\n",
      "At step count 77690\n",
      "Test Error: \n",
      " Avg loss: 0.001036 \n",
      "\n",
      "Epoch 701\n",
      "-------------------------------\n",
      "Loss: 0.000072  [   64/ 7049]\n",
      "At step count 77701\n",
      "Loss: 0.000049  [ 6464/ 7049]\n",
      "At step count 77801\n",
      "Test Error: \n",
      " Avg loss: 0.001038 \n",
      "\n",
      "Epoch 702\n",
      "-------------------------------\n",
      "Loss: 0.000079  [   64/ 7049]\n",
      "At step count 77812\n",
      "Loss: 0.000046  [ 6464/ 7049]\n",
      "At step count 77912\n",
      "Test Error: \n",
      " Avg loss: 0.000745 \n",
      "\n",
      "Epoch 703\n",
      "-------------------------------\n",
      "Loss: 0.000094  [   64/ 7049]\n",
      "At step count 77923\n",
      "Loss: 0.000052  [ 6464/ 7049]\n",
      "At step count 78023\n",
      "Test Error: \n",
      " Avg loss: 0.000800 \n",
      "\n",
      "Epoch 704\n",
      "-------------------------------\n",
      "Loss: 0.000066  [   64/ 7049]\n",
      "At step count 78034\n",
      "Loss: 0.000075  [ 6464/ 7049]\n",
      "At step count 78134\n",
      "Test Error: \n",
      " Avg loss: 0.000963 \n",
      "\n",
      "Epoch 705\n",
      "-------------------------------\n",
      "Loss: 0.000063  [   64/ 7049]\n",
      "At step count 78145\n",
      "Loss: 0.000096  [ 6464/ 7049]\n",
      "At step count 78245\n",
      "Test Error: \n",
      " Avg loss: 0.000991 \n",
      "\n",
      "Epoch 706\n",
      "-------------------------------\n",
      "Loss: 0.000052  [   64/ 7049]\n",
      "At step count 78256\n",
      "Loss: 0.000108  [ 6464/ 7049]\n",
      "At step count 78356\n",
      "Test Error: \n",
      " Avg loss: 0.000971 \n",
      "\n",
      "Epoch 707\n",
      "-------------------------------\n",
      "Loss: 0.000064  [   64/ 7049]\n",
      "At step count 78367\n",
      "Loss: 0.000072  [ 6464/ 7049]\n",
      "At step count 78467\n",
      "Test Error: \n",
      " Avg loss: 0.000806 \n",
      "\n",
      "Epoch 708\n",
      "-------------------------------\n",
      "Loss: 0.000037  [   64/ 7049]\n",
      "At step count 78478\n",
      "Loss: 0.000101  [ 6464/ 7049]\n",
      "At step count 78578\n",
      "Test Error: \n",
      " Avg loss: 0.001320 \n",
      "\n",
      "Epoch 709\n",
      "-------------------------------\n",
      "Loss: 0.000313  [   64/ 7049]\n",
      "At step count 78589\n",
      "Loss: 0.000089  [ 6464/ 7049]\n",
      "At step count 78689\n",
      "Test Error: \n",
      " Avg loss: 0.000548 \n",
      "\n",
      "Epoch 710\n",
      "-------------------------------\n",
      "Loss: 0.000047  [   64/ 7049]\n",
      "At step count 78700\n",
      "Loss: 0.000077  [ 6464/ 7049]\n",
      "At step count 78800\n",
      "Test Error: \n",
      " Avg loss: 0.001060 \n",
      "\n",
      "Epoch 711\n",
      "-------------------------------\n",
      "Loss: 0.000153  [   64/ 7049]\n",
      "At step count 78811\n",
      "Loss: 0.000998  [ 6464/ 7049]\n",
      "At step count 78911\n",
      "Test Error: \n",
      " Avg loss: 0.000872 \n",
      "\n",
      "Epoch 712\n",
      "-------------------------------\n",
      "Loss: 0.000088  [   64/ 7049]\n",
      "At step count 78922\n",
      "Loss: 0.000039  [ 6464/ 7049]\n",
      "At step count 79022\n",
      "Test Error: \n",
      " Avg loss: 0.000679 \n",
      "\n",
      "Epoch 713\n",
      "-------------------------------\n",
      "Loss: 0.000645  [   64/ 7049]\n",
      "At step count 79033\n",
      "Loss: 0.000099  [ 6464/ 7049]\n",
      "At step count 79133\n",
      "Test Error: \n",
      " Avg loss: 0.000641 \n",
      "\n",
      "Epoch 714\n",
      "-------------------------------\n",
      "Loss: 0.000054  [   64/ 7049]\n",
      "At step count 79144\n",
      "Loss: 0.000081  [ 6464/ 7049]\n",
      "At step count 79244\n",
      "Test Error: \n",
      " Avg loss: 0.000887 \n",
      "\n",
      "Epoch 715\n",
      "-------------------------------\n",
      "Loss: 0.000064  [   64/ 7049]\n",
      "At step count 79255\n",
      "Loss: 0.000101  [ 6464/ 7049]\n",
      "At step count 79355\n",
      "Test Error: \n",
      " Avg loss: 0.000895 \n",
      "\n",
      "Epoch 716\n",
      "-------------------------------\n",
      "Loss: 0.000083  [   64/ 7049]\n",
      "At step count 79366\n",
      "Loss: 0.000083  [ 6464/ 7049]\n",
      "At step count 79466\n",
      "Test Error: \n",
      " Avg loss: 0.000900 \n",
      "\n",
      "Epoch 717\n",
      "-------------------------------\n",
      "Loss: 0.000085  [   64/ 7049]\n",
      "At step count 79477\n",
      "Loss: 0.000051  [ 6464/ 7049]\n",
      "At step count 79577\n",
      "Test Error: \n",
      " Avg loss: 0.000959 \n",
      "\n",
      "Epoch 718\n",
      "-------------------------------\n",
      "Loss: 0.000207  [   64/ 7049]\n",
      "At step count 79588\n",
      "Loss: 0.000838  [ 6464/ 7049]\n",
      "At step count 79688\n",
      "Test Error: \n",
      " Avg loss: 0.001137 \n",
      "\n",
      "Epoch 719\n",
      "-------------------------------\n",
      "Loss: 0.000188  [   64/ 7049]\n",
      "At step count 79699\n",
      "Loss: 0.000055  [ 6464/ 7049]\n",
      "At step count 79799\n",
      "Test Error: \n",
      " Avg loss: 0.001182 \n",
      "\n",
      "Epoch 720\n",
      "-------------------------------\n",
      "Loss: 0.000033  [   64/ 7049]\n",
      "At step count 79810\n",
      "Loss: 0.000077  [ 6464/ 7049]\n",
      "At step count 79910\n",
      "Test Error: \n",
      " Avg loss: 0.000515 \n",
      "\n",
      "Epoch 721\n",
      "-------------------------------\n",
      "Loss: 0.000510  [   64/ 7049]\n",
      "At step count 79921\n",
      "Loss: 0.000048  [ 6464/ 7049]\n",
      "At step count 80021\n",
      "Test Error: \n",
      " Avg loss: 0.000538 \n",
      "\n",
      "Epoch 722\n",
      "-------------------------------\n",
      "Loss: 0.000054  [   64/ 7049]\n",
      "At step count 80032\n",
      "Loss: 0.000059  [ 6464/ 7049]\n",
      "At step count 80132\n",
      "Test Error: \n",
      " Avg loss: 0.000694 \n",
      "\n",
      "Epoch 723\n",
      "-------------------------------\n",
      "Loss: 0.000043  [   64/ 7049]\n",
      "At step count 80143\n",
      "Loss: 0.000066  [ 6464/ 7049]\n",
      "At step count 80243\n",
      "Test Error: \n",
      " Avg loss: 0.000507 \n",
      "\n",
      "Epoch 724\n",
      "-------------------------------\n",
      "Loss: 0.000100  [   64/ 7049]\n",
      "At step count 80254\n",
      "Loss: 0.000163  [ 6464/ 7049]\n",
      "At step count 80354\n",
      "Test Error: \n",
      " Avg loss: 0.001094 \n",
      "\n",
      "Epoch 725\n",
      "-------------------------------\n",
      "Loss: 0.000080  [   64/ 7049]\n",
      "At step count 80365\n",
      "Loss: 0.000045  [ 6464/ 7049]\n",
      "At step count 80465\n",
      "Test Error: \n",
      " Avg loss: 0.000774 \n",
      "\n",
      "Epoch 726\n",
      "-------------------------------\n",
      "Loss: 0.000056  [   64/ 7049]\n",
      "At step count 80476\n",
      "Loss: 0.000080  [ 6464/ 7049]\n",
      "At step count 80576\n",
      "Test Error: \n",
      " Avg loss: 0.000930 \n",
      "\n",
      "Epoch 727\n",
      "-------------------------------\n",
      "Loss: 0.000058  [   64/ 7049]\n",
      "At step count 80587\n",
      "Loss: 0.000051  [ 6464/ 7049]\n",
      "At step count 80687\n",
      "Test Error: \n",
      " Avg loss: 0.001316 \n",
      "\n",
      "Epoch 728\n",
      "-------------------------------\n",
      "Loss: 0.000043  [   64/ 7049]\n",
      "At step count 80698\n",
      "Loss: 0.000063  [ 6464/ 7049]\n",
      "At step count 80798\n",
      "Test Error: \n",
      " Avg loss: 0.001251 \n",
      "\n",
      "Epoch 729\n",
      "-------------------------------\n",
      "Loss: 0.000037  [   64/ 7049]\n",
      "At step count 80809\n",
      "Loss: 0.000065  [ 6464/ 7049]\n",
      "At step count 80909\n",
      "Test Error: \n",
      " Avg loss: 0.000737 \n",
      "\n",
      "Epoch 730\n",
      "-------------------------------\n",
      "Loss: 0.000060  [   64/ 7049]\n",
      "At step count 80920\n",
      "Loss: 0.000055  [ 6464/ 7049]\n",
      "At step count 81020\n",
      "Test Error: \n",
      " Avg loss: 0.001367 \n",
      "\n",
      "Epoch 731\n",
      "-------------------------------\n",
      "Loss: 0.000043  [   64/ 7049]\n",
      "At step count 81031\n",
      "Loss: 0.000069  [ 6464/ 7049]\n",
      "At step count 81131\n",
      "Test Error: \n",
      " Avg loss: 0.000541 \n",
      "\n",
      "Epoch 732\n",
      "-------------------------------\n",
      "Loss: 0.000073  [   64/ 7049]\n",
      "At step count 81142\n",
      "Loss: 0.000123  [ 6464/ 7049]\n",
      "At step count 81242\n",
      "Test Error: \n",
      " Avg loss: 0.014387 \n",
      "\n",
      "Epoch 733\n",
      "-------------------------------\n",
      "Loss: 0.000490  [   64/ 7049]\n",
      "At step count 81253\n",
      "Loss: 0.000050  [ 6464/ 7049]\n",
      "At step count 81353\n",
      "Test Error: \n",
      " Avg loss: 0.001382 \n",
      "\n",
      "Epoch 734\n",
      "-------------------------------\n",
      "Loss: 0.000163  [   64/ 7049]\n",
      "At step count 81364\n",
      "Loss: 0.000065  [ 6464/ 7049]\n",
      "At step count 81464\n",
      "Test Error: \n",
      " Avg loss: 0.001483 \n",
      "\n",
      "Epoch 735\n",
      "-------------------------------\n",
      "Loss: 0.000063  [   64/ 7049]\n",
      "At step count 81475\n",
      "Loss: 0.000051  [ 6464/ 7049]\n",
      "At step count 81575\n",
      "Test Error: \n",
      " Avg loss: 0.001662 \n",
      "\n",
      "Epoch 736\n",
      "-------------------------------\n",
      "Loss: 0.000042  [   64/ 7049]\n",
      "At step count 81586\n",
      "Loss: 0.000095  [ 6464/ 7049]\n",
      "At step count 81686\n",
      "Test Error: \n",
      " Avg loss: 0.001237 \n",
      "\n",
      "Epoch 737\n",
      "-------------------------------\n",
      "Loss: 0.000037  [   64/ 7049]\n",
      "At step count 81697\n",
      "Loss: 0.000045  [ 6464/ 7049]\n",
      "At step count 81797\n",
      "Test Error: \n",
      " Avg loss: 0.000997 \n",
      "\n",
      "Epoch 738\n",
      "-------------------------------\n",
      "Loss: 0.000136  [   64/ 7049]\n",
      "At step count 81808\n",
      "Loss: 0.000073  [ 6464/ 7049]\n",
      "At step count 81908\n",
      "Test Error: \n",
      " Avg loss: 0.000995 \n",
      "\n",
      "Epoch 739\n",
      "-------------------------------\n",
      "Loss: 0.000082  [   64/ 7049]\n",
      "At step count 81919\n",
      "Loss: 0.000044  [ 6464/ 7049]\n",
      "At step count 82019\n",
      "Test Error: \n",
      " Avg loss: 0.001803 \n",
      "\n",
      "Epoch 740\n",
      "-------------------------------\n",
      "Loss: 0.000186  [   64/ 7049]\n",
      "At step count 82030\n",
      "Loss: 0.000050  [ 6464/ 7049]\n",
      "At step count 82130\n",
      "Test Error: \n",
      " Avg loss: 0.001361 \n",
      "\n",
      "Epoch 741\n",
      "-------------------------------\n",
      "Loss: 0.000112  [   64/ 7049]\n",
      "At step count 82141\n",
      "Loss: 0.000056  [ 6464/ 7049]\n",
      "At step count 82241\n",
      "Test Error: \n",
      " Avg loss: 0.000910 \n",
      "\n",
      "Epoch 742\n",
      "-------------------------------\n",
      "Loss: 0.000069  [   64/ 7049]\n",
      "At step count 82252\n",
      "Loss: 0.000134  [ 6464/ 7049]\n",
      "At step count 82352\n",
      "Test Error: \n",
      " Avg loss: 0.000648 \n",
      "\n",
      "Epoch 743\n",
      "-------------------------------\n",
      "Loss: 0.000074  [   64/ 7049]\n",
      "At step count 82363\n",
      "Loss: 0.000130  [ 6464/ 7049]\n",
      "At step count 82463\n",
      "Test Error: \n",
      " Avg loss: 0.001569 \n",
      "\n",
      "Epoch 744\n",
      "-------------------------------\n",
      "Loss: 0.000178  [   64/ 7049]\n",
      "At step count 82474\n",
      "Loss: 0.000029  [ 6464/ 7049]\n",
      "At step count 82574\n",
      "Test Error: \n",
      " Avg loss: 0.001117 \n",
      "\n",
      "Epoch 745\n",
      "-------------------------------\n",
      "Loss: 0.000046  [   64/ 7049]\n",
      "At step count 82585\n",
      "Loss: 0.000044  [ 6464/ 7049]\n",
      "At step count 82685\n",
      "Test Error: \n",
      " Avg loss: 0.001334 \n",
      "\n",
      "Epoch 746\n",
      "-------------------------------\n",
      "Loss: 0.000041  [   64/ 7049]\n",
      "At step count 82696\n",
      "Loss: 0.000094  [ 6464/ 7049]\n",
      "At step count 82796\n",
      "Test Error: \n",
      " Avg loss: 0.001309 \n",
      "\n",
      "Epoch 747\n",
      "-------------------------------\n",
      "Loss: 0.000072  [   64/ 7049]\n",
      "At step count 82807\n",
      "Loss: 0.000049  [ 6464/ 7049]\n",
      "At step count 82907\n",
      "Test Error: \n",
      " Avg loss: 0.001384 \n",
      "\n",
      "Epoch 748\n",
      "-------------------------------\n",
      "Loss: 0.000069  [   64/ 7049]\n",
      "At step count 82918\n",
      "Loss: 0.000058  [ 6464/ 7049]\n",
      "At step count 83018\n",
      "Test Error: \n",
      " Avg loss: 0.001083 \n",
      "\n",
      "Epoch 749\n",
      "-------------------------------\n",
      "Loss: 0.000605  [   64/ 7049]\n",
      "At step count 83029\n",
      "Loss: 0.000077  [ 6464/ 7049]\n",
      "At step count 83129\n",
      "Test Error: \n",
      " Avg loss: 0.000845 \n",
      "\n",
      "Epoch 750\n",
      "-------------------------------\n",
      "Loss: 0.000056  [   64/ 7049]\n",
      "At step count 83140\n",
      "Loss: 0.000083  [ 6464/ 7049]\n",
      "At step count 83240\n",
      "Test Error: \n",
      " Avg loss: 0.001178 \n",
      "\n",
      "Epoch 751\n",
      "-------------------------------\n",
      "Loss: 0.000071  [   64/ 7049]\n",
      "At step count 83251\n",
      "Loss: 0.000114  [ 6464/ 7049]\n",
      "At step count 83351\n",
      "Test Error: \n",
      " Avg loss: 0.000929 \n",
      "\n",
      "Epoch 752\n",
      "-------------------------------\n",
      "Loss: 0.000074  [   64/ 7049]\n",
      "At step count 83362\n",
      "Loss: 0.000080  [ 6464/ 7049]\n",
      "At step count 83462\n",
      "Test Error: \n",
      " Avg loss: 0.000911 \n",
      "\n",
      "Epoch 753\n",
      "-------------------------------\n",
      "Loss: 0.000042  [   64/ 7049]\n",
      "At step count 83473\n",
      "Loss: 0.000039  [ 6464/ 7049]\n",
      "At step count 83573\n",
      "Test Error: \n",
      " Avg loss: 0.001251 \n",
      "\n",
      "Epoch 754\n",
      "-------------------------------\n",
      "Loss: 0.000054  [   64/ 7049]\n",
      "At step count 83584\n",
      "Loss: 0.000045  [ 6464/ 7049]\n",
      "At step count 83684\n",
      "Test Error: \n",
      " Avg loss: 0.000939 \n",
      "\n",
      "Epoch 755\n",
      "-------------------------------\n",
      "Loss: 0.000072  [   64/ 7049]\n",
      "At step count 83695\n",
      "Loss: 0.000037  [ 6464/ 7049]\n",
      "At step count 83795\n",
      "Test Error: \n",
      " Avg loss: 0.000700 \n",
      "\n",
      "Epoch 756\n",
      "-------------------------------\n",
      "Loss: 0.000075  [   64/ 7049]\n",
      "At step count 83806\n",
      "Loss: 0.000037  [ 6464/ 7049]\n",
      "At step count 83906\n",
      "Test Error: \n",
      " Avg loss: 0.000877 \n",
      "\n",
      "Epoch 757\n",
      "-------------------------------\n",
      "Loss: 0.000086  [   64/ 7049]\n",
      "At step count 83917\n",
      "Loss: 0.000040  [ 6464/ 7049]\n",
      "At step count 84017\n",
      "Test Error: \n",
      " Avg loss: 0.001062 \n",
      "\n",
      "Epoch 758\n",
      "-------------------------------\n",
      "Loss: 0.000092  [   64/ 7049]\n",
      "At step count 84028\n",
      "Loss: 0.000040  [ 6464/ 7049]\n",
      "At step count 84128\n",
      "Test Error: \n",
      " Avg loss: 0.001033 \n",
      "\n",
      "Epoch 759\n",
      "-------------------------------\n",
      "Loss: 0.000172  [   64/ 7049]\n",
      "At step count 84139\n",
      "Loss: 0.000034  [ 6464/ 7049]\n",
      "At step count 84239\n",
      "Test Error: \n",
      " Avg loss: 0.001187 \n",
      "\n",
      "Epoch 760\n",
      "-------------------------------\n",
      "Loss: 0.000050  [   64/ 7049]\n",
      "At step count 84250\n",
      "Loss: 0.000071  [ 6464/ 7049]\n",
      "At step count 84350\n",
      "Test Error: \n",
      " Avg loss: 0.001015 \n",
      "\n",
      "Epoch 761\n",
      "-------------------------------\n",
      "Loss: 0.000081  [   64/ 7049]\n",
      "At step count 84361\n",
      "Loss: 0.000092  [ 6464/ 7049]\n",
      "At step count 84461\n",
      "Test Error: \n",
      " Avg loss: 0.001107 \n",
      "\n",
      "Epoch 762\n",
      "-------------------------------\n",
      "Loss: 0.000058  [   64/ 7049]\n",
      "At step count 84472\n",
      "Loss: 0.000090  [ 6464/ 7049]\n",
      "At step count 84572\n",
      "Test Error: \n",
      " Avg loss: 0.001485 \n",
      "\n",
      "Epoch 763\n",
      "-------------------------------\n",
      "Loss: 0.000041  [   64/ 7049]\n",
      "At step count 84583\n",
      "Loss: 0.000052  [ 6464/ 7049]\n",
      "At step count 84683\n",
      "Test Error: \n",
      " Avg loss: 0.001314 \n",
      "\n",
      "Epoch 764\n",
      "-------------------------------\n",
      "Loss: 0.000039  [   64/ 7049]\n",
      "At step count 84694\n",
      "Loss: 0.000081  [ 6464/ 7049]\n",
      "At step count 84794\n",
      "Test Error: \n",
      " Avg loss: 0.000936 \n",
      "\n",
      "Epoch 765\n",
      "-------------------------------\n",
      "Loss: 0.000052  [   64/ 7049]\n",
      "At step count 84805\n",
      "Loss: 0.000041  [ 6464/ 7049]\n",
      "At step count 84905\n",
      "Test Error: \n",
      " Avg loss: 0.001127 \n",
      "\n",
      "Epoch 766\n",
      "-------------------------------\n",
      "Loss: 0.000057  [   64/ 7049]\n",
      "At step count 84916\n",
      "Loss: 0.000049  [ 6464/ 7049]\n",
      "At step count 85016\n",
      "Test Error: \n",
      " Avg loss: 0.000997 \n",
      "\n",
      "Epoch 767\n",
      "-------------------------------\n",
      "Loss: 0.000035  [   64/ 7049]\n",
      "At step count 85027\n",
      "Loss: 0.000067  [ 6464/ 7049]\n",
      "At step count 85127\n",
      "Test Error: \n",
      " Avg loss: 0.000999 \n",
      "\n",
      "Epoch 768\n",
      "-------------------------------\n",
      "Loss: 0.000042  [   64/ 7049]\n",
      "At step count 85138\n",
      "Loss: 0.000071  [ 6464/ 7049]\n",
      "At step count 85238\n",
      "Test Error: \n",
      " Avg loss: 0.000883 \n",
      "\n",
      "Epoch 769\n",
      "-------------------------------\n",
      "Loss: 0.000085  [   64/ 7049]\n",
      "At step count 85249\n",
      "Loss: 0.000074  [ 6464/ 7049]\n",
      "At step count 85349\n",
      "Test Error: \n",
      " Avg loss: 0.000856 \n",
      "\n",
      "Epoch 770\n",
      "-------------------------------\n",
      "Loss: 0.000081  [   64/ 7049]\n",
      "At step count 85360\n",
      "Loss: 0.000067  [ 6464/ 7049]\n",
      "At step count 85460\n",
      "Test Error: \n",
      " Avg loss: 0.000606 \n",
      "\n",
      "Epoch 771\n",
      "-------------------------------\n",
      "Loss: 0.000072  [   64/ 7049]\n",
      "At step count 85471\n",
      "Loss: 0.000049  [ 6464/ 7049]\n",
      "At step count 85571\n",
      "Test Error: \n",
      " Avg loss: 0.000924 \n",
      "\n",
      "Epoch 772\n",
      "-------------------------------\n",
      "Loss: 0.000220  [   64/ 7049]\n",
      "At step count 85582\n",
      "Loss: 0.000036  [ 6464/ 7049]\n",
      "At step count 85682\n",
      "Test Error: \n",
      " Avg loss: 0.001057 \n",
      "\n",
      "Epoch 773\n",
      "-------------------------------\n",
      "Loss: 0.000042  [   64/ 7049]\n",
      "At step count 85693\n",
      "Loss: 0.000144  [ 6464/ 7049]\n",
      "At step count 85793\n",
      "Test Error: \n",
      " Avg loss: 0.000976 \n",
      "\n",
      "Epoch 774\n",
      "-------------------------------\n",
      "Loss: 0.000064  [   64/ 7049]\n",
      "At step count 85804\n",
      "Loss: 0.000059  [ 6464/ 7049]\n",
      "At step count 85904\n",
      "Test Error: \n",
      " Avg loss: 0.000986 \n",
      "\n",
      "Epoch 775\n",
      "-------------------------------\n",
      "Loss: 0.000059  [   64/ 7049]\n",
      "At step count 85915\n",
      "Loss: 0.000054  [ 6464/ 7049]\n",
      "At step count 86015\n",
      "Test Error: \n",
      " Avg loss: 0.000762 \n",
      "\n",
      "Epoch 776\n",
      "-------------------------------\n",
      "Loss: 0.000041  [   64/ 7049]\n",
      "At step count 86026\n",
      "Loss: 0.000084  [ 6464/ 7049]\n",
      "At step count 86126\n",
      "Test Error: \n",
      " Avg loss: 0.000896 \n",
      "\n",
      "Epoch 777\n",
      "-------------------------------\n",
      "Loss: 0.000095  [   64/ 7049]\n",
      "At step count 86137\n",
      "Loss: 0.000082  [ 6464/ 7049]\n",
      "At step count 86237\n",
      "Test Error: \n",
      " Avg loss: 0.000596 \n",
      "\n",
      "Epoch 778\n",
      "-------------------------------\n",
      "Loss: 0.000065  [   64/ 7049]\n",
      "At step count 86248\n",
      "Loss: 0.000056  [ 6464/ 7049]\n",
      "At step count 86348\n",
      "Test Error: \n",
      " Avg loss: 0.001075 \n",
      "\n",
      "Epoch 779\n",
      "-------------------------------\n",
      "Loss: 0.000065  [   64/ 7049]\n",
      "At step count 86359\n",
      "Loss: 0.000072  [ 6464/ 7049]\n",
      "At step count 86459\n",
      "Test Error: \n",
      " Avg loss: 0.000773 \n",
      "\n",
      "Epoch 780\n",
      "-------------------------------\n",
      "Loss: 0.000075  [   64/ 7049]\n",
      "At step count 86470\n",
      "Loss: 0.000259  [ 6464/ 7049]\n",
      "At step count 86570\n",
      "Test Error: \n",
      " Avg loss: 0.000799 \n",
      "\n",
      "Epoch 781\n",
      "-------------------------------\n",
      "Loss: 0.000060  [   64/ 7049]\n",
      "At step count 86581\n",
      "Loss: 0.000096  [ 6464/ 7049]\n",
      "At step count 86681\n",
      "Test Error: \n",
      " Avg loss: 0.000696 \n",
      "\n",
      "Epoch 782\n",
      "-------------------------------\n",
      "Loss: 0.000088  [   64/ 7049]\n",
      "At step count 86692\n",
      "Loss: 0.000046  [ 6464/ 7049]\n",
      "At step count 86792\n",
      "Test Error: \n",
      " Avg loss: 0.000463 \n",
      "\n",
      "Epoch 783\n",
      "-------------------------------\n",
      "Loss: 0.000074  [   64/ 7049]\n",
      "At step count 86803\n",
      "Loss: 0.000078  [ 6464/ 7049]\n",
      "At step count 86903\n",
      "Test Error: \n",
      " Avg loss: 0.000670 \n",
      "\n",
      "Epoch 784\n",
      "-------------------------------\n",
      "Loss: 0.000081  [   64/ 7049]\n",
      "At step count 86914\n",
      "Loss: 0.000096  [ 6464/ 7049]\n",
      "At step count 87014\n",
      "Test Error: \n",
      " Avg loss: 0.001007 \n",
      "\n",
      "Epoch 785\n",
      "-------------------------------\n",
      "Loss: 0.000045  [   64/ 7049]\n",
      "At step count 87025\n",
      "Loss: 0.000056  [ 6464/ 7049]\n",
      "At step count 87125\n",
      "Test Error: \n",
      " Avg loss: 0.001165 \n",
      "\n",
      "Epoch 786\n",
      "-------------------------------\n",
      "Loss: 0.000058  [   64/ 7049]\n",
      "At step count 87136\n",
      "Loss: 0.000051  [ 6464/ 7049]\n",
      "At step count 87236\n",
      "Test Error: \n",
      " Avg loss: 0.001007 \n",
      "\n",
      "Epoch 787\n",
      "-------------------------------\n",
      "Loss: 0.000052  [   64/ 7049]\n",
      "At step count 87247\n",
      "Loss: 0.000051  [ 6464/ 7049]\n",
      "At step count 87347\n",
      "Test Error: \n",
      " Avg loss: 0.000618 \n",
      "\n",
      "Epoch 788\n",
      "-------------------------------\n",
      "Loss: 0.000080  [   64/ 7049]\n",
      "At step count 87358\n",
      "Loss: 0.000140  [ 6464/ 7049]\n",
      "At step count 87458\n",
      "Test Error: \n",
      " Avg loss: 0.000807 \n",
      "\n",
      "Epoch 789\n",
      "-------------------------------\n",
      "Loss: 0.000098  [   64/ 7049]\n",
      "At step count 87469\n",
      "Loss: 0.000055  [ 6464/ 7049]\n",
      "At step count 87569\n",
      "Test Error: \n",
      " Avg loss: 0.001187 \n",
      "\n",
      "Epoch 790\n",
      "-------------------------------\n",
      "Loss: 0.000089  [   64/ 7049]\n",
      "At step count 87580\n",
      "Loss: 0.000056  [ 6464/ 7049]\n",
      "At step count 87680\n",
      "Test Error: \n",
      " Avg loss: 0.000981 \n",
      "\n",
      "Epoch 791\n",
      "-------------------------------\n",
      "Loss: 0.000064  [   64/ 7049]\n",
      "At step count 87691\n",
      "Loss: 0.000062  [ 6464/ 7049]\n",
      "At step count 87791\n",
      "Test Error: \n",
      " Avg loss: 0.001321 \n",
      "\n",
      "Epoch 792\n",
      "-------------------------------\n",
      "Loss: 0.000096  [   64/ 7049]\n",
      "At step count 87802\n",
      "Loss: 0.000065  [ 6464/ 7049]\n",
      "At step count 87902\n",
      "Test Error: \n",
      " Avg loss: 0.000758 \n",
      "\n",
      "Epoch 793\n",
      "-------------------------------\n",
      "Loss: 0.000055  [   64/ 7049]\n",
      "At step count 87913\n",
      "Loss: 0.000129  [ 6464/ 7049]\n",
      "At step count 88013\n",
      "Test Error: \n",
      " Avg loss: 0.001006 \n",
      "\n",
      "Epoch 794\n",
      "-------------------------------\n",
      "Loss: 0.000050  [   64/ 7049]\n",
      "At step count 88024\n",
      "Loss: 0.000078  [ 6464/ 7049]\n",
      "At step count 88124\n",
      "Test Error: \n",
      " Avg loss: 0.001185 \n",
      "\n",
      "Epoch 795\n",
      "-------------------------------\n",
      "Loss: 0.000079  [   64/ 7049]\n",
      "At step count 88135\n",
      "Loss: 0.000054  [ 6464/ 7049]\n",
      "At step count 88235\n",
      "Test Error: \n",
      " Avg loss: 0.000750 \n",
      "\n",
      "Epoch 796\n",
      "-------------------------------\n",
      "Loss: 0.000160  [   64/ 7049]\n",
      "At step count 88246\n",
      "Loss: 0.000033  [ 6464/ 7049]\n",
      "At step count 88346\n",
      "Test Error: \n",
      " Avg loss: 0.000641 \n",
      "\n",
      "Epoch 797\n",
      "-------------------------------\n",
      "Loss: 0.000064  [   64/ 7049]\n",
      "At step count 88357\n",
      "Loss: 0.000050  [ 6464/ 7049]\n",
      "At step count 88457\n",
      "Test Error: \n",
      " Avg loss: 0.000879 \n",
      "\n",
      "Epoch 798\n",
      "-------------------------------\n",
      "Loss: 0.000050  [   64/ 7049]\n",
      "At step count 88468\n",
      "Loss: 0.000053  [ 6464/ 7049]\n",
      "At step count 88568\n",
      "Test Error: \n",
      " Avg loss: 0.001083 \n",
      "\n",
      "Epoch 799\n",
      "-------------------------------\n",
      "Loss: 0.000078  [   64/ 7049]\n",
      "At step count 88579\n",
      "Loss: 0.000070  [ 6464/ 7049]\n",
      "At step count 88679\n",
      "Test Error: \n",
      " Avg loss: 0.001110 \n",
      "\n",
      "Epoch 800\n",
      "-------------------------------\n",
      "Loss: 0.000051  [   64/ 7049]\n",
      "At step count 88690\n",
      "Loss: 0.000046  [ 6464/ 7049]\n",
      "At step count 88790\n",
      "Test Error: \n",
      " Avg loss: 0.000861 \n",
      "\n",
      "Epoch 801\n",
      "-------------------------------\n",
      "Loss: 0.000043  [   64/ 7049]\n",
      "At step count 88801\n",
      "Loss: 0.000048  [ 6464/ 7049]\n",
      "At step count 88901\n",
      "Test Error: \n",
      " Avg loss: 0.000857 \n",
      "\n",
      "Epoch 802\n",
      "-------------------------------\n",
      "Loss: 0.000071  [   64/ 7049]\n",
      "At step count 88912\n",
      "Loss: 0.000046  [ 6464/ 7049]\n",
      "At step count 89012\n",
      "Test Error: \n",
      " Avg loss: 0.000945 \n",
      "\n",
      "Epoch 803\n",
      "-------------------------------\n",
      "Loss: 0.000167  [   64/ 7049]\n",
      "At step count 89023\n",
      "Loss: 0.000038  [ 6464/ 7049]\n",
      "At step count 89123\n",
      "Test Error: \n",
      " Avg loss: 0.001692 \n",
      "\n",
      "Epoch 804\n",
      "-------------------------------\n",
      "Loss: 0.000079  [   64/ 7049]\n",
      "At step count 89134\n",
      "Loss: 0.000551  [ 6464/ 7049]\n",
      "At step count 89234\n",
      "Test Error: \n",
      " Avg loss: 0.001311 \n",
      "\n",
      "Epoch 805\n",
      "-------------------------------\n",
      "Loss: 0.000073  [   64/ 7049]\n",
      "At step count 89245\n",
      "Loss: 0.000111  [ 6464/ 7049]\n",
      "At step count 89345\n",
      "Test Error: \n",
      " Avg loss: 0.001415 \n",
      "\n",
      "Epoch 806\n",
      "-------------------------------\n",
      "Loss: 0.000051  [   64/ 7049]\n",
      "At step count 89356\n",
      "Loss: 0.000044  [ 6464/ 7049]\n",
      "At step count 89456\n",
      "Test Error: \n",
      " Avg loss: 0.000857 \n",
      "\n",
      "Epoch 807\n",
      "-------------------------------\n",
      "Loss: 0.000067  [   64/ 7049]\n",
      "At step count 89467\n",
      "Loss: 0.000047  [ 6464/ 7049]\n",
      "At step count 89567\n",
      "Test Error: \n",
      " Avg loss: 0.001166 \n",
      "\n",
      "Epoch 808\n",
      "-------------------------------\n",
      "Loss: 0.000059  [   64/ 7049]\n",
      "At step count 89578\n",
      "Loss: 0.000043  [ 6464/ 7049]\n",
      "At step count 89678\n",
      "Test Error: \n",
      " Avg loss: 0.001545 \n",
      "\n",
      "Epoch 809\n",
      "-------------------------------\n",
      "Loss: 0.000057  [   64/ 7049]\n",
      "At step count 89689\n",
      "Loss: 0.000101  [ 6464/ 7049]\n",
      "At step count 89789\n",
      "Test Error: \n",
      " Avg loss: 0.001886 \n",
      "\n",
      "Epoch 810\n",
      "-------------------------------\n",
      "Loss: 0.000067  [   64/ 7049]\n",
      "At step count 89800\n",
      "Loss: 0.000055  [ 6464/ 7049]\n",
      "At step count 89900\n",
      "Test Error: \n",
      " Avg loss: 0.001067 \n",
      "\n",
      "Epoch 811\n",
      "-------------------------------\n",
      "Loss: 0.000056  [   64/ 7049]\n",
      "At step count 89911\n",
      "Loss: 0.000075  [ 6464/ 7049]\n",
      "At step count 90011\n",
      "Test Error: \n",
      " Avg loss: 0.001726 \n",
      "\n",
      "Epoch 812\n",
      "-------------------------------\n",
      "Loss: 0.000038  [   64/ 7049]\n",
      "At step count 90022\n",
      "Loss: 0.000025  [ 6464/ 7049]\n",
      "At step count 90122\n",
      "Test Error: \n",
      " Avg loss: 0.001273 \n",
      "\n",
      "Epoch 813\n",
      "-------------------------------\n",
      "Loss: 0.000068  [   64/ 7049]\n",
      "At step count 90133\n",
      "Loss: 0.000110  [ 6464/ 7049]\n",
      "At step count 90233\n",
      "Test Error: \n",
      " Avg loss: 0.001563 \n",
      "\n",
      "Epoch 814\n",
      "-------------------------------\n",
      "Loss: 0.000047  [   64/ 7049]\n",
      "At step count 90244\n",
      "Loss: 0.000090  [ 6464/ 7049]\n",
      "At step count 90344\n",
      "Test Error: \n",
      " Avg loss: 0.000924 \n",
      "\n",
      "Epoch 815\n",
      "-------------------------------\n",
      "Loss: 0.000036  [   64/ 7049]\n",
      "At step count 90355\n",
      "Loss: 0.000057  [ 6464/ 7049]\n",
      "At step count 90455\n",
      "Test Error: \n",
      " Avg loss: 0.001261 \n",
      "\n",
      "Epoch 816\n",
      "-------------------------------\n",
      "Loss: 0.000139  [   64/ 7049]\n",
      "At step count 90466\n",
      "Loss: 0.000074  [ 6464/ 7049]\n",
      "At step count 90566\n",
      "Test Error: \n",
      " Avg loss: 0.001473 \n",
      "\n",
      "Epoch 817\n",
      "-------------------------------\n",
      "Loss: 0.000054  [   64/ 7049]\n",
      "At step count 90577\n",
      "Loss: 0.000069  [ 6464/ 7049]\n",
      "At step count 90677\n",
      "Test Error: \n",
      " Avg loss: 0.001000 \n",
      "\n",
      "Epoch 818\n",
      "-------------------------------\n",
      "Loss: 0.000189  [   64/ 7049]\n",
      "At step count 90688\n",
      "Loss: 0.000060  [ 6464/ 7049]\n",
      "At step count 90788\n",
      "Test Error: \n",
      " Avg loss: 0.000791 \n",
      "\n",
      "Epoch 819\n",
      "-------------------------------\n",
      "Loss: 0.000061  [   64/ 7049]\n",
      "At step count 90799\n",
      "Loss: 0.000039  [ 6464/ 7049]\n",
      "At step count 90899\n",
      "Test Error: \n",
      " Avg loss: 0.001220 \n",
      "\n",
      "Epoch 820\n",
      "-------------------------------\n",
      "Loss: 0.000050  [   64/ 7049]\n",
      "At step count 90910\n",
      "Loss: 0.000044  [ 6464/ 7049]\n",
      "At step count 91010\n",
      "Test Error: \n",
      " Avg loss: 0.001235 \n",
      "\n",
      "Epoch 821\n",
      "-------------------------------\n",
      "Loss: 0.000118  [   64/ 7049]\n",
      "At step count 91021\n",
      "Loss: 0.000073  [ 6464/ 7049]\n",
      "At step count 91121\n",
      "Test Error: \n",
      " Avg loss: 0.001035 \n",
      "\n",
      "Epoch 822\n",
      "-------------------------------\n",
      "Loss: 0.000059  [   64/ 7049]\n",
      "At step count 91132\n",
      "Loss: 0.000032  [ 6464/ 7049]\n",
      "At step count 91232\n",
      "Test Error: \n",
      " Avg loss: 0.001188 \n",
      "\n",
      "Epoch 823\n",
      "-------------------------------\n",
      "Loss: 0.000035  [   64/ 7049]\n",
      "At step count 91243\n",
      "Loss: 0.000087  [ 6464/ 7049]\n",
      "At step count 91343\n",
      "Test Error: \n",
      " Avg loss: 0.001457 \n",
      "\n",
      "Epoch 824\n",
      "-------------------------------\n",
      "Loss: 0.000047  [   64/ 7049]\n",
      "At step count 91354\n",
      "Loss: 0.000052  [ 6464/ 7049]\n",
      "At step count 91454\n",
      "Test Error: \n",
      " Avg loss: 0.001457 \n",
      "\n",
      "Epoch 825\n",
      "-------------------------------\n",
      "Loss: 0.000137  [   64/ 7049]\n",
      "At step count 91465\n",
      "Loss: 0.000203  [ 6464/ 7049]\n",
      "At step count 91565\n",
      "Test Error: \n",
      " Avg loss: 0.001245 \n",
      "\n",
      "Epoch 826\n",
      "-------------------------------\n",
      "Loss: 0.000090  [   64/ 7049]\n",
      "At step count 91576\n",
      "Loss: 0.000154  [ 6464/ 7049]\n",
      "At step count 91676\n",
      "Test Error: \n",
      " Avg loss: 0.002848 \n",
      "\n",
      "Epoch 827\n",
      "-------------------------------\n",
      "Loss: 0.000050  [   64/ 7049]\n",
      "At step count 91687\n",
      "Loss: 0.000094  [ 6464/ 7049]\n",
      "At step count 91787\n",
      "Test Error: \n",
      " Avg loss: 0.001249 \n",
      "\n",
      "Epoch 828\n",
      "-------------------------------\n",
      "Loss: 0.000055  [   64/ 7049]\n",
      "At step count 91798\n",
      "Loss: 0.000036  [ 6464/ 7049]\n",
      "At step count 91898\n",
      "Test Error: \n",
      " Avg loss: 0.000815 \n",
      "\n",
      "Epoch 829\n",
      "-------------------------------\n",
      "Loss: 0.000118  [   64/ 7049]\n",
      "At step count 91909\n",
      "Loss: 0.000165  [ 6464/ 7049]\n",
      "At step count 92009\n",
      "Test Error: \n",
      " Avg loss: 0.001218 \n",
      "\n",
      "Epoch 830\n",
      "-------------------------------\n",
      "Loss: 0.000535  [   64/ 7049]\n",
      "At step count 92020\n",
      "Loss: 0.000077  [ 6464/ 7049]\n",
      "At step count 92120\n",
      "Test Error: \n",
      " Avg loss: 0.001297 \n",
      "\n",
      "Epoch 831\n",
      "-------------------------------\n",
      "Loss: 0.000047  [   64/ 7049]\n",
      "At step count 92131\n",
      "Loss: 0.000172  [ 6464/ 7049]\n",
      "At step count 92231\n",
      "Test Error: \n",
      " Avg loss: 0.001058 \n",
      "\n",
      "Epoch 832\n",
      "-------------------------------\n",
      "Loss: 0.000608  [   64/ 7049]\n",
      "At step count 92242\n",
      "Loss: 0.000077  [ 6464/ 7049]\n",
      "At step count 92342\n",
      "Test Error: \n",
      " Avg loss: 0.001116 \n",
      "\n",
      "Epoch 833\n",
      "-------------------------------\n",
      "Loss: 0.000059  [   64/ 7049]\n",
      "At step count 92353\n",
      "Loss: 0.000081  [ 6464/ 7049]\n",
      "At step count 92453\n",
      "Test Error: \n",
      " Avg loss: 0.001638 \n",
      "\n",
      "Epoch 834\n",
      "-------------------------------\n",
      "Loss: 0.000069  [   64/ 7049]\n",
      "At step count 92464\n",
      "Loss: 0.000109  [ 6464/ 7049]\n",
      "At step count 92564\n",
      "Test Error: \n",
      " Avg loss: 0.001425 \n",
      "\n",
      "Epoch 835\n",
      "-------------------------------\n",
      "Loss: 0.000047  [   64/ 7049]\n",
      "At step count 92575\n",
      "Loss: 0.000278  [ 6464/ 7049]\n",
      "At step count 92675\n",
      "Test Error: \n",
      " Avg loss: 0.000914 \n",
      "\n",
      "Epoch 836\n",
      "-------------------------------\n",
      "Loss: 0.000105  [   64/ 7049]\n",
      "At step count 92686\n",
      "Loss: 0.000072  [ 6464/ 7049]\n",
      "At step count 92786\n",
      "Test Error: \n",
      " Avg loss: 0.001182 \n",
      "\n",
      "Epoch 837\n",
      "-------------------------------\n",
      "Loss: 0.000041  [   64/ 7049]\n",
      "At step count 92797\n",
      "Loss: 0.000035  [ 6464/ 7049]\n",
      "At step count 92897\n",
      "Test Error: \n",
      " Avg loss: 0.000988 \n",
      "\n",
      "Epoch 838\n",
      "-------------------------------\n",
      "Loss: 0.000163  [   64/ 7049]\n",
      "At step count 92908\n",
      "Loss: 0.000061  [ 6464/ 7049]\n",
      "At step count 93008\n",
      "Test Error: \n",
      " Avg loss: 0.001346 \n",
      "\n",
      "Epoch 839\n",
      "-------------------------------\n",
      "Loss: 0.000072  [   64/ 7049]\n",
      "At step count 93019\n",
      "Loss: 0.000049  [ 6464/ 7049]\n",
      "At step count 93119\n",
      "Test Error: \n",
      " Avg loss: 0.001402 \n",
      "\n",
      "Epoch 840\n",
      "-------------------------------\n",
      "Loss: 0.000040  [   64/ 7049]\n",
      "At step count 93130\n",
      "Loss: 0.000156  [ 6464/ 7049]\n",
      "At step count 93230\n",
      "Test Error: \n",
      " Avg loss: 0.000713 \n",
      "\n",
      "Epoch 841\n",
      "-------------------------------\n",
      "Loss: 0.000054  [   64/ 7049]\n",
      "At step count 93241\n",
      "Loss: 0.000097  [ 6464/ 7049]\n",
      "At step count 93341\n",
      "Test Error: \n",
      " Avg loss: 0.001257 \n",
      "\n",
      "Epoch 842\n",
      "-------------------------------\n",
      "Loss: 0.000092  [   64/ 7049]\n",
      "At step count 93352\n",
      "Loss: 0.000065  [ 6464/ 7049]\n",
      "At step count 93452\n",
      "Test Error: \n",
      " Avg loss: 0.001188 \n",
      "\n",
      "Epoch 843\n",
      "-------------------------------\n",
      "Loss: 0.000091  [   64/ 7049]\n",
      "At step count 93463\n",
      "Loss: 0.000047  [ 6464/ 7049]\n",
      "At step count 93563\n",
      "Test Error: \n",
      " Avg loss: 0.001137 \n",
      "\n",
      "Epoch 844\n",
      "-------------------------------\n",
      "Loss: 0.000111  [   64/ 7049]\n",
      "At step count 93574\n",
      "Loss: 0.000070  [ 6464/ 7049]\n",
      "At step count 93674\n",
      "Test Error: \n",
      " Avg loss: 0.001704 \n",
      "\n",
      "Epoch 845\n",
      "-------------------------------\n",
      "Loss: 0.000103  [   64/ 7049]\n",
      "At step count 93685\n",
      "Loss: 0.000063  [ 6464/ 7049]\n",
      "At step count 93785\n",
      "Test Error: \n",
      " Avg loss: 0.000655 \n",
      "\n",
      "Epoch 846\n",
      "-------------------------------\n",
      "Loss: 0.000062  [   64/ 7049]\n",
      "At step count 93796\n",
      "Loss: 0.000109  [ 6464/ 7049]\n",
      "At step count 93896\n",
      "Test Error: \n",
      " Avg loss: 0.000751 \n",
      "\n",
      "Epoch 847\n",
      "-------------------------------\n",
      "Loss: 0.000084  [   64/ 7049]\n",
      "At step count 93907\n",
      "Loss: 0.000054  [ 6464/ 7049]\n",
      "At step count 94007\n",
      "Test Error: \n",
      " Avg loss: 0.001799 \n",
      "\n",
      "Epoch 848\n",
      "-------------------------------\n",
      "Loss: 0.000076  [   64/ 7049]\n",
      "At step count 94018\n",
      "Loss: 0.000064  [ 6464/ 7049]\n",
      "At step count 94118\n",
      "Test Error: \n",
      " Avg loss: 0.001098 \n",
      "\n",
      "Epoch 849\n",
      "-------------------------------\n",
      "Loss: 0.000090  [   64/ 7049]\n",
      "At step count 94129\n",
      "Loss: 0.000083  [ 6464/ 7049]\n",
      "At step count 94229\n",
      "Test Error: \n",
      " Avg loss: 0.001444 \n",
      "\n",
      "Epoch 850\n",
      "-------------------------------\n",
      "Loss: 0.000084  [   64/ 7049]\n",
      "At step count 94240\n",
      "Loss: 0.000082  [ 6464/ 7049]\n",
      "At step count 94340\n",
      "Test Error: \n",
      " Avg loss: 0.000773 \n",
      "\n",
      "Epoch 851\n",
      "-------------------------------\n",
      "Loss: 0.000074  [   64/ 7049]\n",
      "At step count 94351\n",
      "Loss: 0.000056  [ 6464/ 7049]\n",
      "At step count 94451\n",
      "Test Error: \n",
      " Avg loss: 0.000685 \n",
      "\n",
      "Epoch 852\n",
      "-------------------------------\n",
      "Loss: 0.000049  [   64/ 7049]\n",
      "At step count 94462\n",
      "Loss: 0.000056  [ 6464/ 7049]\n",
      "At step count 94562\n",
      "Test Error: \n",
      " Avg loss: 0.000994 \n",
      "\n",
      "Epoch 853\n",
      "-------------------------------\n",
      "Loss: 0.000059  [   64/ 7049]\n",
      "At step count 94573\n",
      "Loss: 0.000075  [ 6464/ 7049]\n",
      "At step count 94673\n",
      "Test Error: \n",
      " Avg loss: 0.001233 \n",
      "\n",
      "Epoch 854\n",
      "-------------------------------\n",
      "Loss: 0.000066  [   64/ 7049]\n",
      "At step count 94684\n",
      "Loss: 0.000065  [ 6464/ 7049]\n",
      "At step count 94784\n",
      "Test Error: \n",
      " Avg loss: 0.000827 \n",
      "\n",
      "Epoch 855\n",
      "-------------------------------\n",
      "Loss: 0.000050  [   64/ 7049]\n",
      "At step count 94795\n",
      "Loss: 0.000645  [ 6464/ 7049]\n",
      "At step count 94895\n",
      "Test Error: \n",
      " Avg loss: 0.000678 \n",
      "\n",
      "Epoch 856\n",
      "-------------------------------\n",
      "Loss: 0.000050  [   64/ 7049]\n",
      "At step count 94906\n",
      "Loss: 0.000077  [ 6464/ 7049]\n",
      "At step count 95006\n",
      "Test Error: \n",
      " Avg loss: 0.000899 \n",
      "\n",
      "Epoch 857\n",
      "-------------------------------\n",
      "Loss: 0.000066  [   64/ 7049]\n",
      "At step count 95017\n",
      "Loss: 0.000102  [ 6464/ 7049]\n",
      "At step count 95117\n",
      "Test Error: \n",
      " Avg loss: 0.001592 \n",
      "\n",
      "Epoch 858\n",
      "-------------------------------\n",
      "Loss: 0.000059  [   64/ 7049]\n",
      "At step count 95128\n",
      "Loss: 0.000077  [ 6464/ 7049]\n",
      "At step count 95228\n",
      "Test Error: \n",
      " Avg loss: 0.000691 \n",
      "\n",
      "Epoch 859\n",
      "-------------------------------\n",
      "Loss: 0.000054  [   64/ 7049]\n",
      "At step count 95239\n",
      "Loss: 0.000046  [ 6464/ 7049]\n",
      "At step count 95339\n",
      "Test Error: \n",
      " Avg loss: 0.001122 \n",
      "\n",
      "Epoch 860\n",
      "-------------------------------\n",
      "Loss: 0.000057  [   64/ 7049]\n",
      "At step count 95350\n",
      "Loss: 0.000062  [ 6464/ 7049]\n",
      "At step count 95450\n",
      "Test Error: \n",
      " Avg loss: 0.001097 \n",
      "\n",
      "Epoch 861\n",
      "-------------------------------\n",
      "Loss: 0.000295  [   64/ 7049]\n",
      "At step count 95461\n",
      "Loss: 0.000052  [ 6464/ 7049]\n",
      "At step count 95561\n",
      "Test Error: \n",
      " Avg loss: 0.000835 \n",
      "\n",
      "Epoch 862\n",
      "-------------------------------\n",
      "Loss: 0.000056  [   64/ 7049]\n",
      "At step count 95572\n",
      "Loss: 0.000072  [ 6464/ 7049]\n",
      "At step count 95672\n",
      "Test Error: \n",
      " Avg loss: 0.001113 \n",
      "\n",
      "Epoch 863\n",
      "-------------------------------\n",
      "Loss: 0.000084  [   64/ 7049]\n",
      "At step count 95683\n",
      "Loss: 0.000049  [ 6464/ 7049]\n",
      "At step count 95783\n",
      "Test Error: \n",
      " Avg loss: 0.000930 \n",
      "\n",
      "Epoch 864\n",
      "-------------------------------\n",
      "Loss: 0.000168  [   64/ 7049]\n",
      "At step count 95794\n",
      "Loss: 0.000044  [ 6464/ 7049]\n",
      "At step count 95894\n",
      "Test Error: \n",
      " Avg loss: 0.000777 \n",
      "\n",
      "Epoch 865\n",
      "-------------------------------\n",
      "Loss: 0.000825  [   64/ 7049]\n",
      "At step count 95905\n",
      "Loss: 0.000094  [ 6464/ 7049]\n",
      "At step count 96005\n",
      "Test Error: \n",
      " Avg loss: 0.001397 \n",
      "\n",
      "Epoch 866\n",
      "-------------------------------\n",
      "Loss: 0.000035  [   64/ 7049]\n",
      "At step count 96016\n",
      "Loss: 0.000120  [ 6464/ 7049]\n",
      "At step count 96116\n",
      "Test Error: \n",
      " Avg loss: 0.001001 \n",
      "\n",
      "Epoch 867\n",
      "-------------------------------\n",
      "Loss: 0.000055  [   64/ 7049]\n",
      "At step count 96127\n",
      "Loss: 0.000081  [ 6464/ 7049]\n",
      "At step count 96227\n",
      "Test Error: \n",
      " Avg loss: 0.002234 \n",
      "\n",
      "Epoch 868\n",
      "-------------------------------\n",
      "Loss: 0.000080  [   64/ 7049]\n",
      "At step count 96238\n",
      "Loss: 0.000062  [ 6464/ 7049]\n",
      "At step count 96338\n",
      "Test Error: \n",
      " Avg loss: 0.000911 \n",
      "\n",
      "Epoch 869\n",
      "-------------------------------\n",
      "Loss: 0.000045  [   64/ 7049]\n",
      "At step count 96349\n",
      "Loss: 0.000065  [ 6464/ 7049]\n",
      "At step count 96449\n",
      "Test Error: \n",
      " Avg loss: 0.000857 \n",
      "\n",
      "Epoch 870\n",
      "-------------------------------\n",
      "Loss: 0.000052  [   64/ 7049]\n",
      "At step count 96460\n",
      "Loss: 0.000829  [ 6464/ 7049]\n",
      "At step count 96560\n",
      "Test Error: \n",
      " Avg loss: 0.000773 \n",
      "\n",
      "Epoch 871\n",
      "-------------------------------\n",
      "Loss: 0.000170  [   64/ 7049]\n",
      "At step count 96571\n",
      "Loss: 0.000058  [ 6464/ 7049]\n",
      "At step count 96671\n",
      "Test Error: \n",
      " Avg loss: 0.000943 \n",
      "\n",
      "Epoch 872\n",
      "-------------------------------\n",
      "Loss: 0.000117  [   64/ 7049]\n",
      "At step count 96682\n",
      "Loss: 0.000095  [ 6464/ 7049]\n",
      "At step count 96782\n",
      "Test Error: \n",
      " Avg loss: 0.001184 \n",
      "\n",
      "Epoch 873\n",
      "-------------------------------\n",
      "Loss: 0.000051  [   64/ 7049]\n",
      "At step count 96793\n",
      "Loss: 0.000054  [ 6464/ 7049]\n",
      "At step count 96893\n",
      "Test Error: \n",
      " Avg loss: 0.001156 \n",
      "\n",
      "Epoch 874\n",
      "-------------------------------\n",
      "Loss: 0.000076  [   64/ 7049]\n",
      "At step count 96904\n",
      "Loss: 0.000079  [ 6464/ 7049]\n",
      "At step count 97004\n",
      "Test Error: \n",
      " Avg loss: 0.000961 \n",
      "\n",
      "Epoch 875\n",
      "-------------------------------\n",
      "Loss: 0.000296  [   64/ 7049]\n",
      "At step count 97015\n",
      "Loss: 0.000049  [ 6464/ 7049]\n",
      "At step count 97115\n",
      "Test Error: \n",
      " Avg loss: 0.001153 \n",
      "\n",
      "Epoch 876\n",
      "-------------------------------\n",
      "Loss: 0.000033  [   64/ 7049]\n",
      "At step count 97126\n",
      "Loss: 0.000701  [ 6464/ 7049]\n",
      "At step count 97226\n",
      "Test Error: \n",
      " Avg loss: 0.000833 \n",
      "\n",
      "Epoch 877\n",
      "-------------------------------\n",
      "Loss: 0.000043  [   64/ 7049]\n",
      "At step count 97237\n",
      "Loss: 0.000053  [ 6464/ 7049]\n",
      "At step count 97337\n",
      "Test Error: \n",
      " Avg loss: 0.001315 \n",
      "\n",
      "Epoch 878\n",
      "-------------------------------\n",
      "Loss: 0.000112  [   64/ 7049]\n",
      "At step count 97348\n",
      "Loss: 0.000081  [ 6464/ 7049]\n",
      "At step count 97448\n",
      "Test Error: \n",
      " Avg loss: 0.001340 \n",
      "\n",
      "Epoch 879\n",
      "-------------------------------\n",
      "Loss: 0.000059  [   64/ 7049]\n",
      "At step count 97459\n",
      "Loss: 0.000031  [ 6464/ 7049]\n",
      "At step count 97559\n",
      "Test Error: \n",
      " Avg loss: 0.000582 \n",
      "\n",
      "Epoch 880\n",
      "-------------------------------\n",
      "Loss: 0.000062  [   64/ 7049]\n",
      "At step count 97570\n",
      "Loss: 0.000039  [ 6464/ 7049]\n",
      "At step count 97670\n",
      "Test Error: \n",
      " Avg loss: 0.000951 \n",
      "\n",
      "Epoch 881\n",
      "-------------------------------\n",
      "Loss: 0.000031  [   64/ 7049]\n",
      "At step count 97681\n",
      "Loss: 0.000121  [ 6464/ 7049]\n",
      "At step count 97781\n",
      "Test Error: \n",
      " Avg loss: 0.000860 \n",
      "\n",
      "Epoch 882\n",
      "-------------------------------\n",
      "Loss: 0.000040  [   64/ 7049]\n",
      "At step count 97792\n",
      "Loss: 0.000158  [ 6464/ 7049]\n",
      "At step count 97892\n",
      "Test Error: \n",
      " Avg loss: 0.000967 \n",
      "\n",
      "Epoch 883\n",
      "-------------------------------\n",
      "Loss: 0.000046  [   64/ 7049]\n",
      "At step count 97903\n",
      "Loss: 0.000546  [ 6464/ 7049]\n",
      "At step count 98003\n",
      "Test Error: \n",
      " Avg loss: 0.000751 \n",
      "\n",
      "Epoch 884\n",
      "-------------------------------\n",
      "Loss: 0.000496  [   64/ 7049]\n",
      "At step count 98014\n",
      "Loss: 0.000335  [ 6464/ 7049]\n",
      "At step count 98114\n",
      "Test Error: \n",
      " Avg loss: 0.000709 \n",
      "\n",
      "Epoch 885\n",
      "-------------------------------\n",
      "Loss: 0.000362  [   64/ 7049]\n",
      "At step count 98125\n",
      "Loss: 0.000329  [ 6464/ 7049]\n",
      "At step count 98225\n",
      "Test Error: \n",
      " Avg loss: 0.000569 \n",
      "\n",
      "Epoch 886\n",
      "-------------------------------\n",
      "Loss: 0.000174  [   64/ 7049]\n",
      "At step count 98236\n",
      "Loss: 0.000149  [ 6464/ 7049]\n",
      "At step count 98336\n",
      "Test Error: \n",
      " Avg loss: 0.000737 \n",
      "\n",
      "Epoch 887\n",
      "-------------------------------\n",
      "Loss: 0.000174  [   64/ 7049]\n",
      "At step count 98347\n",
      "Loss: 0.000186  [ 6464/ 7049]\n",
      "At step count 98447\n",
      "Test Error: \n",
      " Avg loss: 0.000628 \n",
      "\n",
      "Epoch 888\n",
      "-------------------------------\n",
      "Loss: 0.000185  [   64/ 7049]\n",
      "At step count 98458\n",
      "Loss: 0.000193  [ 6464/ 7049]\n",
      "At step count 98558\n",
      "Test Error: \n",
      " Avg loss: 0.000738 \n",
      "\n",
      "Epoch 889\n",
      "-------------------------------\n",
      "Loss: 0.000126  [   64/ 7049]\n",
      "At step count 98569\n",
      "Loss: 0.000505  [ 6464/ 7049]\n",
      "At step count 98669\n",
      "Test Error: \n",
      " Avg loss: 0.000619 \n",
      "\n",
      "Epoch 890\n",
      "-------------------------------\n",
      "Loss: 0.000240  [   64/ 7049]\n",
      "At step count 98680\n",
      "Loss: 0.000118  [ 6464/ 7049]\n",
      "At step count 98780\n",
      "Test Error: \n",
      " Avg loss: 0.000976 \n",
      "\n",
      "Epoch 891\n",
      "-------------------------------\n",
      "Loss: 0.000102  [   64/ 7049]\n",
      "At step count 98791\n",
      "Loss: 0.000114  [ 6464/ 7049]\n",
      "At step count 98891\n",
      "Test Error: \n",
      " Avg loss: 0.000755 \n",
      "\n",
      "Epoch 892\n",
      "-------------------------------\n",
      "Loss: 0.000084  [   64/ 7049]\n",
      "At step count 98902\n",
      "Loss: 0.000089  [ 6464/ 7049]\n",
      "At step count 99002\n",
      "Test Error: \n",
      " Avg loss: 0.000958 \n",
      "\n",
      "Epoch 893\n",
      "-------------------------------\n",
      "Loss: 0.000094  [   64/ 7049]\n",
      "At step count 99013\n",
      "Loss: 0.000527  [ 6464/ 7049]\n",
      "At step count 99113\n",
      "Test Error: \n",
      " Avg loss: 0.000690 \n",
      "\n",
      "Epoch 894\n",
      "-------------------------------\n",
      "Loss: 0.000078  [   64/ 7049]\n",
      "At step count 99124\n",
      "Loss: 0.000188  [ 6464/ 7049]\n",
      "At step count 99224\n",
      "Test Error: \n",
      " Avg loss: 0.000964 \n",
      "\n",
      "Epoch 895\n",
      "-------------------------------\n",
      "Loss: 0.000111  [   64/ 7049]\n",
      "At step count 99235\n",
      "Loss: 0.000129  [ 6464/ 7049]\n",
      "At step count 99335\n",
      "Test Error: \n",
      " Avg loss: 0.001088 \n",
      "\n",
      "Epoch 896\n",
      "-------------------------------\n",
      "Loss: 0.000159  [   64/ 7049]\n",
      "At step count 99346\n",
      "Loss: 0.000774  [ 6464/ 7049]\n",
      "At step count 99446\n",
      "Test Error: \n",
      " Avg loss: 0.000677 \n",
      "\n",
      "Epoch 897\n",
      "-------------------------------\n",
      "Loss: 0.000600  [   64/ 7049]\n",
      "At step count 99457\n",
      "Loss: 0.000085  [ 6464/ 7049]\n",
      "At step count 99557\n",
      "Test Error: \n",
      " Avg loss: 0.000971 \n",
      "\n",
      "Epoch 898\n",
      "-------------------------------\n",
      "Loss: 0.000126  [   64/ 7049]\n",
      "At step count 99568\n",
      "Loss: 0.000090  [ 6464/ 7049]\n",
      "At step count 99668\n",
      "Test Error: \n",
      " Avg loss: 0.000930 \n",
      "\n",
      "Epoch 899\n",
      "-------------------------------\n",
      "Loss: 0.000091  [   64/ 7049]\n",
      "At step count 99679\n",
      "Loss: 0.000060  [ 6464/ 7049]\n",
      "At step count 99779\n",
      "Test Error: \n",
      " Avg loss: 0.000887 \n",
      "\n",
      "Epoch 900\n",
      "-------------------------------\n",
      "Loss: 0.000135  [   64/ 7049]\n",
      "At step count 99790\n",
      "Loss: 0.000098  [ 6464/ 7049]\n",
      "At step count 99890\n",
      "Test Error: \n",
      " Avg loss: 0.000567 \n",
      "\n",
      "Epoch 901\n",
      "-------------------------------\n",
      "Loss: 0.000114  [   64/ 7049]\n",
      "At step count 99901\n",
      "Loss: 0.000074  [ 6464/ 7049]\n",
      "At step count 100001\n",
      "Test Error: \n",
      " Avg loss: 0.001036 \n",
      "\n",
      "Epoch 902\n",
      "-------------------------------\n",
      "Loss: 0.000087  [   64/ 7049]\n",
      "At step count 100012\n",
      "Loss: 0.000065  [ 6464/ 7049]\n",
      "At step count 100112\n",
      "Test Error: \n",
      " Avg loss: 0.001142 \n",
      "\n",
      "Epoch 903\n",
      "-------------------------------\n",
      "Loss: 0.000092  [   64/ 7049]\n",
      "At step count 100123\n",
      "Loss: 0.000054  [ 6464/ 7049]\n",
      "At step count 100223\n",
      "Test Error: \n",
      " Avg loss: 0.000577 \n",
      "\n",
      "Epoch 904\n",
      "-------------------------------\n",
      "Loss: 0.000131  [   64/ 7049]\n",
      "At step count 100234\n",
      "Loss: 0.000085  [ 6464/ 7049]\n",
      "At step count 100334\n",
      "Test Error: \n",
      " Avg loss: 0.000785 \n",
      "\n",
      "Epoch 905\n",
      "-------------------------------\n",
      "Loss: 0.000085  [   64/ 7049]\n",
      "At step count 100345\n",
      "Loss: 0.000063  [ 6464/ 7049]\n",
      "At step count 100445\n",
      "Test Error: \n",
      " Avg loss: 0.001073 \n",
      "\n",
      "Epoch 906\n",
      "-------------------------------\n",
      "Loss: 0.000094  [   64/ 7049]\n",
      "At step count 100456\n",
      "Loss: 0.000171  [ 6464/ 7049]\n",
      "At step count 100556\n",
      "Test Error: \n",
      " Avg loss: 0.000945 \n",
      "\n",
      "Epoch 907\n",
      "-------------------------------\n",
      "Loss: 0.000056  [   64/ 7049]\n",
      "At step count 100567\n",
      "Loss: 0.000319  [ 6464/ 7049]\n",
      "At step count 100667\n",
      "Test Error: \n",
      " Avg loss: 0.000858 \n",
      "\n",
      "Epoch 908\n",
      "-------------------------------\n",
      "Loss: 0.000059  [   64/ 7049]\n",
      "At step count 100678\n",
      "Loss: 0.000060  [ 6464/ 7049]\n",
      "At step count 100778\n",
      "Test Error: \n",
      " Avg loss: 0.000758 \n",
      "\n",
      "Epoch 909\n",
      "-------------------------------\n",
      "Loss: 0.000112  [   64/ 7049]\n",
      "At step count 100789\n",
      "Loss: 0.000062  [ 6464/ 7049]\n",
      "At step count 100889\n",
      "Test Error: \n",
      " Avg loss: 0.001098 \n",
      "\n",
      "Epoch 910\n",
      "-------------------------------\n",
      "Loss: 0.000063  [   64/ 7049]\n",
      "At step count 100900\n",
      "Loss: 0.000082  [ 6464/ 7049]\n",
      "At step count 101000\n",
      "Test Error: \n",
      " Avg loss: 0.000702 \n",
      "\n",
      "Epoch 911\n",
      "-------------------------------\n",
      "Loss: 0.000069  [   64/ 7049]\n",
      "At step count 101011\n",
      "Loss: 0.000050  [ 6464/ 7049]\n",
      "At step count 101111\n",
      "Test Error: \n",
      " Avg loss: 0.000829 \n",
      "\n",
      "Epoch 912\n",
      "-------------------------------\n",
      "Loss: 0.000104  [   64/ 7049]\n",
      "At step count 101122\n",
      "Loss: 0.000085  [ 6464/ 7049]\n",
      "At step count 101222\n",
      "Test Error: \n",
      " Avg loss: 0.000532 \n",
      "\n",
      "Epoch 913\n",
      "-------------------------------\n",
      "Loss: 0.000146  [   64/ 7049]\n",
      "At step count 101233\n",
      "Loss: 0.000058  [ 6464/ 7049]\n",
      "At step count 101333\n",
      "Test Error: \n",
      " Avg loss: 0.000809 \n",
      "\n",
      "Epoch 914\n",
      "-------------------------------\n",
      "Loss: 0.000115  [   64/ 7049]\n",
      "At step count 101344\n",
      "Loss: 0.000056  [ 6464/ 7049]\n",
      "At step count 101444\n",
      "Test Error: \n",
      " Avg loss: 0.000960 \n",
      "\n",
      "Epoch 915\n",
      "-------------------------------\n",
      "Loss: 0.000173  [   64/ 7049]\n",
      "At step count 101455\n",
      "Loss: 0.000085  [ 6464/ 7049]\n",
      "At step count 101555\n",
      "Test Error: \n",
      " Avg loss: 0.000804 \n",
      "\n",
      "Epoch 916\n",
      "-------------------------------\n",
      "Loss: 0.000057  [   64/ 7049]\n",
      "At step count 101566\n",
      "Loss: 0.000048  [ 6464/ 7049]\n",
      "At step count 101666\n",
      "Test Error: \n",
      " Avg loss: 0.000892 \n",
      "\n",
      "Epoch 917\n",
      "-------------------------------\n",
      "Loss: 0.000176  [   64/ 7049]\n",
      "At step count 101677\n",
      "Loss: 0.000071  [ 6464/ 7049]\n",
      "At step count 101777\n",
      "Test Error: \n",
      " Avg loss: 0.001354 \n",
      "\n",
      "Epoch 918\n",
      "-------------------------------\n",
      "Loss: 0.000108  [   64/ 7049]\n",
      "At step count 101788\n",
      "Loss: 0.000064  [ 6464/ 7049]\n",
      "At step count 101888\n",
      "Test Error: \n",
      " Avg loss: 0.001069 \n",
      "\n",
      "Epoch 919\n",
      "-------------------------------\n",
      "Loss: 0.000050  [   64/ 7049]\n",
      "At step count 101899\n",
      "Loss: 0.000093  [ 6464/ 7049]\n",
      "At step count 101999\n",
      "Test Error: \n",
      " Avg loss: 0.000711 \n",
      "\n",
      "Epoch 920\n",
      "-------------------------------\n",
      "Loss: 0.000053  [   64/ 7049]\n",
      "At step count 102010\n",
      "Loss: 0.000075  [ 6464/ 7049]\n",
      "At step count 102110\n",
      "Test Error: \n",
      " Avg loss: 0.000729 \n",
      "\n",
      "Epoch 921\n",
      "-------------------------------\n",
      "Loss: 0.000074  [   64/ 7049]\n",
      "At step count 102121\n",
      "Loss: 0.000068  [ 6464/ 7049]\n",
      "At step count 102221\n",
      "Test Error: \n",
      " Avg loss: 0.000751 \n",
      "\n",
      "Epoch 922\n",
      "-------------------------------\n",
      "Loss: 0.000074  [   64/ 7049]\n",
      "At step count 102232\n",
      "Loss: 0.000062  [ 6464/ 7049]\n",
      "At step count 102332\n",
      "Test Error: \n",
      " Avg loss: 0.000847 \n",
      "\n",
      "Epoch 923\n",
      "-------------------------------\n",
      "Loss: 0.000067  [   64/ 7049]\n",
      "At step count 102343\n",
      "Loss: 0.000093  [ 6464/ 7049]\n",
      "At step count 102443\n",
      "Test Error: \n",
      " Avg loss: 0.001049 \n",
      "\n",
      "Epoch 924\n",
      "-------------------------------\n",
      "Loss: 0.000047  [   64/ 7049]\n",
      "At step count 102454\n",
      "Loss: 0.000044  [ 6464/ 7049]\n",
      "At step count 102554\n",
      "Test Error: \n",
      " Avg loss: 0.000641 \n",
      "\n",
      "Epoch 925\n",
      "-------------------------------\n",
      "Loss: 0.000058  [   64/ 7049]\n",
      "At step count 102565\n",
      "Loss: 0.000069  [ 6464/ 7049]\n",
      "At step count 102665\n",
      "Test Error: \n",
      " Avg loss: 0.000787 \n",
      "\n",
      "Epoch 926\n",
      "-------------------------------\n",
      "Loss: 0.000056  [   64/ 7049]\n",
      "At step count 102676\n",
      "Loss: 0.000600  [ 6464/ 7049]\n",
      "At step count 102776\n",
      "Test Error: \n",
      " Avg loss: 0.000621 \n",
      "\n",
      "Epoch 927\n",
      "-------------------------------\n",
      "Loss: 0.000663  [   64/ 7049]\n",
      "At step count 102787\n",
      "Loss: 0.000169  [ 6464/ 7049]\n",
      "At step count 102887\n",
      "Test Error: \n",
      " Avg loss: 0.001152 \n",
      "\n",
      "Epoch 928\n",
      "-------------------------------\n",
      "Loss: 0.000058  [   64/ 7049]\n",
      "At step count 102898\n",
      "Loss: 0.000074  [ 6464/ 7049]\n",
      "At step count 102998\n",
      "Test Error: \n",
      " Avg loss: 0.001121 \n",
      "\n",
      "Epoch 929\n",
      "-------------------------------\n",
      "Loss: 0.000057  [   64/ 7049]\n",
      "At step count 103009\n",
      "Loss: 0.000064  [ 6464/ 7049]\n",
      "At step count 103109\n",
      "Test Error: \n",
      " Avg loss: 0.049263 \n",
      "\n",
      "Epoch 930\n",
      "-------------------------------\n",
      "Loss: 0.000536  [   64/ 7049]\n",
      "At step count 103120\n",
      "Loss: 0.000110  [ 6464/ 7049]\n",
      "At step count 103220\n",
      "Test Error: \n",
      " Avg loss: 0.001288 \n",
      "\n",
      "Epoch 931\n",
      "-------------------------------\n",
      "Loss: 0.000092  [   64/ 7049]\n",
      "At step count 103231\n",
      "Loss: 0.000047  [ 6464/ 7049]\n",
      "At step count 103331\n",
      "Test Error: \n",
      " Avg loss: 0.000814 \n",
      "\n",
      "Epoch 932\n",
      "-------------------------------\n",
      "Loss: 0.000067  [   64/ 7049]\n",
      "At step count 103342\n",
      "Loss: 0.000058  [ 6464/ 7049]\n",
      "At step count 103442\n",
      "Test Error: \n",
      " Avg loss: 0.000742 \n",
      "\n",
      "Epoch 933\n",
      "-------------------------------\n",
      "Loss: 0.000662  [   64/ 7049]\n",
      "At step count 103453\n",
      "Loss: 0.000058  [ 6464/ 7049]\n",
      "At step count 103553\n",
      "Test Error: \n",
      " Avg loss: 0.001035 \n",
      "\n",
      "Epoch 934\n",
      "-------------------------------\n",
      "Loss: 0.000067  [   64/ 7049]\n",
      "At step count 103564\n",
      "Loss: 0.000054  [ 6464/ 7049]\n",
      "At step count 103664\n",
      "Test Error: \n",
      " Avg loss: 0.000570 \n",
      "\n",
      "Epoch 935\n",
      "-------------------------------\n",
      "Loss: 0.000053  [   64/ 7049]\n",
      "At step count 103675\n",
      "Loss: 0.000053  [ 6464/ 7049]\n",
      "At step count 103775\n",
      "Test Error: \n",
      " Avg loss: 0.000654 \n",
      "\n",
      "Epoch 936\n",
      "-------------------------------\n",
      "Loss: 0.000063  [   64/ 7049]\n",
      "At step count 103786\n",
      "Loss: 0.000066  [ 6464/ 7049]\n",
      "At step count 103886\n",
      "Test Error: \n",
      " Avg loss: 0.000991 \n",
      "\n",
      "Epoch 937\n",
      "-------------------------------\n",
      "Loss: 0.000103  [   64/ 7049]\n",
      "At step count 103897\n",
      "Loss: 0.000043  [ 6464/ 7049]\n",
      "At step count 103997\n",
      "Test Error: \n",
      " Avg loss: 0.000684 \n",
      "\n",
      "Epoch 938\n",
      "-------------------------------\n",
      "Loss: 0.000029  [   64/ 7049]\n",
      "At step count 104008\n",
      "Loss: 0.000070  [ 6464/ 7049]\n",
      "At step count 104108\n",
      "Test Error: \n",
      " Avg loss: 0.001057 \n",
      "\n",
      "Epoch 939\n",
      "-------------------------------\n",
      "Loss: 0.000059  [   64/ 7049]\n",
      "At step count 104119\n",
      "Loss: 0.000069  [ 6464/ 7049]\n",
      "At step count 104219\n",
      "Test Error: \n",
      " Avg loss: 0.001488 \n",
      "\n",
      "Epoch 940\n",
      "-------------------------------\n",
      "Loss: 0.000037  [   64/ 7049]\n",
      "At step count 104230\n",
      "Loss: 0.000572  [ 6464/ 7049]\n",
      "At step count 104330\n",
      "Test Error: \n",
      " Avg loss: 0.000848 \n",
      "\n",
      "Epoch 941\n",
      "-------------------------------\n",
      "Loss: 0.000049  [   64/ 7049]\n",
      "At step count 104341\n",
      "Loss: 0.000052  [ 6464/ 7049]\n",
      "At step count 104441\n",
      "Test Error: \n",
      " Avg loss: 0.000877 \n",
      "\n",
      "Epoch 942\n",
      "-------------------------------\n",
      "Loss: 0.000049  [   64/ 7049]\n",
      "At step count 104452\n",
      "Loss: 0.000056  [ 6464/ 7049]\n",
      "At step count 104552\n",
      "Test Error: \n",
      " Avg loss: 0.001035 \n",
      "\n",
      "Epoch 943\n",
      "-------------------------------\n",
      "Loss: 0.000032  [   64/ 7049]\n",
      "At step count 104563\n",
      "Loss: 0.000255  [ 6464/ 7049]\n",
      "At step count 104663\n",
      "Test Error: \n",
      " Avg loss: 0.000556 \n",
      "\n",
      "Epoch 944\n",
      "-------------------------------\n",
      "Loss: 0.000051  [   64/ 7049]\n",
      "At step count 104674\n",
      "Loss: 0.000089  [ 6464/ 7049]\n",
      "At step count 104774\n",
      "Test Error: \n",
      " Avg loss: 0.000863 \n",
      "\n",
      "Epoch 945\n",
      "-------------------------------\n",
      "Loss: 0.000046  [   64/ 7049]\n",
      "At step count 104785\n",
      "Loss: 0.000070  [ 6464/ 7049]\n",
      "At step count 104885\n",
      "Test Error: \n",
      " Avg loss: 0.001332 \n",
      "\n",
      "Epoch 946\n",
      "-------------------------------\n",
      "Loss: 0.000056  [   64/ 7049]\n",
      "At step count 104896\n",
      "Loss: 0.000123  [ 6464/ 7049]\n",
      "At step count 104996\n",
      "Test Error: \n",
      " Avg loss: 0.000740 \n",
      "\n",
      "Epoch 947\n",
      "-------------------------------\n",
      "Loss: 0.000052  [   64/ 7049]\n",
      "At step count 105007\n",
      "Loss: 0.000046  [ 6464/ 7049]\n",
      "At step count 105107\n",
      "Test Error: \n",
      " Avg loss: 0.000969 \n",
      "\n",
      "Epoch 948\n",
      "-------------------------------\n",
      "Loss: 0.000270  [   64/ 7049]\n",
      "At step count 105118\n",
      "Loss: 0.000063  [ 6464/ 7049]\n",
      "At step count 105218\n",
      "Test Error: \n",
      " Avg loss: 0.000807 \n",
      "\n",
      "Epoch 949\n",
      "-------------------------------\n",
      "Loss: 0.000036  [   64/ 7049]\n",
      "At step count 105229\n",
      "Loss: 0.000037  [ 6464/ 7049]\n",
      "At step count 105329\n",
      "Test Error: \n",
      " Avg loss: 0.000994 \n",
      "\n",
      "Epoch 950\n",
      "-------------------------------\n",
      "Loss: 0.000135  [   64/ 7049]\n",
      "At step count 105340\n",
      "Loss: 0.000045  [ 6464/ 7049]\n",
      "At step count 105440\n",
      "Test Error: \n",
      " Avg loss: 0.000776 \n",
      "\n",
      "Epoch 951\n",
      "-------------------------------\n",
      "Loss: 0.000058  [   64/ 7049]\n",
      "At step count 105451\n",
      "Loss: 0.000040  [ 6464/ 7049]\n",
      "At step count 105551\n",
      "Test Error: \n",
      " Avg loss: 0.000464 \n",
      "\n",
      "Epoch 952\n",
      "-------------------------------\n",
      "Loss: 0.000050  [   64/ 7049]\n",
      "At step count 105562\n",
      "Loss: 0.000043  [ 6464/ 7049]\n",
      "At step count 105662\n",
      "Test Error: \n",
      " Avg loss: 0.000348 \n",
      "\n",
      "Epoch 953\n",
      "-------------------------------\n",
      "Loss: 0.000051  [   64/ 7049]\n",
      "At step count 105673\n",
      "Loss: 0.000039  [ 6464/ 7049]\n",
      "At step count 105773\n",
      "Test Error: \n",
      " Avg loss: 0.000619 \n",
      "\n",
      "Epoch 954\n",
      "-------------------------------\n",
      "Loss: 0.000080  [   64/ 7049]\n",
      "At step count 105784\n",
      "Loss: 0.000053  [ 6464/ 7049]\n",
      "At step count 105884\n",
      "Test Error: \n",
      " Avg loss: 0.001381 \n",
      "\n",
      "Epoch 955\n",
      "-------------------------------\n",
      "Loss: 0.000056  [   64/ 7049]\n",
      "At step count 105895\n",
      "Loss: 0.000128  [ 6464/ 7049]\n",
      "At step count 105995\n",
      "Test Error: \n",
      " Avg loss: 0.000765 \n",
      "\n",
      "Epoch 956\n",
      "-------------------------------\n",
      "Loss: 0.000092  [   64/ 7049]\n",
      "At step count 106006\n",
      "Loss: 0.000063  [ 6464/ 7049]\n",
      "At step count 106106\n",
      "Test Error: \n",
      " Avg loss: 0.001222 \n",
      "\n",
      "Epoch 957\n",
      "-------------------------------\n",
      "Loss: 0.000735  [   64/ 7049]\n",
      "At step count 106117\n",
      "Loss: 0.000046  [ 6464/ 7049]\n",
      "At step count 106217\n",
      "Test Error: \n",
      " Avg loss: 0.000625 \n",
      "\n",
      "Epoch 958\n",
      "-------------------------------\n",
      "Loss: 0.000051  [   64/ 7049]\n",
      "At step count 106228\n",
      "Loss: 0.000055  [ 6464/ 7049]\n",
      "At step count 106328\n",
      "Test Error: \n",
      " Avg loss: 0.000922 \n",
      "\n",
      "Epoch 959\n",
      "-------------------------------\n",
      "Loss: 0.000108  [   64/ 7049]\n",
      "At step count 106339\n",
      "Loss: 0.000158  [ 6464/ 7049]\n",
      "At step count 106439\n",
      "Test Error: \n",
      " Avg loss: 0.000766 \n",
      "\n",
      "Epoch 960\n",
      "-------------------------------\n",
      "Loss: 0.000062  [   64/ 7049]\n",
      "At step count 106450\n",
      "Loss: 0.000039  [ 6464/ 7049]\n",
      "At step count 106550\n",
      "Test Error: \n",
      " Avg loss: 0.000798 \n",
      "\n",
      "Epoch 961\n",
      "-------------------------------\n",
      "Loss: 0.000031  [   64/ 7049]\n",
      "At step count 106561\n",
      "Loss: 0.000191  [ 6464/ 7049]\n",
      "At step count 106661\n",
      "Test Error: \n",
      " Avg loss: 0.000754 \n",
      "\n",
      "Epoch 962\n",
      "-------------------------------\n",
      "Loss: 0.000066  [   64/ 7049]\n",
      "At step count 106672\n",
      "Loss: 0.000051  [ 6464/ 7049]\n",
      "At step count 106772\n",
      "Test Error: \n",
      " Avg loss: 0.000862 \n",
      "\n",
      "Epoch 963\n",
      "-------------------------------\n",
      "Loss: 0.000057  [   64/ 7049]\n",
      "At step count 106783\n",
      "Loss: 0.000093  [ 6464/ 7049]\n",
      "At step count 106883\n",
      "Test Error: \n",
      " Avg loss: 0.000876 \n",
      "\n",
      "Epoch 964\n",
      "-------------------------------\n",
      "Loss: 0.000047  [   64/ 7049]\n",
      "At step count 106894\n",
      "Loss: 0.000060  [ 6464/ 7049]\n",
      "At step count 106994\n",
      "Test Error: \n",
      " Avg loss: 0.001050 \n",
      "\n",
      "Epoch 965\n",
      "-------------------------------\n",
      "Loss: 0.000051  [   64/ 7049]\n",
      "At step count 107005\n",
      "Loss: 0.000044  [ 6464/ 7049]\n",
      "At step count 107105\n",
      "Test Error: \n",
      " Avg loss: 0.001066 \n",
      "\n",
      "Epoch 966\n",
      "-------------------------------\n",
      "Loss: 0.000065  [   64/ 7049]\n",
      "At step count 107116\n",
      "Loss: 0.000052  [ 6464/ 7049]\n",
      "At step count 107216\n",
      "Test Error: \n",
      " Avg loss: 0.001040 \n",
      "\n",
      "Epoch 967\n",
      "-------------------------------\n",
      "Loss: 0.000050  [   64/ 7049]\n",
      "At step count 107227\n",
      "Loss: 0.000069  [ 6464/ 7049]\n",
      "At step count 107327\n",
      "Test Error: \n",
      " Avg loss: 0.000457 \n",
      "\n",
      "Epoch 968\n",
      "-------------------------------\n",
      "Loss: 0.000058  [   64/ 7049]\n",
      "At step count 107338\n",
      "Loss: 0.000088  [ 6464/ 7049]\n",
      "At step count 107438\n",
      "Test Error: \n",
      " Avg loss: 0.000586 \n",
      "\n",
      "Epoch 969\n",
      "-------------------------------\n",
      "Loss: 0.000044  [   64/ 7049]\n",
      "At step count 107449\n",
      "Loss: 0.000057  [ 6464/ 7049]\n",
      "At step count 107549\n",
      "Test Error: \n",
      " Avg loss: 0.000965 \n",
      "\n",
      "Epoch 970\n",
      "-------------------------------\n",
      "Loss: 0.000050  [   64/ 7049]\n",
      "At step count 107560\n",
      "Loss: 0.000079  [ 6464/ 7049]\n",
      "At step count 107660\n",
      "Test Error: \n",
      " Avg loss: 0.000522 \n",
      "\n",
      "Epoch 971\n",
      "-------------------------------\n",
      "Loss: 0.000075  [   64/ 7049]\n",
      "At step count 107671\n",
      "Loss: 0.000029  [ 6464/ 7049]\n",
      "At step count 107771\n",
      "Test Error: \n",
      " Avg loss: 0.001093 \n",
      "\n",
      "Epoch 972\n",
      "-------------------------------\n",
      "Loss: 0.000031  [   64/ 7049]\n",
      "At step count 107782\n",
      "Loss: 0.000104  [ 6464/ 7049]\n",
      "At step count 107882\n",
      "Test Error: \n",
      " Avg loss: 0.000723 \n",
      "\n",
      "Epoch 973\n",
      "-------------------------------\n",
      "Loss: 0.000030  [   64/ 7049]\n",
      "At step count 107893\n",
      "Loss: 0.000045  [ 6464/ 7049]\n",
      "At step count 107993\n",
      "Test Error: \n",
      " Avg loss: 0.000721 \n",
      "\n",
      "Epoch 974\n",
      "-------------------------------\n",
      "Loss: 0.000062  [   64/ 7049]\n",
      "At step count 108004\n",
      "Loss: 0.000077  [ 6464/ 7049]\n",
      "At step count 108104\n",
      "Test Error: \n",
      " Avg loss: 0.000809 \n",
      "\n",
      "Epoch 975\n",
      "-------------------------------\n",
      "Loss: 0.000120  [   64/ 7049]\n",
      "At step count 108115\n",
      "Loss: 0.000084  [ 6464/ 7049]\n",
      "At step count 108215\n",
      "Test Error: \n",
      " Avg loss: 0.000739 \n",
      "\n",
      "Epoch 976\n",
      "-------------------------------\n",
      "Loss: 0.000056  [   64/ 7049]\n",
      "At step count 108226\n",
      "Loss: 0.000152  [ 6464/ 7049]\n",
      "At step count 108326\n",
      "Test Error: \n",
      " Avg loss: 0.000866 \n",
      "\n",
      "Epoch 977\n",
      "-------------------------------\n",
      "Loss: 0.000087  [   64/ 7049]\n",
      "At step count 108337\n",
      "Loss: 0.000281  [ 6464/ 7049]\n",
      "At step count 108437\n",
      "Test Error: \n",
      " Avg loss: 0.000942 \n",
      "\n",
      "Epoch 978\n",
      "-------------------------------\n",
      "Loss: 0.000036  [   64/ 7049]\n",
      "At step count 108448\n",
      "Loss: 0.000071  [ 6464/ 7049]\n",
      "At step count 108548\n",
      "Test Error: \n",
      " Avg loss: 0.000687 \n",
      "\n",
      "Epoch 979\n",
      "-------------------------------\n",
      "Loss: 0.000137  [   64/ 7049]\n",
      "At step count 108559\n",
      "Loss: 0.000051  [ 6464/ 7049]\n",
      "At step count 108659\n",
      "Test Error: \n",
      " Avg loss: 0.001359 \n",
      "\n",
      "Epoch 980\n",
      "-------------------------------\n",
      "Loss: 0.000068  [   64/ 7049]\n",
      "At step count 108670\n",
      "Loss: 0.000073  [ 6464/ 7049]\n",
      "At step count 108770\n",
      "Test Error: \n",
      " Avg loss: 0.000548 \n",
      "\n",
      "Epoch 981\n",
      "-------------------------------\n",
      "Loss: 0.000048  [   64/ 7049]\n",
      "At step count 108781\n",
      "Loss: 0.000095  [ 6464/ 7049]\n",
      "At step count 108881\n",
      "Test Error: \n",
      " Avg loss: 0.001067 \n",
      "\n",
      "Epoch 982\n",
      "-------------------------------\n",
      "Loss: 0.000677  [   64/ 7049]\n",
      "At step count 108892\n",
      "Loss: 0.000040  [ 6464/ 7049]\n",
      "At step count 108992\n",
      "Test Error: \n",
      " Avg loss: 0.000877 \n",
      "\n",
      "Epoch 983\n",
      "-------------------------------\n",
      "Loss: 0.000068  [   64/ 7049]\n",
      "At step count 109003\n",
      "Loss: 0.000051  [ 6464/ 7049]\n",
      "At step count 109103\n",
      "Test Error: \n",
      " Avg loss: 0.001358 \n",
      "\n",
      "Epoch 984\n",
      "-------------------------------\n",
      "Loss: 0.000051  [   64/ 7049]\n",
      "At step count 109114\n",
      "Loss: 0.000034  [ 6464/ 7049]\n",
      "At step count 109214\n",
      "Test Error: \n",
      " Avg loss: 0.002346 \n",
      "\n",
      "Epoch 985\n",
      "-------------------------------\n",
      "Loss: 0.000031  [   64/ 7049]\n",
      "At step count 109225\n",
      "Loss: 0.000938  [ 6464/ 7049]\n",
      "At step count 109325\n",
      "Test Error: \n",
      " Avg loss: 0.001014 \n",
      "\n",
      "Epoch 986\n",
      "-------------------------------\n",
      "Loss: 0.000426  [   64/ 7049]\n",
      "At step count 109336\n",
      "Loss: 0.000053  [ 6464/ 7049]\n",
      "At step count 109436\n",
      "Test Error: \n",
      " Avg loss: 0.001162 \n",
      "\n",
      "Epoch 987\n",
      "-------------------------------\n",
      "Loss: 0.000066  [   64/ 7049]\n",
      "At step count 109447\n",
      "Loss: 0.000085  [ 6464/ 7049]\n",
      "At step count 109547\n",
      "Test Error: \n",
      " Avg loss: 0.001484 \n",
      "\n",
      "Epoch 988\n",
      "-------------------------------\n",
      "Loss: 0.000058  [   64/ 7049]\n",
      "At step count 109558\n",
      "Loss: 0.000247  [ 6464/ 7049]\n",
      "At step count 109658\n",
      "Test Error: \n",
      " Avg loss: 0.000911 \n",
      "\n",
      "Epoch 989\n",
      "-------------------------------\n",
      "Loss: 0.000040  [   64/ 7049]\n",
      "At step count 109669\n",
      "Loss: 0.000084  [ 6464/ 7049]\n",
      "At step count 109769\n",
      "Test Error: \n",
      " Avg loss: 0.000868 \n",
      "\n",
      "Epoch 990\n",
      "-------------------------------\n",
      "Loss: 0.000035  [   64/ 7049]\n",
      "At step count 109780\n",
      "Loss: 0.000496  [ 6464/ 7049]\n",
      "At step count 109880\n",
      "Test Error: \n",
      " Avg loss: 0.000943 \n",
      "\n",
      "Epoch 991\n",
      "-------------------------------\n",
      "Loss: 0.000081  [   64/ 7049]\n",
      "At step count 109891\n",
      "Loss: 0.000040  [ 6464/ 7049]\n",
      "At step count 109991\n",
      "Test Error: \n",
      " Avg loss: 0.001187 \n",
      "\n",
      "Epoch 992\n",
      "-------------------------------\n",
      "Loss: 0.000588  [   64/ 7049]\n",
      "At step count 110002\n",
      "Loss: 0.000062  [ 6464/ 7049]\n",
      "At step count 110102\n",
      "Test Error: \n",
      " Avg loss: 0.000991 \n",
      "\n",
      "Epoch 993\n",
      "-------------------------------\n",
      "Loss: 0.000237  [   64/ 7049]\n",
      "At step count 110113\n",
      "Loss: 0.000132  [ 6464/ 7049]\n",
      "At step count 110213\n",
      "Test Error: \n",
      " Avg loss: 0.001206 \n",
      "\n",
      "Epoch 994\n",
      "-------------------------------\n",
      "Loss: 0.000039  [   64/ 7049]\n",
      "At step count 110224\n",
      "Loss: 0.000042  [ 6464/ 7049]\n",
      "At step count 110324\n",
      "Test Error: \n",
      " Avg loss: 0.001022 \n",
      "\n",
      "Epoch 995\n",
      "-------------------------------\n",
      "Loss: 0.000062  [   64/ 7049]\n",
      "At step count 110335\n",
      "Loss: 0.000067  [ 6464/ 7049]\n",
      "At step count 110435\n",
      "Test Error: \n",
      " Avg loss: 0.001171 \n",
      "\n",
      "Epoch 996\n",
      "-------------------------------\n",
      "Loss: 0.000070  [   64/ 7049]\n",
      "At step count 110446\n",
      "Loss: 0.000095  [ 6464/ 7049]\n",
      "At step count 110546\n",
      "Test Error: \n",
      " Avg loss: 0.000954 \n",
      "\n",
      "Epoch 997\n",
      "-------------------------------\n",
      "Loss: 0.000049  [   64/ 7049]\n",
      "At step count 110557\n",
      "Loss: 0.000088  [ 6464/ 7049]\n",
      "At step count 110657\n",
      "Test Error: \n",
      " Avg loss: 0.001692 \n",
      "\n",
      "Epoch 998\n",
      "-------------------------------\n",
      "Loss: 0.000148  [   64/ 7049]\n",
      "At step count 110668\n",
      "Loss: 0.000051  [ 6464/ 7049]\n",
      "At step count 110768\n",
      "Test Error: \n",
      " Avg loss: 0.000953 \n",
      "\n",
      "Epoch 999\n",
      "-------------------------------\n",
      "Loss: 0.000049  [   64/ 7049]\n",
      "At step count 110779\n",
      "Loss: 0.000098  [ 6464/ 7049]\n",
      "At step count 110879\n",
      "Test Error: \n",
      " Avg loss: 0.000999 \n",
      "\n",
      "Epoch 1000\n",
      "-------------------------------\n",
      "Loss: 0.000053  [   64/ 7049]\n",
      "At step count 110890\n",
      "Loss: 0.000116  [ 6464/ 7049]\n",
      "At step count 110990\n",
      "Test Error: \n",
      " Avg loss: 0.000975 \n",
      "\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2500x1000 with 1 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAB+EAAANXCAYAAADq8y0MAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQABAABJREFUeJzs3XeYnGW5P/DvbMkmm06AFAiEEiCBEDqiICglQUWpIlaw/dSDqCgeC4eqoigcVCwgYgUFFBQ5SBEFERGkN0GlhhKqSSB1s7u/P2ZnSxrJ7mbfbObzua653jLvPHvvZnjn4vrO/Tyl1tbW1gAAAAAAAAAAPVZTdAEAAAAAAAAAsLYQwgMAAAAAAABALxHCAwAAAAAAAEAvEcIDAAAAAAAAQC8RwgMAAAAAAABALxHCAwAAAAAAAEAvEcIDAAAAAAAAQC8RwgMAAAAAAABALxHCAwAAAAAAAEAvEcIDAAAAVev6669PqVTKr371q6JLAQAAYC0hhAcAAKDq/fjHP06pVMptt91WdCkr5aabbspBBx2U0aNHp6GhIRMmTMj/+3//L0888UTRpS2lEnIv7/HLX/6y6BIBAACgV9UVXQAAAACw8r797W/nE5/4RDbddNN8/OMfz9ixY/OPf/wj5513Xi666KJceeWVee1rX1t0mUs55phjsvPOOy91frfddiugGgAAAFh9hPAAAADQT9x000355Cc/md133z1XXXVVGhsb25/76Ec/mte97nU59NBDc//992fkyJF9VtfcuXMzePDgFV6zxx575NBDD+2jigAAAKA4pqMHAACAlXTnnXdm//33z7BhwzJkyJDsvffe+dvf/tblmqamppx88smZOHFiBg4cmFGjRmX33XfPtdde237NzJkzc9RRR2XDDTdMQ0NDxo4dm7e97W157LHHVvjzTz311JRKpfzkJz/pEsAnyWabbZbTTz89zzzzTM4555wkyTe+8Y2USqU8/vjjS431+c9/PgMGDMh//vOf9nO33HJLpk+fnuHDh6exsTF77rlnbrrppi6vO+mkk1IqlfLAAw/kne98Z0aOHJndd999pf5+r6ZUKuXoo4/OBRdckC233DIDBw7MjjvumD//+c9LXbsy/xZJMmvWrHzqU5/KhAkT0tDQkA033DDvfe9788ILL3S5rqWlJV/+8pez4YYbZuDAgdl7773z73//u8s1//rXv3LIIYdkzJgxGThwYDbccMO84x3vyOzZs3vl9wcAAGDtoBMeAAAAVsL999+fPfbYI8OGDctnP/vZ1NfX55xzzslee+2VG264IbvuumuSckh92mmn5YMf/GB22WWXzJkzJ7fddlvuuOOO7LvvvkmSQw45JPfff38+/vGPZ8KECXnuuedy7bXX5oknnsiECROW+fPnzZuX6667LnvssUc22WSTZV5z+OGH58Mf/nCuuOKKfO5zn8vb3/72fPazn83FF1+c4447rsu1F198cfbbb7/2jvk//vGP2X///bPjjjvmxBNPTE1NTX70ox/ljW98Y2688cbssssuXV5/2GGHZeLEifnKV76S1tbWV/37vfzyy0sF30kyatSolEql9uMbbrghF110UY455pg0NDTku9/9bqZPn55bb70122yzzSr9W7zyyivZY4898o9//CPvf//7s8MOO+SFF17I5ZdfnieffDLrrrtu+8/96le/mpqamnzmM5/J7Nmzc/rpp+dd73pXbrnlliTJokWLMm3atCxcuDAf//jHM2bMmDz11FO54oorMmvWrAwfPvxV/wYAAABUh1LryvyfMgAAAKzFfvzjH+eoo47K3//+9+y0007LvOaggw7KlVdemX/84x/ZdNNNkyTPPPNMttxyy2y//fa54YYbkiTbbbddNtxww1xxxRXLHGfWrFkZOXJkvv71r+czn/nMStd49913Z7vttssnPvGJnHXWWcu9burUqXnyySfz4osvJkle+9rXZtGiRbntttvar/n73/+eXXbZJT/96U/znve8J62trdlyyy2z6aab5ve//317KD5//vxsvfXW2XzzzXPNNdckKX/J4OSTT84RRxyRCy+88FXrvv766/OGN7xhuc8/88wzGTNmTJK0/9zbbrstO+64Y5LkiSeeyJZbbpn9998/l156aZKV/7c48cQTc8opp+TSSy/NQQcd1OXntra2plQqtdc3adKk3HXXXRkwYECS5Fvf+lY+8YlP5N57780222yTu+66K9tvv30uueQS0+oDAACwQqajBwAAgFfR3Nyca665JgceeGB76JskY8eOzTvf+c785S9/yZw5c5IkI0aMyP33359//etfyxxr0KBBGTBgQK6//vouU8G/mpdffjlJMnTo0BVeN3To0PZaknJ3/O23356HH364/dxFF12UhoaGvO1tb0uS3HXXXfnXv/6Vd77znXnxxRfzwgsv5IUXXsjcuXOz9957589//nNaWlq6/JyPfOQjK117kpxwwgm59tprl3qss846Xa7bbbfd2gP4JNloo43ytre9LVdffXWam5tX6d/i17/+daZOnbpUAJ+kS/d9khx11FHtAXxSXsM+SR555JEkae90v/rqqzNv3rxV+t0BAACoLkJ4AAAAeBXPP/985s2bly233HKp5yZNmpSWlpbMmDEjSXLKKadk1qxZ2WKLLTJlypQcd9xxueeee9qvb2hoyNe+9rX8/ve/z+jRo/P6178+p59+embOnLnCGirheyWMX56XX365S1B/2GGHpaamJhdddFGScgf4JZdc0r6eepL2Lwy8733vy3rrrdflcd5552XhwoVLrXu+vCnxl2fKlCnZZ599lnp0Dr6TZOLEiUu9dosttsi8efPy/PPPr9K/xcMPP9w+hf2r2WijjbocV6bpr3xRYpNNNsmxxx6b8847L+uuu26mTZuW73znO9aDBwAAYClCeAAAAOhFr3/96/Pwww/n/PPPzzbbbJPzzjsvO+ywQ84777z2az75yU/mn//8Z0477bQMHDgw//M//5NJkyblzjvvXO64m2++eerq6roE+ktauHBhHnrooUyePLn93Lhx47LHHnvk4osvTpL87W9/yxNPPJHDDz+8/ZpKl/vXv/71ZXarX3vttRkyZEiXnzVo0KBV+8Os4Wpra5d5vvMqfmeccUbuueeefOELX8j8+fNzzDHHZOutt86TTz7ZV2UCAADQDwjhAQAA4FWst956aWxszEMPPbTUcw8++GBqamoyfvz49nPrrLNOjjrqqPziF7/IjBkzsu222+akk07q8rrNNtssn/70p3PNNdfkvvvuy6JFi3LGGWcst4bBgwfnDW94Q/785z/n8ccfX+Y1F198cRYuXJi3vOUtXc4ffvjhufvuu/PQQw/loosuSmNjYw444IAutSTJsGHDltmtvs8++6S+vv5V/069YVnT+P/zn/9MY2Nje3f+yv5bbLbZZrnvvvt6tb4pU6bk+OOPz5///OfceOONeeqpp/L973+/V38GAAAA/ZsQHgAAAF5FbW1t9ttvv/z2t7/NY4891n7+2WefzYUXXpjdd9+9fWr3F198sctrhwwZks033zwLFy5MksybNy8LFizocs1mm22WoUOHtl+zPMcff3xaW1tz5JFHZv78+V2ee/TRR/PZz342Y8eOzf/7f/+vy3OHHHJIamtr84tf/CKXXHJJ3vKWt2Tw4MHtz++4447ZbLPN8o1vfCOvvPLKUj/3+eefX2Fdvenmm2/OHXfc0X48Y8aM/Pa3v81+++2X2traVfq3OOSQQ3L33XfnsssuW+rndO5wXxlz5szJ4sWLu5ybMmVKampqXvXfDQAAgOpSV3QBAAAAsKY4//zzc9VVVy11/hOf+ES+9KUv5dprr83uu++ej33sY6mrq8s555yThQsX5vTTT2+/dvLkydlrr72y4447Zp111sltt92WX/3qVzn66KOTlLu6995777z97W/P5MmTU1dXl8suuyzPPvts3vGOd6ywvte//vX5xje+kWOPPTbbbrttjjzyyIwdOzYPPvhgfvCDH6SlpSVXXnll+3rmFeuvv37e8IY35Mwzz8zLL7/cZSr6JKmpqcl5552X/fffP1tvvXWOOuqobLDBBnnqqafypz/9KcOGDcvvfve77v5ZkyQ33njjUl8+SJJtt9022267bfvxNttsk2nTpuWYY45JQ0NDvvvd7yZJTj755PZrVvbf4rjjjsuvfvWrHHbYYXn/+9+fHXfcMS+99FIuv/zyfP/738/UqVNXuv4//vGPOfroo3PYYYdliy22yOLFi/Ozn/0stbW1OeSQQ7rzJwEAAGAtJYQHAACANt/73veWef7II4/M1ltvnRtvvDGf//znc9ppp6WlpSW77rprfv7zn2fXXXdtv/aYY47J5ZdfnmuuuSYLFy7MxhtvnC996Us57rjjkiTjx4/PEUcckeuuuy4/+9nPUldXl6222ioXX3zxSoW5n/rUp7LTTjvljDPOyFlnnZXZs2dn7NixOeyww/LFL34xG2+88TJfd/jhh+cPf/hDhg4dmje96U1LPb/XXnvl5ptvzqmnnpqzzz47r7zySsaMGZNdd911qc767vjWt761zPMnnnhilxB+zz33zG677ZaTTz45TzzxRCZPnpwf//jHXa5Z2X+LIUOG5MYbb8yJJ56Yyy67LD/5yU+y/vrrZ++9986GG264SvVPnTo106ZNy+9+97s89dRTaWxszNSpU/P73/8+r3nNa1bxrwEAAMDarNS6qvOvAQAAAKwGpVIp//Vf/5Wzzz676FIAAACg26wJDwAAAAAAAAC9RAgPAAAAAAAAAL1ECA8AAAAAAAAAvaSu6AIAAAAAkqS1tbXoEgAAAKDHdMIDAAAAAAAAQC8RwgMAAAAAAABALzEd/TK0tLTk6aefztChQ1MqlYouBwAAAAAAAICCtba25uWXX864ceNSU7P8fnch/DI8/fTTGT9+fNFlAAAAAAAAALCGmTFjRjbccMPlPi+EX4ahQ4cmKf/xhg0bVnA1a5+mpqZcc8012W+//VJfX190OQBVx30YoHjuxQDFch8GKJ57MUCx3Ie7Z86cORk/fnx7nrw8QvhlqExBP2zYMCH8atDU1JTGxsYMGzbMf9QABXAfBiieezFAsdyHAYrnXgxQLPfhnnm1Jc2XP1E9AAAAAAAAALBKhPAAAAAAAAAA0EuE8AAAAAAAAADQS6wJDwAAAAAAANANra2tWbx4cZqbm4suZZU0NTWlrq4uCxYs6He1r061tbWpq6t71TXfX40QHgAAAAAAAGAVLVq0KM8880zmzZtXdCmrrLW1NWPGjMmMGTN6HDivbRobGzN27NgMGDCg22MI4QEAAAAAAABWQUtLSx599NHU1tZm3LhxGTBgQL8Ks1taWvLKK69kyJAhqamxgnlS/mLCokWL8vzzz+fRRx/NxIkTu/23EcIDAAAAAAAArIJFixalpaUl48ePT2NjY9HlrLKWlpYsWrQoAwcOFMJ3MmjQoNTX1+fxxx9v//t0h78oAAAAAAAAQDcIsNc+vfFv6l0BAAAAAAAAAL1ECA8AAAAAAAAAvUQIDwAAAAAAAFCQ5pbW3Pzwi/ntXU/l5odfTHNLa9ElrbIJEybkrLPOKrqMNUZd0QUAAAAAAAAAVKOr7nsmJ//ugTwze0H7ubHDB+bEAyZn+jZje/3nlUqlFT5/4okn5qSTTlrlcf/+979n8ODB3ayqbK+99sp22223VoT5QngAAAAAAACAPnbVfc/koz+/I0v2vc+cvSAf/fkd+d67d+j1IP6ZZ55JkrS0tOSnP/1pTjvttDz00EPtzw8ZMqR9v7W1Nc3Nzamre/VIeb311uvVOvs709EDAAAAAAAA9FBra2vmLVq8Uo+XFzTlxMvvXyqAT9J+7qTLH8jLC5pWarzW1pWbwn7MmDHtj2HDhqVUKrUfP/jggxk6dGh+//vfZ8cdd0xDQ0P+8pe/5OGHH87b3va2jB49OkOGDMnOO++cP/zhD13GXXI6+lKplPPOOy8HHXRQGhsbM3HixFx++eXd+8O2+fWvf52tt946DQ0NmTBhQs4444wuz3/3u9/NxIkTM3DgwIwePTqHHnpo+3O/+tWvMmXKlAwaNCijRo3KPvvsk7lz5/aonhXRCQ8AAAAAAADQQ/ObmjP5hKt7ZazWJDPnLMiUk65ZqesfOGVaGgf0TvT7uc99Lt/4xjey6aabZuTIkZkxY0be9KY35ctf/nIaGhry05/+NAcccEAeeuihbLTRRssd5+STT87pp5+er3/96/n2t7+dd73rXXn88cezzjrrrHJNt99+e97+9rfnpJNOyuGHH56//vWv+djHPpZRo0blyCOPzG233ZZjjjkmP/vZz/La1742L730Um688cYk5e7/I444IqeffnoOOuigvPzyy7nxxhtX+osL3SGEBwAAAAAAACBJcsopp2TfffdtP15nnXUyderU9uNTTz01l112WS6//PIcffTRyx3nyCOPzBFHHJEk+cpXvpJvfetbufXWWzN9+vRVrunMM8/M3nvvnf/5n/9JkmyxxRZ54IEH8vWvfz1HHnlknnjiiQwePDhvectbMnTo0Gy88cbZfvvtk5RD+MWLF+fggw/OxhtvnCSZMmXKKtewKoTwAAAAAAAAAD00qL42D5wybaWuvfXRl3Lkj/7+qtf9+Kids8smr945Pqi+dqV+7srYaaeduhy/8sorOemkk/J///d/7YH2/Pnz88QTT6xwnG233bZ9f/DgwRk2bFiee+65btX0j3/8I29729u6nHvd616Xs846K83Nzdl3332z8cYbZ9NNN8306dMzffr09qnwp06dmr333jtTpkzJtGnTst9+++XQQw/NyJEju1XLyrAmPAAAAAAAAEAPlUqlNA6oW6nHHhPXy9jhA1Na3lhJxg4fmD0mrrdS45VKyxtp1Q0ePLjL8Wc+85lcdtll+cpXvpIbb7wxd911V6ZMmZJFixatcJz6+vquv1OplJaWll6rs7OhQ4fmjjvuyC9+8YuMHTs2J5xwQqZOnZpZs2altrY21157bX7/+99n8uTJ+fa3v50tt9wyjz766GqpJRHCAwAAAAAAAPSp2ppSTjxgcpIsFcRXjk88YHJqa3ovXO+um266KUceeWQOOuigTJkyJWPGjMljjz3WpzVMmjQpN91001J1bbHFFqmtLc8CUFdXl3322Senn3567rnnnjz22GP54x//mKT8BYDXve51Ofnkk3PnnXdmwIABueyyy1ZbvaajBwAAAAAAAOhj07cZm++9e4ec/LsH8szsBe3nxwwfmBMPmJzp24wtsLoOEydOzKWXXpoDDjggpVIp//M//7PaOtqff/753HXXXV3OjR07Np/+9Kez884759RTT83hhx+em2++OWeffXa++93vJkmuuOKKPPLII3n961+fkSNH5sorr0xLS0u23HLL3HLLLbnuuuuy3377Zf31188tt9yS559/PpMmTVotv0MihAcAAAAAAAAoxPRtxmbfyWNy66Mv5bmXF2T9oQOzyybrrBEd8BVnnnlm3v/+9+e1r31t1l133fz3f/935syZs1p+1oUXXpgLL7ywy7lTTz01xx9/fC6++OKccMIJOfXUUzN27NiccsopOfLII5MkI0aMyKWXXpqTTjopCxYsyMSJE/OLX/wiW2+9df7xj3/kz3/+c84666zMmTMnG2+8cc4444zsv//+q+V3SITwAAAAAAAAAIWprSllt81G9fnPfec735mPfOQj7cd77bVXWltbl7puwoQJ7dO6V/zXf/1Xl+Mlp6df1jizZs1aYT3XX3/9Cp8/5JBDcsghhyzzud133325r580aVKuuuqqFY7d26wJDwAAAAAAAAC9RAgPAAAAAAAAAL1ECA8AAAAAAAAAvUQIDwAAAAAAAAC9RAgPAAAAAAAAAL2krugCqE6DFr2QPHN3Urect2DjqGTE+L4tCgAAAAAAAKCHhPD0vdlPZu8H/ju19zct/5q6huTo2wXxAAAAAAAAQL9iOnr63rwXU9u6ggA+SRYvTOa92Df1AAAAAAAAAPQSITwAAAAAAAAA9BLT0QMAAAAAAAD0tVkzVjwzdOMoSzf3U0J4AAAAAAAAgL40a0Zy9o7lJZqXp64hOfr2Xg3iS6XSCp8/8cQTc9JJJ3V77MsuuywHHnhgr1zXnwnhAQAAAAAAAPrSvBdXHMAn5efnvdirIfwzzzyTJGlpaclPf/rTnHbaaXnooYfanx8yZEiv/axqZk14AAAAAAAAgN6yaO7yH00Len/cVTBmzJj2x7Bhw1Iqlbqc++Uvf5lJkyZl4MCB2WqrrfLd736348cvWpSjjz46Y8eOzcCBA7PxxhvntNNOS5JMmDAhSXLQQQelVCq1H6+qlpaWnHLKKdlwww3T0NCQ7bbbLlddddVK1dDa2pqTTjopG220URoaGjJu3Lgcc8wx3aqjp3TCAwAAAAAAAPSWr4xb/nMT90vedUn3xj1ryrLXkD9pdvfGW8IFF1yQE044IWeffXa233773HnnnfnQhz6UwYMH533ve1++9a1v5fLLL8/FF1+cjTbaKDNmzMiMGTOSJH//+9+z/vrr50c/+lGmT5+e2trabtXwzW9+M2eccUbOOeecbL/99jn//PPz1re+Nffff38mTpy4whp+/etf53//93/zy1/+MltvvXVmzpyZu+++u1f+NqtKCE/faxyV5lJ9alubln9NXUPSOKrvagIAAAAAAIAqduKJJ+aMM87IwQcfnCTZZJNN8sADD+Scc87J+973vjzxxBOZOHFidt9995RKpWy88cbtr11vvfWSJCNGjMiYMWO6XcM3vvGN/Pd//3fe8Y53JEm+9rWv5U9/+lPOOuusfOc731lhDU888UTGjBmTffbZJ/X19dloo42yyy67dLuWnhDC0/eGb5jrJn8tb9h1auqv+kzy9J3l8x++oeOaxlG9ur4FAAAAAAAA9IkvPL3850rd6xBPknzy3u6/9lXMnTs3Dz/8cD7wgQ/kQx/6UPv5xYsXZ/jw4UmSI488Mvvuu2+23HLLTJ8+PW95y1uy33779VoNc+bMydNPP53Xve51Xc6/7nWva+9oX1ENhx12WM4666xsuummmT59et70pjflgAMOSF1d30fiQngKMX/AusnYqcmQTt+EGbddYfUAAAAAAABArxgwuH+Nm+SVV15JkvzgBz/Irrvu2uW5ytTyO+ywQx599NH8/ve/zx/+8Ie8/e1vzz777JNf/epXq62uJa2ohvHjx+ehhx7KH/7wh1x77bX52Mc+lq9//eu54YYbUl9f32c1JklNn/40WNJrPlLerjep2DoAAAAAAACgSo0ePTrjxo3LI488ks0337zLY5NNNmm/btiwYTn88MPzgx/8IBdddFF+/etf56WXXkqS1NfXp7m5uds1DBs2LOPGjctNN93U5fxNN92UyZMnr1QNgwYNygEHHJBvfetbuf7663PzzTfn3ntX3wwCy6MTnmLVtH3rpGUF68MDAAAAAADA2qRxVFLXkCxeuPxr6hrK1/WRk08+Occcc0yGDx+e6dOnZ+HChbntttvyn//8J8cee2zOPPPMjB07Nttvv31qampyySWXZMyYMRkxYkSSZMKECbnuuuvyute9Lg0NDRk5cuRyf9ajjz6au+66q8u5iRMn5rjjjsuJJ56YzTbbLNttt11+9KMf5a677soFF1yQJCus4cc//nGam5uz6667prGxMT//+c8zaNCgLuvG9xUhPMWqbQvhm4XwAAAAAAAAVIkR45Ojb0/mvbj8axpHla/rIx/84AfT2NiYr3/96znuuOMyePDgTJkyJZ/85CeTJEOHDs3pp5+ef/3rX6mtrc3OO++cK6+8MjU15cnXzzjjjBx77LH5wQ9+kA022CCPPfbYcn/Wscceu9S5G2+8Mcccc0xmz56dT3/603nuuecyefLkXH755Zk4ceKr1jBixIh89atfzbHHHpvm5uZMmTIlv/vd7zJqVN99kaGi1Nra2trnP3UNN2fOnAwfPjyzZ8/OsGHDii5nrdPU1JQrr7wyb3rTm1J/3YnJ375TfuKk2cUWBlAlutyH+3gdHADK3IsBiuU+DFA892Kgv1uwYEEeffTRbLLJJhk4cGDR5ayylpaWzJkzJ8OGDWsP0Slb0b/tyubI/qIUq9IJv/7WxdYBAAAAAAAA0AuE8BRrwJDydvzOxdYBAAAAAAAA0AuE8BSrtaVtp1RoGQAAAAAAAAC9QQhPsRbOKW9v/1GxdQAAAAAAAAD0AiE8xVowq+gKAAAAAAAAoFtaW1uLLoFe1hv/pkJ4ilWq7dh3kwIAAAAAAKAfqK+vT5LMmzev4ErobZV/08q/cXfU9VYx0C11DR37Lc1JrbckAAAAAAAAa7ba2tqMGDEizz33XJKksbExpVKp4KpWXktLSxYtWpQFCxakpkbfdlLugJ83b16ee+65jBgxIrW1ta/+ouWQeFKsN/5Pcuu55f2WxUJ4AAAAAAAA+oUxY8YkSXsQ35+0trZm/vz5GTRoUL/68kBfGDFiRPu/bXdJPClWbadpHFqakgwsrBQAAAAAAABYWaVSKWPHjs3666+fpqamostZJU1NTfnzn/+c17/+9T2adn1tU19f36MO+AohPMWq6fQWbO5fNycAAAAAAACora3tleC2L9XW1mbx4sUZOHCgEH41MME/xbrnoo79lubi6gAAAAAAAADoBUJ4ivXcP8rb9bdOBg4rthYAAAAAAACAHhLCU6zW1vJ24r5JXUOxtQAAAAAAAAD0kBCeYrW2lLclb0UAAAAAAACg/5N8UrC2Tvi7Lkjm/6fYUgAAAAAAAAB6SAhPsSqd8K88m8x+qthaAAAAAAAAAHpICE+xKmvCJ0lLU3F1AAAAAAAAAPQCITzFqnTCJ0nz4uLqAAAAAAAAAOgFQniK9aavJyM2Ku/rhAcAAAAAAAD6OSE8xaqpTeoby/stOuEBAAAAAACA/k0IT/Fq6svbZp3wAAAAAAAAQP8mhKdYt52fPHtveV8nPAAAAAAAANDPCeEp1pO3lbfjtk/GTi22FgAAAAAAAIAeEsJTrNbW8nbygcnQMYWWAgAAAAAAANBTQniK1dpS3pa8FQEAAAAAAID+T/JJwdo64e+/LHnp0WJLAQAAAAAAAOghITzFqnTCP31H8tiNxdYCAAAAAAAA0ENCeIpVWRM+SZqbiqsDAAAAAAAAoBcI4SlWpRM+SVoWF1cHAAAAAAAAQC8QwlOst30nmbhfeV8IDwAAAAAAAPRzQniKNaAxaVy3vG86egAAAAAAAKCfE8JTvNq68rZFCA8AAAAAAAD0b0J4inXrD5I7flrebzYdPQAAAAAAANC/CeEp1sN/Km/H75pMekuxtQAAAAAAAAD0kBCegrWWN9u9KxkzpdhSAAAAAAAAAHpICE+xWlvK21Kp2DoAAAAAAAAAeoEQnmJVQvh/Xp3MvLfYWgAAAAAAAAB6SAhPsVrbpqN/8Irk7z8sthYAAAAAAACAHhLCU6xKJ3yStDQVVwcAAAAAAABALxDCU6wuIXxzcXUAAAAAAAAA9AIhPMU69PzktR8v7zfrhAcAAAAAAAD6NyE8xWpcJxm+UXnfdPQAAAAAAABAPyeEp3i1deVt8+Ji6wAAAAAAAADoobqiC6DK3XJOct2p5X2d8AAAAAAAAEA/pxOeYj3w22TRy8mEPZJdPlx0NQAAAAAAAAA9IoSnWK0t5e0uH0om7ltsLQAAAAAAAAA9JISnWJUQvuStCAAAAAAAAPR/kk+KVQnhH7spefL2YmsBAAAAAAAA6CEhPMVqbS1vb/le8n+fKrYWAAAAAAAAgB4SwlOsSid8krQ0F1cHAAAAAAAAQC8QwlOsziF8c1NxdQAAAAAAAAD0AiE8xTr858nbvlPebxHCAwAAAAAAAP2bEJ5ijRifrLdVeb95cbG1AAAAAAAAAPSQEJ7i1dSVtzrhAQAAAAAAgH6urugCqHJ/+17yyPXl/Rad8AAAAAAAAED/JoSnWHf8NHnugWTzfZIt9y+6GgAAAAAAAIAeEcJTrNaW8vZ1n0g2eX2xtQAAAAAAAAD0kDXhKVZra3lb8lYEAAAAAAAA+j/JJ8WqdMI/fWfyxC3F1gIAAAAAAADQQ2tECP+d73wnEyZMyMCBA7Prrrvm1ltvXeH1l1xySbbaaqsMHDgwU6ZMyZVXXtnl+SOPPDKlUqnLY/r06avzV6C7KiH8Nccn5+/X0RkPAAAAAAAA0A8VHsJfdNFFOfbYY3PiiSfmjjvuyNSpUzNt2rQ899xzy7z+r3/9a4444oh84AMfyJ133pkDDzwwBx54YO67774u102fPj3PPPNM++MXv/hFX/w6rLIlQveWxcWUAQAAAAAAANALCg/hzzzzzHzoQx/KUUcdlcmTJ+f73/9+Ghsbc/755y/z+m9+85uZPn16jjvuuEyaNCmnnnpqdthhh5x99tldrmtoaMiYMWPaHyNHjuyLX4dVVemEr2huKqYOAAAAAAAAgF5QV+QPX7RoUW6//fZ8/vOfbz9XU1OTffbZJzfffPMyX3PzzTfn2GOP7XJu2rRp+c1vftPl3PXXX5/1118/I0eOzBvf+MZ86UtfyqhRo5Y55sKFC7Nw4cL24zlz5iRJmpqa0tQkFO5tlb9pU1NTctgFKS16JXU/nlY+t3B+UqovsjyAtV6X+zAAhXAvBiiW+zBA8dyLAYrlPtw9K/v3KjSEf+GFF9Lc3JzRo0d3OT969Og8+OCDy3zNzJkzl3n9zJkz24+nT5+egw8+OJtsskkefvjhfOELX8j++++fm2++ObW1tUuNedppp+Xkk09e6vw111yTxsbG7vxqrIRrr722vNPakre1nfvDNb/PorqhhdUEUE3a78MAFMa9GKBY7sMAxXMvBiiW+/CqmTdv3kpdV2gIv7q84x3vaN+fMmVKtt1222y22Wa5/vrrs/feey91/ec///ku3fVz5szJ+PHjs99++2XYsGF9UnM1aWpqyrXXXpt999039fXlrvfWu0oppTX7vHGvZMjoFQ8AQI8s6z4MQN9yLwYolvswQPHciwGK5T7cPZUZ1V9NoSH8uuuum9ra2jz77LNdzj/77LMZM2bMMl8zZsyYVbo+STbddNOsu+66+fe//73MEL6hoSENDQ1Lna+vr/emW43q6+tTf/sPk0UvJ2ktn6tJ4m8O0Cd8zgEUz70YoFjuwwDFcy8GKJb78KpZ2b9VzWquY4UGDBiQHXfcMdddd137uZaWllx33XXZbbfdlvma3Xbbrcv1SXmahOVdnyRPPvlkXnzxxYwdO7Z3Cqf33HRW8scvJZPemrzh+GTAkKIrAgAAAAAAAOi2wqejP/bYY/O+970vO+20U3bZZZecddZZmTt3bo466qgkyXvf+95ssMEGOe2005Ikn/jEJ7LnnnvmjDPOyJvf/Ob88pe/zG233ZZzzz03SfLKK6/k5JNPziGHHJIxY8bk4Ycfzmc/+9lsvvnmmTZtWmG/J8vR2lLe7vnZZMyUYmsBAAAAAAAA6KHCQ/jDDz88zz//fE444YTMnDkz2223Xa666qqMHl1eF/yJJ55ITU1Hw/5rX/vaXHjhhTn++OPzhS98IRMnTsxvfvObbLPNNkmS2tra3HPPPfnJT36SWbNmZdy4cdlvv/1y6qmnLnPKeQrW2tq2Uyq0DAAAAAAAgH5v1oxk3ovLf75xVDJifN/VA1Wq8BA+SY4++ugcffTRy3zu+uuvX+rcYYcdlsMOO2yZ1w8aNChXX311b5bH6lTphH/pkfL+qM2TAY3F1gQAAAAAANDfzJqRnL1jsnjh8q+pa0iOvl0QD6tZoWvCQ9LWCX/xe5Jz9kie/0ex5QAAAAAAAPRH815ccQCflJ9fUac80CuE8BSr0glf0by4mDoAAAAAAAAAeoEQnmK1h/Bta8K3NBVWCgAAAAAAAEBPCeEp1rsvS95/dbLOJuXjZiE8AAAAAAAA0H/VFV0AVW7DHcvbAUPK25bm4moBAAAAAAAA6CGd8KwZauvLW9PRAwAAAAAAAP2YTniKdcu5ScvipGlB+dh09AAAAAAAAEA/JoSnWNf+T7J4QbL7p5It9ktGbV50RQAAAAAAAP1P46ikriFZvHD519Q1lK8DVishPMVqbSlvd/5gMnzDYmsBAAAAAADor0aMT46+PZn3YnLD15KHriyf//ANHdc0jipfB6xWQniKM/vJpKUthH/2H8ncF7o+74MAAAAAAABg5Y0YX35s9ZZyCD9xv2TcdkVXBVVHCE8hBi16IXXf2zVpXVw+ceGhS19U11D+xpYgHgAAAAAAYNW1thZdAVSlmqILoDoNWPxKSs0rWJMkKa9ZMu/FvikIAAAAAABgbdE0r7yd/59i64AqJYQHAAAAAACAtcldF5S3T91WbB1QpYTwAAAAAAAAANBLhPAAAAAAAAAA0EuE8AAAAAAAALA22WDH8rZhWLF1QJUSwgMAAAAAAMDaZJ3NytuJ+xVbB1QpITwAAAAAAACsVVqLLgCqmhCeQiyqG5LW2oYVX1TXkDSO6puCAAAAAAAA1havPFvePnN3sXVAlaorugCq0/wB62bxh65P/fd3K594/1VJ3aCuFzWOSkaM7/viAAAAAAAA+rO5L5S3L/6r2DqgSgnhKc7QsR37Y6YmAxqLqwUAAAAAAGBtsdkbk7suSCbsUXQlUJVMR09xWjutR7JobvLyzGThy8XVAwAAAAAAANBDQniK0zmEv+6k5Iwtk7+eXVg5AAAAAAAAa4XmpvK2aV6xdUCVEsJTnNaWjv1SbeVkIaUAAAAAAACsNW49p7x96vZi64AqJYSnQJ0C95q2EL5VCA8AAAAAAAD0X3VFF0AVGzA4eceF5Y74R24on+vcHQ8AAAAAAADQz+iEpzi1A5Kt3pxMOiApVd6KOuEBAAAAAAB6ZPTW5W394GLrgColhGfNUCqVt6ajBwAAAAAA6Jl1Nitvtzmo2DqgSpmOnuI0zU8euLS8HrxOeAAAAAAAgF4ib4EiCeEpzoJZyWUfTmrqkoPOSbZ/dzJ2u6KrAgAAAAAA6N/mvVTePvePYuuAKiWEpzjtU8+XkimHlh8AAAAAAAD0TCWEf+r2YuuAKmVNeArUFsKXvA0BAAAAAAB6zVZvLm833KXYOqBK6YSnOK0t5W2plCxeWH7U1if1g4qtCwAAAAAAoD8rldp2rA0PRdCCTHHaQ/ia5E9fTr46Prnu1GJrAgAAAAAA6O8qSwK3NBdbB1QpITzFqYTwKbU9Et/IAgAAAAAA6KEbzyhvn76j2DqgSgnhKU5rpzXhK9OitArhAQAAAAAAgP7LmvAUZ/B6ycHnJTW1ybP3tZ0UwgMAAAAAAAD9l054itMwNNn2sGSbg9M+HX37FPUAAAAAAAB0y6jNy9u6gcXWAVVKCM+awXT0AAAAAAAAvWOdTcvb7d9dbB1QpUxHT3EWvpz8+6byt7BKle+DCOEBAAAAAAB6Rt4CRRLCU5zZTyYXvbu8NvybvpFsc0gydruiqwIAAAAAAOjfFr5c3r74cLF1QJUSwlOc9vXfS8nWB5YfAAAAAAAA9My8l8rbR/5UbB1QpawJT4HapkIpeRsCAAAAAAD0mimHlbdjti22DqhSOuEpTqUTvlRKWlo6jmu9LQEAAAAAALqtVNmxNjwUQQsyxWkP4WuSv5yZnDoqueKThZYEAAAAAADQ/7Wl8DJ4KIQQnsKUWit3/lK5Gz6JTwMAAAAAAIAeuv608vbZe4utA6qUEJ7itHZeE943sgAAAAAAAHpFy+KiK4CqZvFtCtM6YnxywDeTAUOS2TMqZwutCQAAAAAAAKAndMJTnMHrJTsemUw5NB2d8C1FVgQAAAAAAND/jdiovC3VFlsHVCkhPGuGUttbsVUnPAAAAAAAQI+MnFDevuajhZYB1cp09BRn/qzk8bvL09GX2jrhTUcPAAAAAAAA9GM64SlM6fkHkp8fkvz26GTkJskW+ydjti26LAAAAAAAgP6taX55O3tGsXVAldIJT3EqU8+XapJJbyk/AAAAAAAA6Jn5/ylvH/htsXVAldIJT3FaW8rbkrchAAAAAABAr9nhfeXtulsUWwdUKZ3wFKe9E7604utezawZybwXl/9846hkxPie/QwAAAAAAID+opK9VLIYoE8J4SlQp+no//7D5KrPJZPemhz6w5UfYtaM5Owdk8ULl39NXUNy9O2CeAAAAAAAoEpUGiCF8FAE84BTnMp09CmV95sXJS1NqzbGvBdXHMAn5edX1CkPAAAAAACwNvnjl8rbF/9dbB1QpYTwFGdZ09GbFgUAAAAAAKBnFs8vugKoaqajpzCt605Mpn+1vGb7wjmVs4XWBAAAAAAAANATOuEpzvDxyWs+mmz79rSvTaITHgAAAAAAoGeGjCm6AqhqQnjWDCUhPAAAAAAAQK8YuXF5u8eni60DqpTp6CnOvJeSWY8kDUOTUuX7IEJ4AAAAAACAHmlveiwVWgZUK53wFKY042/Jj6YnV3wqGTou2eT1yeitiy4LAAAAAACgf2teVN7Ofa7YOqBK6YSnOJVvYZVKyRb7lR+rqnFUUteQLF64/GvqGsrXAQAAAAAAVIMFs8rbO36avPXbhZYC1UgIT4FayptSDyZkGDE+Ofr2ZN6L5eNz9yxv33hCsvne5f3GUeXrAAAAAAAAqsFuRyf3X5aM2KjoSqAqCeEpTmsvhPBJOWBfMmQfuXEybruejQsAAAAAANAvta0F37riq4DVw5rwFKcyHX1KyX2/Tr66UXLRe3pn7AGDe2ccAAAAAACA/qZU2ZHCQxGE8BSnvRO+lDQ3JQtmJ4te6dmY9Y3l7fqTejYOAAAAAABAf3XdqeXt7BnF1gFVSghPgdq+fVWqSce0KD38Rlbn7noAAAAAAIBqtGB20RVAVbMmPIVpXX/r5I3/k4zYuPPZHg7aqbseAAAAAAAAoI8J4SnOelsl46aU9+/9VXlbCdG7q3lhefv0XcmIjXo2FgAAAAAAQH/UuE7RFUBVMx09a5aeTkc/amJ568MFAAAAAACoVsM3LG/fcHyxdUCV0glPcea9lMybmTQM673p40tt3yvpaZgPAAAAAADQX8lJoFA64SlM6Z+/T855ffL7zyaNo5INdkrW27KHg1ZC+B5Oaw8AAAAAANBftTSXt4teKbYOqFI64SlQ27ewSjXJpnuVHz31/D/K23kv9nwsAAAAAACA/mjh7PL2prOSfU8utBSoRjrhKU6lW720Gt6GLYt7f0wAAAAAAID+YM//Lm+HjC62DqhSQniK09qpE743xwMAAAAAAKhqpfJGdgKFEMJTmFLnddv//YfkjEnJL47o/oCdP0gGDOn+OAAAAAAAAP1ZqS2EjxAeiiCEpzidO+EXL0xefjqZ+3wPxusU6m/0mp7VBgAAAAAA0F9dd0p525PcBeg2ITwF6jwdfW9Mi9Lpte3f8AIAAAAAAKgyrzxbdAVQ1eqKLoDq1Tp2arLHZ5L1J3VaF74HIXznTvgI4QEAAAAAAIC+J4SnMK0b7JRM2K188M+r2062LP8Fq+KxG5NJB/TOWAAAAAAAAP1Jw7CiK4CqZjp61hC9MB19XUOy4c5dxwMAAAAAAKg2Q8eWt/ueUmwdUKV0wlOc+f9JZs9JGoZ2WsO9J2vCp3emtQcAAAAAAFgraFqEIuiEpzA1d1+YnL1jcu3/lIP49bdO1tm0h6NWOup7aVp7AAAAAACA/qaSk7QsLrYOqFI64SlQW7d6qSbZ6DXJx/7as+EWzUtm/K28v3hRz8YCAAAAAADorxbOKW+vOznZ49hia4EqpBOe4lS+hVXqpbdhS9PSYwMAAAAAAFSb/b5U3jYML7YOqFJCeIrTWlm3vZfWI2m1DjwAAAAAAEBH9iI7gSII4SlOeyd8KZnx9+TbOyYXvL0nA3bsDhjco9IAAAAAAAD6rVJbCK+BEQphTXiK09ppTfjF85MX/53U9OAt2fmDZMv9e1YbAAAAAABAf/WHk8rbRS8XWgZUK53wFKfLmvC98I2szq/trXXmAQAAAAAA+pvZM4quAKqaTngK07rBjslrPpZsuHPHtCg9WZukEuonncYDAAAAAAAA6DtCeArTuukbki33Kx88/te2k720NsmDVyZbval3xgIAAAAAAOhP6huLrgCqmjm7WUNUpqNvWfFlKzJkvWTzfcv781/qeUkAAAAAAAD90eD1ytv9v15sHVCldMJTnAVzknkLkoYhvTMdfdKxFnxvddQDAAAAAAD0O205ieV7oRA64SlMzc3fTv53cvKnryR1A5ORE5LhG/Zs0FIvdNQDAAAAAAD0Z5oVoVA64SlQ5VtYNcm47ZJP3N2z4ea+mPzzqq5jAwAAAAAAVJtFc8vbKz+T7PKhYmuBKqQTnuK0d6v30lQoTfM6jS2EBwAAAAAAqtQB3yxvaxuKrQOqlBCe4lRC+N5aj6TzFPSmowcAAAAAAKpVe/aiaRGKIISnQJXp6EvJcw8m3989+fkhPR8vSeobe1QZAAAAAABA/9UWwps5GAphTXiK094JX5Msnp/MvDcZ9lIPxmv7IKkfnGx3RM/rAwAAAAAA6I+uO6W8bWkqtg6oUjrhKU7nEL43vpHVZTwAAAAAAIAq9cI/i64AqppOeArTusHOyQ4LknE79O7aJL21xjwAAAAAAADAKtIyTGFaJx+YvPVbyeS3dnSv96gTvu21C+ck913a4/oAAAAAAAD6pdoBRVcAVU0IzxqiMh19S/eHGLVZsvXB5f2Xn+l5SQAAAAAAAP3RoJHl7QHfKrYOqFKmo6c4i+Ymi1uTukG9Mx19qZTU1rcN0wvT2gMAAAAAAPRLbTmJJXyhEDrhKUzNdScmX5uQ3HRWUlOfDF4/GbxeD0fthY56AAAAAACA/qy9WVEID0XQCU9xKh8ApZpkvS2S4/7Vs/FmP5nc88vK4D0bCwAAAAAAoL9qmlfeXn50ssN7iq0FqpBOeApTau9W76VvYS2Y3bGvEx4AAAAAAKhWh/6o6AqgqgnhKU4lKO+t9Ug6B+/WhAcAAAAAAKpV5+xFZgJ9TghP8Uql8lTyP5yW/Ozg7o/T+UOktr7ndQEAAAAAAPRLQngokjXhKU57J3xNsnhhMuNvScPwngxY3gwdm7z24z0uDwAAAAAAoF/64ylFVwBVTSc8xVnWmvA9Wcu9c6gPAAAAAABQrZ65u9OBTnjoazrhKUzrBjslaUnW26rT2iQ9+CBon06ll9aYBwAAAAAA6O9MRw99TsswhWnZ8ajkkPOSLad3dK/36IOg7bVznkzu+kWP6wMAAAAAAOiXavThQpHWiBD+O9/5TiZMmJCBAwdm1113za233rrC6y+55JJstdVWGThwYKZMmZIrr7xyudd+5CMfSalUyllnndXLVdO72rrXezId/djtkm3fUd5/6ZEeVwQAAAAAANAvDRhc3h50blIrkIe+VngIf9FFF+XYY4/NiSeemDvuuCNTp07NtGnT8txzzy3z+r/+9a854ogj8oEPfCB33nlnDjzwwBx44IG57777lrr2sssuy9/+9reMGzdudf8adEdzU7J4UdLS0jvT0dfUJgOH93wcAAAAAACAtUHJEr5QhMJD+DPPPDMf+tCHctRRR2Xy5Mn5/ve/n8bGxpx//vnLvP6b3/xmpk+fnuOOOy6TJk3Kqaeemh122CFnn312l+ueeuqpfPzjH88FF1yQ+vr6vvhVWEW1v/1I8qX1kr//ICnVJgOGJgOG9GzQUi901AMAAAAAAPRn7cv/CuGhCIXOP7Fo0aLcfvvt+fznP99+rqamJvvss09uvvnmZb7m5ptvzrHHHtvl3LRp0/Kb3/ym/bilpSXvec97ctxxx2Xrrbd+1ToWLlyYhQsXth/PmTMnSdLU1JSmpqZV+ZVYCZW/aUtLS2qSNLe0pqVx/eS4RysXdG/glx5J/S3fT5I0Nzenxb8dwDJV7sM+4wCK414MUCz3YYDiuRfD6lXbNL/ciXvpB9M0cXpSN7DokljDuA93z8r+vQoN4V944YU0Nzdn9OjRXc6PHj06Dz744DJfM3PmzGVeP3PmzPbjr33ta6mrq8sxxxyzUnWcdtppOfnkk5c6f80116SxsXGlxmDVPffszIxLct/99+ex567s8XjrvPJQ9mjbf+Tf/8oD83s+JsDa7Nprry26BICq514MUCz3YYDiuRfD6lG3zgfy5idvTZJcddVVaakZUHBFrKnch1fNvHnzVuq6QkP41eH222/PN7/5zdxxxx0preQ6F5///Oe7dNfPmTMn48ePz3777Zdhw4atrlKrVlNTU6699tqsv/56yaxkm22mZPKOb+rxuKUnRiT/Ku9vutmmmfDGno8JsDaq3If33XdfS7YAFMS9GKBY7sMAxXMvhtVs4cvJPeXd6dP2S+o1ndKV+3D3VGZUfzWFhvDrrrtuamtr8+yzz3Y5/+yzz2bMmDHLfM2YMWNWeP2NN96Y5557LhtttFH7883Nzfn0pz+ds846K4899thSYzY0NKShoWGp8/X19d50q1FN27a2ri61TS8nv/5AklLynku7N2BtbcduTU1q/dsBrJDPOYDiuRcDFMt9GKB47sWwmrR0dL7X19Ul/jtjOdyHV83K/q1qXv2S1WfAgAHZcccdc91117Wfa2lpyXXXXZfddtttma/ZbbfdulyflKdJqFz/nve8J/fcc0/uuuuu9se4ceNy3HHH5eqrr159vwzd0FrelGqSlsXJw38sP7o9XEt5u+6Wyb6n9Lw8AAAAAACA/uhPXy66AqhqhU9Hf+yxx+Z973tfdtppp+yyyy4566yzMnfu3Bx11FFJkve+973ZYIMNctpppyVJPvGJT2TPPffMGWeckTe/+c355S9/mdtuuy3nnntukmTUqFEZNWpUl59RX1+fMWPGZMstt+zbX44Vq4TmKbU9kvZgvlvjdQr1AQAAAAAAqtUTN3fst/YgewG6pfAQ/vDDD8/zzz+fE044ITNnzsx2222Xq666KqNHj06SPPHEE6mp6QhVX/va1+bCCy/M8ccfny984QuZOHFifvOb32SbbbYp6legm1o32CmpqUtGbJSUSp2eaO16vNIDtoX63XktAAAAAADAWkkID32t8BA+SY4++ugcffTRy3zu+uuvX+rcYYcdlsMOO2ylx1/WOvAUr+V1n+pYt33eSx1PdDeEr3yIPPdAcvuPkx2P7GGFAAAAAAAA/VCXWYM1L0JfM283a572aepX0cavS3Z4b3n/2ft7rx4AAAAAAID+pHZAeXvYT5KGIcXWAlVICM+aoUvnezenRalrSIaObRvC1CoAAAAAAECVquQklvCFQgjhKUztL96enDIqueeS8rQopZqkVNvDAL3tw6S73fQAAAAAAAD9XiVrEcJDEdaINeGpUi2Ly48kGTg8OfE/PRvvuQeTG77adqATHgAAAAAAqFLNTeXtxe9JPjcjGTis2HqgyuiEpziVbvXemgpl1uNLjw0AAAAAAFBtjvy/jv3W5uLqgColhKdAvbweSefg3ZrwAAAAAABAtaod0LEvM4E+J4SnOO2d8DXJ4oXJL99VfjQt6OZ4nT5EdMIDAAAAAADVqrcaIIFusSY8xamE5qWacmj+4BXl48o68as8XlvwPnZq8pazelweAAAAAABAv/SnrxRdAVQ1nfAUp71zvdT2qJzvbhd723h1A5Na3y8BAAAAAACq1MN/7Ng3HT30OUklhWkdt10yYFAyZP0lpkXp5odBl1AfAAAAAACAbucuQLcJ4SlMy75fTm19ffmguanjie5+I6vSQT/jb8mtP0h2+VDPCgQAAAAAAOjvSibGhr7mvzrWEL0wHf3m+yQ7faC8P+PWnpcEAAAAAADQL7U1PL7z4qRxnWJLgSokhGfNUOqFKeQbhiSjNm87MLUKAAAAAABQpSzhC4USwlOY2p8dkJw2Pvn3denaCd+DAL0S5ne3mx4AAAAAAKDfa8taeqMJElhl1oSnMKWFryQL55RD91Ip+eKz5W3tgO4N+Mw9yXWnlPd7EuQDAAAAAACsDS44NDnukWTwqKIrgaqiE57iVILyUsrhe/3ApK6h+9/Kev6hpGle29g64QEAAAAAgCp15P917Lc0FVcHVCkhPAWqhPC99DbsErzrhAcAAAAAAKpUw9CkVFveN3sw9DkhPMWphOaVEP6yjyS//mAy/z/dHXDpsQEAAAAAAKqR9eChMEJ4CrREJ/y9l5QfTfO7OVxb8L7BTslB5/S8PAAAAAAAgP7ohtOTlsVtBzrhoa8J4SlOe7d6qeu2u9OiVF43aGQyYHBPKgMAAAAAAOi/Hvhtx77p6KHP1RVdANWrdcy2KQ0amQwcVj5RmRal21PJ9/Ia8wAAAAAAAP1Rl+BdCA99TQhPYZrf9v3U1Nd3nGgPz7vbCd8W3v/r6uSWc5Jd/1+P6gMAAAAAAOj3NC9Cn/NfHWuQHk5Hv9Vbkl0/Wt7/93W9UxIAAAAAAEC/05a1vPe3ybBxxZYCVUgIz5qjMh19dzvhG9dJxkxpG6K7U9oDAAAAAAD0c+0Nj6UVXgasHkJ4ClP7o2nJN7ZMnr6r7UwPO+GTjilVhPAAAAAAAEDVastaSkJ4KII14SlMae7zySszk5bF5ROfuq/8YdAwrHsDPnVHcuM32g56EOQDAAAAAACsDX5yQHLsg8mwsUVXAlVFJzzFqXSrV76F1bhOMmhkUlPbvfGeuj158d9dxwYAAAAAAKg27/tdx/7iBcXVAVVKCE+BKlOhrIa3YU+mtAcAAAAAAOjPhqyf1A9uO5CZQF8TwlOc9m71tk74q76QXH5M8vLMHo4XnfAAAAAAAEB1sx48FEYIT3Hap6NvexvefWFyx0+SBbO7OV7bN7nGvyY57Cc9rw8AAAAAAKA/+vM3kkWvlPfNHgx9TghPcSo3/fZvYpW6nl/1Acub4Rskg0f1pDIAAAAAAID+664Li64Aqlpd0QVQvVrX2yqlIaOTukHlE5UwvrtTyS/ZWQ8AAAAAAFDtdMJDnxPCU5jmd12amvr6TmcqHfHd/DCofIjce0mywU7Jaz7Sk/IAAAAAAAD6qU5Zi7Xhoc9pGWbNUelg7+43sqYcmrzuE+X9+y/tnZoAAAAAAAD6m0rW8v6rk1GbFVsLVCEhPGuOUg874YeOScbv2jZEN6e0BwAAAAAA6PcqWYsueCiCEJ7C1J33huSb2yX/eaztTGVN+B6sTdLTbnoAAAAAAID+rpKTmIoeCmFNeIoz67Fk4ctJS3P5+MPXlzvYB6/XvfGevD25+TvlfZ3wAAAAAABAtfvZwcnHbk5GjC+6EqgqOuEpTiUor3wLa9jYZPgGSd2A7o336PXJYzd2HRsAAAAAAKDavO/y8nbRy8miucXWAlVICE9x2meM76WpULpMQW86egAAAAAAoEqNnJA0jmo7kJlAXzMdPcVp74Rv+y7IDacn815KdvtYMmKjbozX6UNEJzwAAAAAAFDVrAcPRdEJT3GWDOHv/Flyy/eSV57r7oDlzca7J++4sMflAQAAAAAA9Es3fTOZ90J5v1UnPPQ1ITwFarvpV9aEr3wjq7td7JUPkXUndq+THgAAAAAAYG1wy7mdDoTw0NdMR09x1tk0aW5KaurLx5UwvrvfyFqysx4AAAAAAKDa6YSHPieEpzCLP/yX1NfXdzpT6Yjv7odB2+tu+2EyavPy2vIAAAAAAABVR/AORdIyzJqj0sHe3W9kTT0ief1x5f3bf9wrJQEAAAAAAPQ7lazlwzckY7YpthaoQkJ41hylHq4Jv84myaZv6NkYAAAAAAAA/V5bCF/JXoA+JYSnGK2tqfvB65PvvS6Z/5+2kz2djj6d1oM3zQoAAAAAAFCl2mcdFsJDEawJT0FaU3rugbbdtg+Cd12StCxOhm3QvSGfvK1jGnqd8AAAAAAAQLW76N3Je39bnk0Y6DM64SlEqXOnemUqlHU2SdadmAxo7N6g//hdcs8vy/tCeAAAAAAAoFq957LydtbjyYLZxdYCVUgITzFaO08X30tToXQO3ltNRw8AAAAAAFSp0ZM7zTwsM4G+Zjp6CtG1E77tuyC3nJu8MjPZ7l3JqM26MWqnMYXwAAAAAABAVbMePBRFJzwFWUYIf/uPkxvPKE+N0q0h28bcdK/kXRf3pDgAAAAAAID+62/fS+Y8Wd7XuAh9TghPIUqty1gTvhLGd/fDoPK6sVOT9Sd1vzgAAAAAAID+7M/f6HQghIe+Zjp6CtM6dGx5IpRK+F6ZFaXb38hqe13Jd0sAAAAAAACSyOChAEJ4CtFc25DFx9yb+vr6TmfbU/iOU7NmJPNeXP5AjaOSEePbXtZS3v7lf5Mho5PXfLQ3SwYAAAAAAOgnJO9QJCE8a44lp6OfNSM5e8dk8cLlv6auITn69nIQv8P7yqH8n75cDuKF8AAAAAAAQDWqZC3/78Zk9DbF1gJVyLzdrDkqa8NXOtrnvbjiAD4pP1/plB89OdnyTV3HAAAAAAAAqDptIXxdQ1IjDoS+5r86ClHXPC+1P56enLdv0lIJzJcxHf2qWrKbHgAAAAAAoNq05ySlFV4GrB6mo6cQNS2LU/PUbeWDSgf8Qecki+cnIyd0b9Anb0sevKK8rxMeAAAAAACodpd+KDnkh8m6mxddCVQVnfAUrxLCr7dFMnZqMnB498a564LyWvBJetRNDwAAAAAA0J+9+9fl7TN3JfNeKLQUqEZCeApRypJT0PeCzlPQ64QHAAAAAACq1YY7JetsWnQVULVMR0+xSp2+B3L3RcnsGcmkt5a74ldV5+DdmvAAAAAAAEBVa2uElJlAnxPCU4hSJTAvdeqEv/1HyRM3J+tO7F4IX5mCfvN9kz3/u8c1AgAAAAAA9Eu3/iB56eG2AyE89DXT0VOszp3wS34jq3FUUtew4tfXNZSvSzo64Td6TTJ+514tEwAAAAAAoN/4w8lFVwBVTSc8hWkdODyl2gEdJyqBfCVMHzE+Ofr2ZN6L5eNz9yxvt9g/2etz5f3GUeXrko4vcpV8twQAAAAAAKhmnbrfTUcPfU4ITyEWDFgniz/9cOrr6ztOtk9N3+nDYMT4jpC9YvCoZNx2Sw9aCe9vPTcZMCTZ9cO9WTIAAAAAAED/IHiHQgnhWfPMfSF5+q7lP79o7rLP7/yB8lryfzgpueZ4ITwAAAAAAFDdPnx9MnqboquAqiOEZ81R6YS/+gtJy+LlX/fA5cmsGUt3yG+4UzJ0TDmEr3TFAwAAAAAAVJ22TvhBI5Pa+hVfCvQ6i2dTiIGLXkrtBQclvzii09m2EH5FAXyStDZ3rBO/pPb14E2zAgAAAAAAVKn26ehLK7wMWD2E8PStWTOSZ+7OyLmPpOaxG5NH/lyeev7pu5Idj0z2OaX7Yz95e/KPK8r71joBAAAAAACq3RWfTJ7/Z9FVQNUxHT19Z9aM5OwdU794YXapnGt6JTl3z45rejIlyt++m9z3q/K+6egBAAAAAIBqdcQvkp8dmDz8x+Tlp5P1tii6IqgqOuHpO/NeTBYvXPE1zU09+AGty9kHAAAAAACoIpu9IVl/6/K+2YOhzwnhWXss2f3uQwUAAAAAAADoY6ajZ+1RCd232D/Z5UPF1gIAAAAAAFCUO36aPHd/24GmRehrQnjWHpVO+M33Lj8AAAAAAACq0RWf6tg3czD0OdPRs+Yp1b76842jlvFE24dIydsaAAAAAACgTAgPfU1ayZpnpw8kH74h2Xj3jnMfvqFjf5uDkhHjl35d5Ztcd/4sue1HSfPi1VsnAAAAAADAmkj3OxRKCM+aZ+DQZNx2yfhdysejp5SPK+oHL/t1O38wmfaV5Ok7kys+mbQ0reZCAQAAAAAA1kRtIfyH/ti16RHoE0J4+k7jqKSu4dWvq29s2w4qbzfcqes3tmrrl/26zd6Q7PC+jmPf8gIAAAAAAKpRJSMZtkFSP7DYWqAK1RVdAFVkxPjk6NvTNOfZ3PnHS7PT4ttTM3R0ssex5eevOT557MZk0IjycfOi8ra2PimVks/8O1k4Jxk0cvk/o/N68K0tq+XXAAAAAAAA6B9KRRcAVUknPH1rxPhk7NQsqhuemif/ljz3QHmq+XHbJdO+nLz718kW08vXvvxMeXvXL8rbIeslozZLGtdZ9thP35k88qdOJ3TCAwAAAAAA1agtI7n688lzDxZbClQhITyFKKWtS72mtuPk2KnJ5vskwzcsH896orxd9PLKDfrHLye/fGfHsU54AAAAAACgGh1+QXl736+TWY8XWwtUISE8hShVAvLSCt6CLZ1C9IWvJCcNLz/uv2w5L1ii892a8AAAAAAAQDWa9JZk3A5FVwFVSwhPQdoC8lKnTvhH/5zc/pPk2QfKx2/4QsdzLYu7XrfMIZcM4XXCAwAAAAAAVU7TIvQ5ITyFaO+Er+n0Frz9x8nvjkkevaF8PHRMedswbIlAvbTsQSvXbPWW8jQrA4b0ZskAAAAAAABrvtbW5J5LkqfvqJwotByoRnVFF0B1KrV3wtd0OZuk4xtZledamsuPdsv7sGg7P/lt5WlWAAAAAAAAqk1rS3LpBzsdC+Ghr+mEpyDLmI6+VAnh2zra77+0vG2am7R2CuGX92HRfn45nfIAAAAAAABVRwgPfU0nPIV4dth2afr8zNTXdXoLtnfFt30YPHB5x3Odp6PvHMh31h7eX1YeY9IBSf2g3ioZAAAAAABgzafzHQqnE55ilEpJTV1SW9/5ZHlT+XBoGFrebnt41+nou6wP38kuH06mfzV56P+SSz+ULJjd62UDAAAAAACs2TqF8B+8Ltlkz+JKgSolhGfNUZmOfsn14ifu1zWsb1lOCD/5rclrPloO95Plh/UAAAAAAABrq86d8KM2TxqGFFcLVCnT0VOIdV75Z2ovuzQZs03y+uPazi6xJnxzU3lbW58MHZN85t/JK88mg0asePBKeG+6FQAAAAAAoJq1N0ACfUknPIVoXPRCah74TfLojR0nd/lQcvjPk60OKB8veqW8vfOCpHlxMmS9cmg/fMNlDzrz3uTxvybNi8rHOuEBAAAAAICq06lJ8Y9fSp59oLhSoEoJ4SlI2wdATW3HqQ12SCYdkKy7efl40dzy9l9XJ80LX33I//t08qP9l/4ZAAAAAAAA1aKmLjn4B+X9W89NXvxXsfVAFRLCU4hSpUu9tIK3YOdO9uceTE4aXn7cf9lyrl8idNcJDwAAAAAAVJua2mTbtycbvbZ8bPle6HNCeApRSiWE79QJ/9TtyT2XdEyL8o4LOp5rmtexf9+vlzPqkiG8DxUAAAAAAKDayUugrwnhKUbrMqajv+OnyaUfTB68ony83qSO5yrrvCdJy3I63Cud71PeXp5mZfC6vVcvAAAAAABAf9C8OPnHFckTfy26EqhadUUXQHXq6ITv9D2Qyn57QN/pueamjv3W5mUPWnndNockW07vnUIBAAAAAAD6k+aFyUXv6jg2czD0OZ3wFKJUueF3WRO+VN5UOtr/enbHU5074Ze71ntlzFJvlAgAAAAAAND/LBW6C+Ghr+mEpxCPj9ozkw8/MfUDGjpOtofnbR8GN5ze8VyX6eiX1wnfFs4//Mdy5/ymeyYNQ3utZgAAAAAAgDWf0B2KJoSnEK01dcnAYUl9faezlU74tg+HSvA+/avJwOGdXrycTvhdPpy8PDP546nJLd9PPnZLsv5WvV47AAAAAABAv/CBa5N1JxZdBVQdITxrjvap6ZcI4ScfmLz8dMd1y1sTfvt3l7d/+14y74UVTFsPAAAAAACwluo8Hf2YbZP6gcXVAlVKCE8h1p9zT2qvuDrZeLdkh/eUT5Y6rQnf0tIRttcOSDbYMTnu4eTFh7t2xS/LkmE+AAAAAABA1eiUj7QvBQz0JSE8hRg2f0ZqHr4oSWtHCL/t25NxOyTrT0pamjouvv/SZMphyeB1y4/lee7BZPGCZNHc8rFOeAAAAAAAoJrdeEZ5xuHRk4uuBKpKzatfAr2vVAnIazq9BTfYMZl6eDJ2246p6JPkys8ks5989UEvOTI5d8+kqRLC64QHAAAAAACqTN2g5C1nlfdv+Foy895Cy4FqJISnEKXKVCil5bwFm5u6Hj/8x+TkkclJw5N7Ll7OqEuE7jrhAQAAAACAalM3INnpqGTTNxRdCVQtITzFqATkpdqOc8/9I3nw/5JnH0gahibvv6bjuQWzO15zy/eXM+aSne864QEAAAAAgCrVvh68vAT6mhCeQpRSCeE7vQXvuiD55TuTuy9MauuTjXZNRmxcfq55Ycd1Lc3LHrQS0u94VHmaleHje71uAAAAAACANVpzU3mG4UduKB9bvhf6XF3RBVCdOtaEr+18trzp/GFQeb7z9PTLnWa+7XXbvj3Z+LW9USYAAAAAAED/svDl5GcHdTohhIe+JoSnEB1rwncK4Tt3xc99Mbnnl8lLj5SPmxd1PLe8EL71VdaZBwAAAAAAWNst2fmuEx76nBCeQvxr9FuyyeGnpX7Q0I6TlbVJWluSOU8lV3+h47nOIfyrTUc/49Zk0dxkgx2TQSN6tW4AAAAAAIA1m9AdiiaEpxCLawclQ8ck9fWdznaajr7z9PMHn5fMebLjeHmd8Lt8KJn3UvLHU8uh/fuvTjZ6Ta/XDgAAAAAAsMbq3Pl+1FXJqM2KqwWqlBCeNUf7NPKtHZ3v62yabHtYcv9vOq5rXU4n/G7/Vd4+8JvkxX+bXgUAAAAAAKhCnfKRjXcrrgyoYkJ4CjF21t9Tc/WNycR9ki2nl092no6+pa0TvnZAebv1gcmmjydP35kMGLziwSth/vI65gEAAAAAAABWEyE8hVj3lQdT++i1yaDhHSH8lvsnw8Yl609OFr1SPvf8g8k/fpdssFMybGyy2RuWP+hLj5TXi1+8sHwshAcAAAAAAKpN55mCb/5usuleyejJhZUD1ajm1S9Z/b7zne9kwoQJGThwYHbdddfceuutK7z+kksuyVZbbZWBAwdmypQpufLKK7s8f9JJJ2WrrbbK4MGDM3LkyOyzzz655ZZbVuevwCoqVQLymtqOkxvsmOz0/vI67p3XhL/o3cmTf3/1QX/8luTsnZJZj7edMB09AAAAAABQZRqGJNO+Ut6/+vMrl7EAvarwEP6iiy7KsccemxNPPDF33HFHpk6dmmnTpuW5555b5vV//etfc8QRR+QDH/hA7rzzzhx44IE58MADc99997Vfs8UWW+Tss8/Ovffem7/85S+ZMGFC9ttvvzz//PN99WvxqtoC8tJy3oKdQ/gkueei5MzJydcmJHf9YjlDLhG664QHAAAAAACqzYDByW7/lWz5pqIrgapVeAh/5pln5kMf+lCOOuqoTJ48Od///vfT2NiY888/f5nXf/Ob38z06dNz3HHHZdKkSTn11FOzww475Oyzz26/5p3vfGf22WefbLrpptl6661z5plnZs6cObnnnnv66tfiVbR3wpc6dcL/57Hk4T8lzz+UbLRb8p7LkrqB5edenpnMeSqZ/5/kDycte9AlQ/clQ3kAAAAAAICqIy+BvlbomvCLFi3K7bffns9//vPt52pqarLPPvvk5ptvXuZrbr755hx77LFdzk2bNi2/+c1vlvszzj333AwfPjxTp05d5jULFy7MwoUL24/nzJmTJGlqakpTU9MyX0P3NTU1pdR2w29ubU1L29+45s5fpPbPX03z9u9Ny5vOTDbaI7Ub7pKax/6c1sULU2p7fWtrcxYv49+lrrUlpSTNr/mvZOjYtAzfOPHvB7CUymebzziA4rgXAxTLfRigeO7FsBotXpjSzLtT++RtKSVZvHhxWv23xhLch7tnZf9ehYbwL7zwQpqbmzN69Ogu50ePHp0HH3xwma+ZOXPmMq+fOXNml3NXXHFF3vGOd2TevHkZO3Zsrr322qy77rrLHPO0007LySefvNT5a665Jo2NjavyK7GStm/rWn/wn//Kv2dfmSTZYua/MinJjCeeyN1Xls+95sX/ZHSSl2e/lGFtr120cEGuanu+s2kLF2Zgkj/PGps5CzdKXrg3yb2r/XcB6K+uvfbaoksAqHruxQDFch8GKJ57MfS+gYteyrT7P9l+fN999+bxmUvnKpC4D6+qefPmrdR1hYbwq9Mb3vCG3HXXXXnhhRfygx/8IG9/+9tzyy23ZP3111/q2s9//vNduuvnzJmT8ePHZ7/99suwYcOWup6eaWpqygvnnZMk2WrS5GzxmvKaJDU3PZQ8k2w0fsNssNMmKT3199Te93CSZGhjQ7Kg/PoBdbV505uWXsek7qFjk8XJ7nu8Pll/ct/8MgD9UFNTU6699trsu+++qa+vL7ocgKrkXgxQLPdhgOK5F8NqNOfp5P6Owylbb52td7Q+PF25D3dPZUb1V1NoCL/uuuumtrY2zz77bJfzzz77bMaMGbPM14wZM2alrh88eHA233zzbL755nnNa16TiRMn5oc//GGXqe8rGhoa0tDQsNT5+vp6b7rV5P5xR2Ts4f+b+qHrpbbyN64trw9fU0pqZtyUXPW59utLzYs79ltblvPvUp7ivv6lfyXN85N1t0ga11ltvwNAf+dzDqB47sUAxXIfBiieezGsBnW1XQ5ra2s7shhYgvvwqlnZv1XNaq5jhQYMGJAdd9wx1113Xfu5lpaWXHfdddltt92W+Zrddtuty/VJeZqE5V3fedzO675TrEX1w5J1Nl0iJG9b9b01SfOi8v7g9ZMDvpmM37njsrap7Jey0/uT13wsufbE5PxpyYxbV0fpAAAAAAAAa67W1o79d1+abDGtuFqgShU+Hf2xxx6b973vfdlpp52yyy675KyzzsrcuXNz1FFHJUne+973ZoMNNshpp52WJPnEJz6RPffcM2eccUbe/OY355e//GVuu+22nHvuuUmSuXPn5stf/nLe+ta3ZuzYsXnhhRfyne98J0899VQOO+ywwn5PVkKp8p2Q1qS5qby75fRkxyOTBXOS+35dPtfSvOzXv/H48nbGrcmcJ1PpjAcAAAAAAKgebflI3cBk872LLQWqVOEh/OGHH57nn38+J5xwQmbOnJntttsuV111VUaPHp0keeKJJ1JT09Gw/9rXvjYXXnhhjj/++HzhC1/IxIkT85vf/CbbbLNNkvKUGg8++GB+8pOf5IUXXsioUaOy884758Ybb8zWW29dyO/I0jZ86abU/On2ZNIBHV3upUonfEtHCF/TNqXD645Jdv5g8sifkppXedtWwvzldcwDAAAAAACs9UpFFwBVq/AQPkmOPvroHH300ct87vrrr1/q3GGHHbbcrvaBAwfm0ksv7c3yWA3GzrottY/fnozcuCOEn7BHMu0ryXpbJo/dVD730sPJv69LRm1evnarNy9/0NlPJWlNWts65YXwAAAAAABAtalMR794fnL7j5PxuybrTyq0JKg2ha4JT/UqpS0gL3V6C26wQ7LbfyWb75O0tHXCP3J98vODkwd+++qDfmfX5H+3TmY/WT5uNR09AAAAAABQZQYO71jC93efSB69sdh6oAoJ4SlEqRKQ19Qu+4LKdPQVN38nOWfP5Pz9k7t+sZyAve1cqW1MnfAAAAAAAEC1GTQief1xydYHtZ3QtAh9bY2Yjp7q09EJ3ymEf3lm8p/Hk8Z1kh3eV56e/q/fSmbckrwys/xIkif+mmz79q6vTTpC9/Zg34cKAAAAAABQ5cwcDH1OCE8xKjf8ztPR339ZctXnkm0OSQ49Pxk9Ofn3H8oh/JJampfuoq+MucP7klKS9axvAgAAAAAAVJnFC5PnH0qee7DoSqBqCeEpRHsnfJcgvVTedP5G1vKmq1/mVPNtr5v6jmTE+J6WCAAAAAAA0P/MeSo5Z49OJ3TCQ18TwlOI0rI64dv3W5PH/pLMeaY8Pf2ytDYv41xlivtSr9UJAAAAAADQryw5/bzp6KHPdSuEnzFjRkqlUjbccMMkya233poLL7wwkydPzoc//OFeLZC1010bvT97vXan1I+a0HGyEp63tiR/+17y4BVJ3cBlD7CsTvjKh8isJ5J5LybDx5fXlwcAAAAAAADoIzWvfsnS3vnOd+ZPf/pTkmTmzJnZd999c+utt+aLX/xiTjnllF4tkLXTvIb1k9HbJINGLv1ka2vS3FTe3/qgZNppychNul7TsoxO+B3eW14P/prjk3Nen/zrmt4vHAAAAAAAYE3WufP98J8nW0wrrhaoUt0K4e+7777ssssuSZKLL74422yzTf7617/mggsuyI9//OPerI9q0nk6+uZF5d1N35Ds9rFk072S+sEd1y6rE/4tZyZv/VZHsG96FQAAAAAAoOq05SMDhyeTDkhGbVZsOVCFujUdfVNTUxoaGpIkf/jDH/LWt741SbLVVlvlmWee6b3qWGtt9OINqbnxgWTbw5J1Ny+fbJ+OvlMnfG19eXvAWclb/je591fl6wYMXmrMDp2mtQcAAAAAAKhKpaILgKrVrU74rbfeOt///vdz44035tprr8306dOTJE8//XRGjRrVqwWydprwwp9S++evJi/+u+PkuB2SNxyfTDk0aWkL4ee+kDzxt+TFh8vh+7aHlZ+va1h60HkvlR/tdMIDAAAAAABVpjJT8IJZyT2XJM8/VGg5UI26FcJ/7WtfyznnnJO99torRxxxRKZOnZokufzyy9unqYcVKVW61Eud3oLjtkv2PK68DnxlOvp7fpmcPy25+ewVD9jampy+Sfkx/z9t53TCAwAAAAAAVaZxnWT3Y8v7l34w+edVxdYDVahb09HvtddeeeGFFzJnzpyMHDmy/fyHP/zhNDY29lpxrM3aAvKa5XwPpDIdfd2g8va285OXHklGblJeH37ifsmATu+1zuu/19S2nRPCAwAAAAAAVWbwusk+JyYvP5Pc/Yuiq4Gq1K0Qfv78+WltbW0P4B9//PFcdtllmTRpUqZNm9arBbJ2KlVC81Jtx8l5LyVznkoGDEn2OTmZ/1Ly1B3J438pP//I9UmuT27/UfLJe5MBG3UasVMIXxmz1XT0AAAAAABAtWpbE15eAn2uWyH82972thx88MH5yEc+klmzZmXXXXdNfX19XnjhhZx55pn56Ec/2tt1spYpZRnT0T90ZfLb/yp3ub/rkvK5l59Z9gAtzV2PO3e9b31gstFrkjHb9lq9AAAAAAAA/cLihcnsJ5NZj7edEMJDX+vWmvB33HFH9thjjyTJr371q4wePTqPP/54fvrTn+Zb3/pWrxbI2ql9Tfia2s5ny5vWZXS1L2nJqeY7v2bqO8rTrGy4Y4/rBAAAAAAA6FdefDj59g7J4zeVj3XCQ5/rVif8vHnzMnTo0CTJNddck4MPPjg1NTV5zWtek8cff/xVXg1JqfKtq86d8O37rclDvy8H7YvnL3uApUL4zsel3ioTAAAAAACgnxG6Q9G61Qm/+eab5ze/+U1mzJiRq6++Ovvtt1+S5LnnnsuwYcN6tUDWTn+fcHQWv+/KZPQ2HSdLlU74luQ3H01++c7kleeWPcCSIXznD5S5z5e/5TX/P71aMwAAAAAAwBpvqc53oTz0tW6F8CeccEI+85nPZMKECdlll12y2267JSl3xW+//fa9WiBrpzmNG6V1w12SgZ2/tNFpOvrmpvL+xq9N3nj80gMsuSZ8qSbZ9vBkytuTa08oT7Ny90WrpXYAAAAAAIA1V6fQ/aBzky32L64UqFLdmo7+0EMPze67755nnnkmU6dObT+/995756CDDuq14qgynaejb15U3t1w52Trg5JHbkge/2vS2ha+ty4Rwtc1JAefW97/1Qc6xgEAAAAAAKgmlU74IaOTqYcXWwtUqW6F8EkyZsyYjBkzJk8++WSSZMMNN8wuu+zSa4Wxdtv4hT+m5pbHk+2OSIasVz45/6XydsHsjhD+hX8lc19I9vtS0jgqeeJvyeIFybANlj9452ntAQAAAAAAAPpQt0L4lpaWfOlLX8oZZ5yRV155JUkydOjQfPrTn84Xv/jF1NR0a5Z7qshWz/wmtTNmJZvtVQ7hZ81Irmmbdv7pOzsu/NmBHft1DcnRtycjxi89YGtrsnhhWwDfaVp7AAAAAACAqtKWj7zybPKPK5L1tkzWnVhsSVBluhXCf/GLX8wPf/jDfPWrX83rXve6JMlf/vKXnHTSSVmwYEG+/OUv92qRrI3autQrU9DPe7Gj+315Fi8sX7esEH7BrORrE8r7Wx9c3nbuhJ81o/za5WkctexxAQAAAAAA+pPGdZNdP5Lc8v3konclb/hisudni64Kqkq3Qvif/OQnOe+88/LWt761/dy2226bDTbYIB/72MeE8LyqUuVbWDW1q/bC+y5N5j6fbLhTMmhkx/nOXe+VMSsh/KwZydk7lkP85VlRlz0AAAAAAEB/MXyDZP+vlXOR239UdDVQlbo1b/xLL72UrbbaaqnzW221VV566aUeF8Xar9S6RCf8yvrrN5MLDk2ee3AFg1eC/bZgft6LKw7gk44uewAAAAAAgLWJ5Xuhz3UrhJ86dWrOPvvspc6fffbZ2XbbbXtcFGu/9k740ip2wld0nmo+6foBstkbk10/mozdrntjAwAAAAAA9FeLFyVznknmvdB2QggPfa1b09GffvrpefOb35w//OEP2W233ZIkN998c2bMmJErr7yyVwtkLVUJ0Wu69T2QpLV52eMlybZvT6Ye3r1xAQAAAAAA+rNn70t+8IaOY53w0Oe6lYDuueee+ec//5mDDjoos2bNyqxZs3LwwQfn/vvvz89+9rPerpG1UCndnI6+omWJEL7zt7hKpe6NCQAAAAAA0O8J3aFo3eqET5Jx48bly1/+cpdzd999d374wx/m3HPP7XFhrN3+tumn85pddkrdkNHdG2B509GXapIFs5NFc5MBQ5KBw3pWKAAAAAAAQH+yVAYvlIe+1s02ZOiZF4dOSusmeyb1g8onGkclNfUrP8CSIXzdgGSrtyRbvTm59sTkzEnJ377bewUDAAAAAAD0C51C97eclWwxvbBKoFoJ4VkzjBifvOV/2w7a3paD10s+fEP50bhu+Vxl+volQ/hBI5N3XJAc/vNO1/hmFwAAAAAAUKVGbJzsdFSywQ5FVwJVp9vT0UO3tbZmwvPXpeaO55Id3t3RDT9k/bYL2gL2+sZk3Hbl/U8/lLQ2Jw9cnsx/KVlvy+WPX1kTvhLUN45K6hqSxQuX/5q6hvJ1AAAAAAAA/ZkmRSjcKoXwBx988AqfnzVrVk9qoWq0ZuqTP0meTLLNwR0h/IiNkl3+XzL7yeSh/0tq65OmBcmcp8rB+jqbJtse9urDVzrhK9OtjBifHH17Mu/FZO7zyQWHls+/5zflDvqkHMCPGN+LvyMAAAAAAEAR2vKRWY8nD/+x3BE/arNiS4Iqs0oh/PDhw1/1+fe+9709Kogq0Hkq+UrXepKsPyl50+nJIzeUQ/ia+mTmvckP9yl/QHzynmTWjHKYvqRXZiYXHl7unt/+PUv/nBHjy49ZMzr9vMnJ0NG9+7sBAAAAAAAUafC6yQ7vTe74afKzg5I9Pp3sfULRVUFVWaUQ/kc/+tHqqoNq0tLcsV9Tu4znm8rb2rqkpq2rfdbjyS/emfzrmo7nl6VpXrJobnl/WdOtdA7mW5uXfh4AAAAAAKA/W2fT5K3fLjcu3vJ909NDAawJT9/r0glf07G/eGEy76Vk0DrJ/qeXp4qv6fQWfej/Vm785kVL/5z2n90peG8RwgMAAAAAAGurymzEQnjoa0J4+l7nILzUqRP+8ZvK06Ksv3Xysb+Wz828b9XHX39SeZqVDXZY+rkhnaafX1ZIDwAAAAAA0J81L04WvZI0zS26EqhaQnj6XudpTzp3wi/rG1nLmq7+1Wz2xmTcdst+bsDg8hQsrS3lTnsAAAAAAIC1yZN/T340vePYdPTQ54Tw9L3lrQlfCeRfeTZ57KakcVTXTvnessN7e39MAAAAAACANcKSobsQHvpazatfAr1sQGP+tumnsvjQn3Zd873U1gk/78Xkx29Krvli9zrhFy9K5s9KFs1b+rn5/0nuvij5x++6VToAAAAAAMAaTec7FE4IT9+rHZBnh2+f1i3f1BG8J+mYjr5NTV15yvhd/t+qjX/Hj5KvbZxcd8rSz82akVz24eSidycLX17l0gEAAAAAANZsnUL4aV9Jtpi+/EuB1UIIz5qjtIwQvnGdZNqXV3Gcytt6Gd/0au00Ff5/Hl+1cQEAAAAAAPqLdbdMdvuvZOPXFl0JVB0hPH1v0dyMf/EvKd33q67nS0u8HWvry9uauuRzM5KP3pTU1K947LqGpK6xvN/asvTzLZ3OLet5AAAAAACA/sx09FC4ule/BHrZ/P9khyfOTetTA5Ltj+g4P2R0sv17knt/lSyeXw7cW5qTV54tb0dvkxxzZ3nN+H9enVz/lfLr3v7TZMTG5f3GUckdPy3vL+tDpnPw3rkrHgAAAAAAYK3Qlo/MfjJ54pZk6Jhk5MbFlgRVRic8faq5pTV3PfFSkqQlNWlu6RSUj9osedvZyV7/XT6urU/mz0rOnJSctU25i33E+GTcduUPjIqx2yW1A5Ifvzn56ds6prVfVqd75+C9RSc8AAAAAACwlhm8XrLNoUnT3OT8/ZJbzy26Iqg6Qnj6zFX3PZPdv/bHfPqSu5Mk8xcnu3/tj7nqvme6XtiyuLytqU1qOr1FL/948tKjydN3JrNnlM9Nemv521sti5NFrySL5q54TfiWTiG86egBAAAAAIC1zfqTkkN/mLzuk+Vj09NDnzMdPX3iqvueyUd/fkdak0wolcPvlpQyc/aCfPTnd+R7794h0yevXw7Sx26f7H1CMnpKUqrtGOSunyctTck9FyVD2jrh6xranmz7ACmVkqxkJ7zp6AEAAAAAgLVVZebgZTUtAquVEJ7VrrmlNSf/7oH2W3xtKiF8TVpTjsxP/t0D2XfYk6k9f59k+EbJp+4tX7xobtfBatresovnl7ctzUnTgo7AvVRT/obXNocm43ZYupj1turY1wkPAAAAAACsbVpayo2IldmBdcJDnxPCs9rd+uhLeWb2gvbjUlsc39LWsd6a5JnZC/LAM6VMaT9TubhTJ3zSMdV8U9t491+abLhzstFr2kfP5LeWH8syZP3kbd9NFsxORmzck18LAAAAAABgzfPo9cnPDup0QggPfU0Iz2r33MsLuhxXOuGbU9Pl/EvzFpV3Zs8or/s+dGzSOKrrYDVtoXzzwo5zC1/u+BZX+9QqK7D9u1a6dgAAAAAAgH5F5zsUrubVL4GeWX/owC7Hz7SOytGLPp7jmz7Q5fzIwZ2uO3ev5O/nLb8TfucPJZvvW95fOCdd1oRvaUmam5LmxUsX8/LM5B+/Sx67qfu/EAAAAAAAQH8hlIc+J4Rntdtlk3UydvjAVHrU52RwrmjZLVe37JykvCb82OEDs/UGw7u+sKY+qalJNtmz41wllB80Mtlo1/L+wjnJgMHJRruV14H/67eSU9dNLj966WKeuiO56N3Jj9+UzHupV39PAAAAAACA4nUK3d9wfLLFfsWVAlVKCM9qV1tTyokHTE6SLDlZfOX4xAMmp7ZmibdjbdtqCW/53/K2YVjHdPStLeXjpDwd/fqTkvdflbz9Jx3d8sv6Zldrc8f+k3/v1u8DAAAAAACwxqrEI2O2TfY8Ltl8n0LLgWpkTXj6xPRtxuZ7794hJ//ugcyf/Xx2q3kgr2RQ/j10l5x4wORM32ZsMvOFri+qqS9vR2ycHPtgktZk5r1Jw9Bk/n+Sey8pP7/w5a6va18XfhkhfEunEL61pTd+NQAAAAAAAIB2OuHpM9O3GZu//Pcbs8fI/+R7A76Zbw/7Wf7y328sB/BJMnBEss0hHS+obQvhm+YmdQ3JkNHJFtOSNx6fLJiTzHq8/PyCOV1/UHsn/DJC9s7nOgfyAAAAAAAAa4W2JsW5LyTP3JPMfqrYcqAKCeHpU7U1pYwYVJ5Svq62LrU1nSaoHzE+OfT8ZNJby8c1bRM1/O82yembJP95rOPa5oUd+5vskcz4e/L1icn509M+yf0yp6NvWfY+AAAAAADA2mDwusmWb0pefjo5Z4/kL2cWXRFUHSE8fa6hbVn3lqVWiG/Tsri8rXTCL2zrdP/Tl5O5LybP/zOZ/WT53AHfTPY+oRzKz30umffiijvhu0xHrxMeAAAAAABYy4zbPjniF8menysfL6tpEVitrAlPnxvQlpG3LPkdkNbWcgA/6YBk/cnJmG27Pn/fr5ORE5Ibz+g4V9vQ8dqkHMCvaE1409EDAAAAAADVYEV5CbBaCeHpcw015Zt9S2mJEP6Ffybf2aW8NvznHl/2i5d8TW190jS/U7heKgf1W765/E2vJW24c8e+b34BAAAAAABrrRUs3wusVkJ4+lx9ZTr61iVXQ1iJb2SVarse//oD5e3hF7Q9X0q2mFZ+LMu6mycH/yCZ9XgyeutVKRsAAAAAAGDN98+rk1++K2lpajshhIe+JoSnzw2odMIvOR19ZVqUBbPL674PG5c0DOl6Tc3/Z+/O4+Mqy/6Pf8/MZGnSNGkS2qRtoKWUJQQoLVYKKIgUIlLFDUQBQYSHStVHXPGH1oKKy4MKsqgobhXFBZECVsqubIWWAqVAWQotNGlp0uzNMsvvj3tOZskkOZPMzJnJfN6v17zmzJn7nLmTTM6ZOdd9XXdcEN7W2x7eR3xgP4HDz0iitwAAAAAAAAAAADkkGIgKwANwg4OIJZBaraUH6CsDF+mRmefHPhEdQL/+HdLr/xm6sR2orztauuBeDWbP93XYDUZ+8bbt0iv3Sc2bxtJ1AAAAAAAAAACALBeX+U45eiDjCMIj43on1eivgRO0ecq7Rm7oKTD30xvMvbcwUo6+6gCp7h1SRZ15HApJNYdL+xwobfiDdEW1KbUS76V/Sas+LP3lXKm7JTU/EAAAAAAAAAAAQLaIDrofd6k0b4l7fQHyFOXokXFFPjP2o88fjH3Cisti94bfnkuuMIHz6gMj2fKhQHhnU8z9PgdJF4cz5//7U1NmpadF2rExdp9t281966vS5tuld1ww3h8HAAAAAAAAAAAg+8xaJJ20wu1eAHmJIDwyriLYqhM8GzWts0PSYZEn4udztzPh910sfW6D5PFJbW9Ii5dL25+QHrlWCvSbNn2d5r5tu3T/lWZ522PSL48fviOh4PDPAQAAAAAAAAAA5KRwJnx88iOAjKEcPTJudvcz+m3hD9XYdGPsEwWl0oHvizz2hMeIeAulKTOl8lnSnHdLp3xX2v2ytPabUm94Lvidm03W+7bHpKDfWUcIwgMAAAAAAAAAgInGLke/t01qeVXq2uVqd4B8RBAeGReuRq9AKG4E1uR9pE/8WSoPz/Nul6O/6T3Sd6dLr95vHrdtl3rbzHJXs7l/+Acm6/22C513JBgYU/8BAAAAAAAAAACyVuk+0v4nSLtfkn62QLp3pds9AvIOQXhkXIFlRmANCcLbAgPm3i5Hv3uLuX/qZqmvS9q1OTUdCRGEBwAAAAAAAAAAE8x+i6Vz/ym9154PPuRqd4B8xJzwyLhCTzgIP9wYkKM+bTLdS/cxj/295v6lu6Vnb5XuujQ1HaEcPQAAAAAAAAAAmKjsOeFDBOGBTCMIj4zzhYPw/lBcEL6jSfrpYZLHK12+M/HGVgqLN1COHgAAAAAAAAAATFjDVCQGkHYE4ZFxBeFjfiDRwKvgwMhl4j3e1HRi/ielukWp2RcAAAAAAAAAAEC2eOFO6fbPSn3t4RVkwgOZxpzwyLiC4TLhB8uiBKX2NxNnqlspCsIvukiafVxq9gUAAAAAAAAAAJAtAv1RAXgAbiAIj4zrmb5AKwY+pbt8J8U+EV1q/ieHSt27h26cinL03gJpoHf8+wEAAAAAAAAAAMg6cZnvzAkPZBxBeGScv/Ig/S5wih623hH3TNzcJN4Ccz9llrkvLBtbOfrJ06WLHjK3I86SAgPSIz+VuluS3xcAAAAAAAAAAEA2iw66v/Niae6J7vUFyFME4ZFxhT7ztuvzx5Wbt+KC8B6fuX/3l839nHdHMuHj245k//dIM+abW0mVWbflX9Lj1yfVbwAAAAAAAAAAgJwx593S+34gHXGm2z0B8o7P7Q4g/5T27dQi6wUN+Ktin4gvNW8H4es/KM1cKBWVSXv3SIcsld7aIC04VyooldZeLk07VDr9BtN+68PS2m9G9jPnXZHl6NFfoWDqfigAAAAAAAAAAAAAEJnwcEHl63frL0VX6oLA32Kf8BZItUfEPpakkkqp9nCpco40c4H0ri9LHW9J638nTTs43NYXyXavmhu738LJkeVQVPZ9MC4THwAAAAAAAAAAINfZCYkDe6WOJpPgCCCjCMIj43zhSvIDobiS8kVl0iejAvN2JvzfLpBWTpXW3WQeBwbMvbdAKq2W5hxv5ne/YbG0+n81ZG75Lf+OLEcH3smEBwAAAAAAAAAAE01JpTRrkfTmk9KPD5bu+rLbPQLyDkF4ZJzPMsHvQMhSKLo8vBQJsHt8kXnf31xnAuYvrDbPdzWHd1QkzThS+tQd0omXS7s2S21vDC1r/8wtkeXowDuZ8AAAAAAAAAAAYKI54L3SZ9ZKjd8PrwiN2BxA6jEnPDLOG46tB0Ie9fmDKi7wRp4smCS94zOxG7RtM/dbH5JeuU+69ezwjgqjGoVPIJYnErxPJEQmPAAAAAAAAAAAyAfheEl8QiSAtCMTHhnntczBPihL/YGoQHhfl3TtfOnZv0onfyfxxtFZ7vac8VLUCcSSJk01ZVYSOfg0yQoH/UNkwgMAAAAAAAAAgAlqMGmRIDyQaWTCI+O8MoH3oDzqGwhKxVFP9rab++Gy1D3RQfgiqeVV6ab3RLazLKlukSmzcvtnpY1/lIrLI9vMWyJ94lbplXulfY9O3Q8FAAAAAAAAAACQDZ6/XVrzdamzye2eAHmLIDwyzgoH4QPyxGbCR5eR37k5NtPd1ro1suwtkDzeSABeis2Uf+fFJgjvmxS7j3lLzA0AAAAAAAAAAGCiGeiJDcBTjh7IOILwyLjQnON19YPb9Exwto4biCoJHx1A//VJiTe++8uR5XdeHDcvvDQ4v4lkAvRSbNn5Pa+boP2UmVJp9Vi6DwAAAAAAAAAAkEMIwgOZRhAeGReqO1q/Ubu6gnFzwkcH0J0on2VK0tvKaqWSKumNx6RbzpD6Osz6YFQQ/r4rpE1/l475vHTcF6WSyjH/HAAAAAAAAAAAAFnHznz3FUuHfUyacaS7/QHyEEF4uMIXjrf3+4cpR+9UdMn6z2+UCoql1x6KBOAl6cM3RZbtueYfvVbq2iV9+BfJvyYAAAAAAAAAAEDWCgfh57xb+uB17nYFyFOe0ZsAKdbxlg7zbNV0tarPP45M+KZnJV9UJnygL7ybqLd19YHSvKjS9tFZ8dFl6gEAAAAAAAAAAAAgBQjCI+M8636uP+hyne/7d1wmfJJvx5fujp0T3t8/dD+Fk2O3CUW9XpAgPAAAAAAAAAAAmGDscvSBAWlvm9Tf7Wp3gHxEEB6ZFzSB8IAs9fmjAuFen3TWrc734/WZEvb7LjaPf32SmfM9uqz9jg3SM3+OPI4OwkcvAwAAAAAAAAAATASTpkrTG6TX/yv9YD/ptovc7hGQdwjCI/PCwe+gPLGZ8JIUHHC+HzsL/tNrpPf9UNrzutTy6tCM+tuXRe2fcvQAAAAAAAAAAGACO+Q0adkj0qk/dLsnQN7yud0B5KFw8DsoT9yc8JKmzJTmNUovrxl9P56ot69dWsWyNGRu+VDQPG9ZcZnwocT7bdsu9bQM/7olVVJF3ej9AwAAAAAAAAAAcE04XjJcPARA2hCER+bZmfAha2gQ/tZzpEC/5C2SAn0j76eoPHqn5s7ySIWlQ9sGA6Z8fcOHpaaNUvfbieeEb9suXbdQ8o/w2r4iafl6AvEAAAAAAAAAACB7DU7fSxAeyDSC8Mg4Kxz8DiQqR9+5wwTpL3xgaFl5yZSc/+unzHJptbn/1RLpzXX23qWaBunT/5Zeult65BqzOhSQ5JPmf0KaOkfa+Eep5vCh++9pGTkAL5nne1oIwgMAAAAAAAAAgOyz6e/S/d8xiYcAXEEQHpkXNSf8kEx4u1x86T6Jg9wFJZFlX3hO+L2tkXV24H7fo6XpDZEgfHTW+36LzQ0AAAAAAAAAAGCi6W2XWl+LPKYcPZBxCVKNgfQKzjtFfys8XU8FDxyaCW/763mJ13u8keWD3m/uvUWRdZaVuG3Qb+7btkstr0p9XUn3GwAAAAAAAAAAIOsNCboThAcyjUx4ZFzooFP1j0kerevw6Bh/gnnZpdgAejQ7071wsrTPgWbZzoiXTKb8rhekG46WPAVRLxp+nb9/Rtr+uPTB66X6D0pFZeP7YQAAAAAAAAAAALLRpKnS3PdKtQmm5wWQVgTh4QpfOGF92Ex4zzBvTTsIH11e3hsOwp/xB6n+A1LTM+E2A9K8k6XDz4yUsbfL3f/zEumZP0vn3Tn2HwIAAAAAAAAAACDrhDPfZx8nffTX7nYFyFOUo0fmdexQXegtTVHX0DnhbcNlwhdOloqmSIE+U1peigThA/3m3op6Wy88Xzrso5IvXLI+FBW8Dw6ThQ8AAAAAAAAAAJCrBsvRWyM2A5A+BOGRcd57v6nvtH9NH/I+MnwmvG9S4vWlVVLtESaj/c114R3GBeGjTypFk2O3jw68h4Z5bQAAAAAAAAAAgJwXkgIDUsDvdkeAvEMQHpkXDn4HZakvfk74479m7ivqht/eDrbbwfeqA8z97cukR6+LzYTf+h/p+dul/u7wa0cH4RNkwpdURbLmh+MrMu0AAAAAAAAAAACyTdEUqXJ/6dUHpSurpT+d6XaPgLzDnPDIvMEgvGdoJnwwPBpruDnhpaggfDhYfuoPpdJ9pAe+I217TCqfFWn78A/N/cf/JNUcFlWCRYnL0VfUScvXS6//xwT1JalmvvSBayJtSqpGHiQAAAAAAAAAAADgliPONLeNt5hYR3RsBEBGEIRH5oWD3wF51B+IC8Lvc4hU/0ETME+kp1Xa8bRZ9kRlvPe2mfsX7zS3eH8+y2SwT4kKng9Xjr6iLnYQQEGxNGP+sD8OAAAAAAAAAABA9mFOeMAtlKNH5kWXox+IC4Q/dp3U/Jw0+7jE20aXmo8OlPf3jP66/j7pgBOl6gPD/UiQCW9rfS2yHGSuFAAAAAAAAAAAkGMsOwhPJjyQaWTCI/Oiy9HHZ8Lv2Sr1tkuBgcTberxRy+G374M/kNbf7Oy1539SWnie9J+rpYr9Yp9r2y71tJjlN58y91P3lw4/U9qxkTL0AAAAAAAAAAAg+z33N+m/P43EPChHD2QcQXhknh2EDyXIhLfPA/EnBDtA7t8bWde6VSqcLLW8nNzrTz9U+mhc0L5tu3TdQpMtH23Pa9K/vmKWfUVmvngC8QAAAAAAAAAAIFt1vy3tfM7tXgB5jSA8Mi540Pu17u1Cvbx7lto7evXYqy1aNKdSXo8l9bWbRv/9ifShG83ycAHyO5Yn/+I9LVJHk8lq9xXGro/ffzx/n2lHEB4AAAAAAAAAAGSrIZnvZMIDmUYQHhm3pqhRX9tTo+6QJbX26KybHldtebFWLK1Xo90oeu53JwFyp/5xsdS9S7pgrVQ7PzYQDwAAAAAAAAAAMFGUzZBmzJdqDnO7J0DeIQiPjFqzqUmf+/MzQ8ZcNbf3atmqDdpaHF4RPfd7KoVL4evXS6Spc6QvbEzP6wAAAAAAAAAAALgiHIWZfaz0kV+52xUgTxGER8YEgiGtXL1Z1dqjAgXUoinqk8lED0myoht70vTWDEXNQR8KpOc1AAAAAAAAAAAA3DJYjt4asRmA9PGM3gRIjXVbW9XU3qsbC6/Ro8Wf1wmeZ2Kej8mOL5iU/AtYo7ydfUWx86AEg8O3BQAAAAAAAAAAyEnhWIhFEB5wC5nwyJhdnb2SJK9M8DuYYATWA4Ej9B7vM9K0Q5J/gVBQOv5r0kGnRtY1b5IGuqV9DpYq95d+8e7Y9gAAAAAAAAAAABNJYak0uUZ67SHpimpTlv7cf7rdKyCvkAmPjJlWZiZ8t8JB+ECCt59P4RLxnoKxvchAjzRjfuT2xM+lf33VlJ6vqIstQU85egAAAAAAAAAAMNEc9Wnpyy9JjVdJwQEp4He7R0DeIRMeGbNoTqVqy4vl3WtnwscG4S1JrxYepONm18iaMmOMrxKXXe8Jv0YwHHCPLkHv75d2bDTLXTslb6EU6B9+174iqaRqjP0CAAAAAAAAAADIoMFy9KERmwFIPYLwyBivx9KKpfXy/MUc7O1y9DO0W5VWpyTpg+WvydrTKfW0RALk/n4TAPf3Db9zy2sy2+PnN7G85t4Ows//hNS0Udr+hNS7R/rl8aN33FcsffrfJgBfUefwpwUAAAAAAAAAAMgCIYLwQKZlRRD++uuv149+9CM1NzfriCOO0M9+9jMtWrRo2PZ//etf9c1vflOvv/665s2bpx/84Ac69VQzD/jAwIAuv/xy3X333XrttddUXl6uk046Sd///vc1Y8ZYs6uRKo0Nteq4p0jqMOXoZ2i37i/6koqtAdOgNdzwr5+KbOQrks69U/IVJt5p07PS6s+ZZSuuxL3HDsKHS62c+kOp/S3ptgulNx4ZvcPv+rJUNdeUtgcAAAAAAAAAAMh2z/5FevJX0sBet3sC5C3X54S/9dZbdemll2rFihXasGGDjjjiCJ1yyinatWtXwvaPPvqozjrrLF1wwQV6+umndfrpp+v000/Xpk2bJEk9PT3asGGDvvnNb2rDhg267bbb9NJLL+kDH/hAJn8sjKCsyLztppYUaarVGQnAD8ffZwLw0XO9R9/KZ0Y1ji9HHx5nEj3/e/lM6ZTvOevsIUtN9jwAAAAAAAAAAEAu6HjLVARu3RpeQSY8kGmuB+F//OMf68ILL9T555+v+vp6/fznP1dJSYluvvnmhO2vueYaNTY26itf+YoOOeQQXXnllVqwYIGuu+46SVJ5ebnWrl2rM844QwcddJCOPvpoXXfddVq/fr22bduWyR8Nwwge8kFtrXqPApNrUrNDb1SG/Gjl6Htapb1tlF4BAAAAAAAAAAATkx0DsasHExMBMs7VcvT9/f1av369LrvsssF1Ho9HJ510kh577LGE2zz22GO69NJLY9adcsopuv3224d9nfb2dlmWpYqKioTP9/X1qa8vMt94R0eHJFPafmBglCxtJG3g6P/Vs51r1b5zH0ktzrbx+6Vh/haWvINv5EAwpGBUO69lySPJP9Cn0MCAfD/cX5ZCGjjrbypw8Lr+N56Q2psUmnvi0FL3AJCj7HMb5zgAcA/HYgBwF8dhAHAfx2IgfTzBoLySQqVVCtUeodA+h8TETgCJ4/BYOf19uRqE3717twKBgKZPnx6zfvr06XrxxRcTbtPc3JywfXNzc8L2vb29+trXvqazzjpLU6ZMSdjmqquu0sqVK4esv+eee1RSUuLkR8EY9LQ5C8BL0iOPPKL2krcSPlfe87pOkNTrK9e/uw+X7r578Llaa76KZ+2nt7e0q+uNu/TBcMmVgj991NHr+v79VUnS6iN+paBnmDnpASBHrV271u0uAEDe41gMAO7iOAwA7uNYDKTevOYXVS9pm2Zp49TPSH7FxE6AaByHk9PT0+OonatB+HQbGBjQGWecoVAopBtvvHHYdpdddllMdn1HR4fq6up08sknDxu4x9gNdOzUgw8+qAP3PUjP73nD0TbHHnusVHtE4id3vSC9JBUVFujU958W9+SpkqRDJCnolzaOrc+NJ58kFU4e28YAkGUGBga0du1aLVmyRAUFTuqCAABSjWMxALiL4zAAuI9jMZA+nkdekpqkuro6zTj1VLe7gyzFcXhs7Irqo3E1CF9dXS2v16udO3fGrN+5c6dqahLPF15TU+OovR2Af+ONN3T//fePGEwvKipSUVHRkPUFBQW86dLA97tTdGrHm9px8K/0vMNtCnw+abi/RXGpJMkK9I/89/IHk+to9Ot7rOFfHwByFOc5AHAfx2IAcBfHYQBwH8diIA08lrnzeuXh/wuj4DicHKe/K1cnuS4sLNTChQt13333Da4LBoO67777tHjx4oTbLF68OKa9ZMokRLe3A/Avv/yy7r33XlVVVaXnB8DYhAKSpEmFKRoD4is2930d0uY7Yp97e4v0+iNSR5MUSjII74nqXzAwvj4CAAAAAAAAAABkgrdIKppi4iNX7Sv9/oNu9wjIO64G4SXp0ksv1U033aTf/e53euGFF7Rs2TJ1d3fr/PPPlySde+65uuyyywbbf+ELX9CaNWt09dVX68UXX9S3v/1tPfXUU1q+fLkkE4D/6Ec/qqeeekp//OMfFQgE1NzcrObmZvX397vyMyJOOBg+qahQe0JlGrBGmWvdVySVjDCQonymtPA8s/z2S7HP3X+l9NtTpRfvTBxI/8z90kUPRR5X7CfNPMosL7lSssL/IkH/yH0EAAAAAAAAAADIBsd+Xrpsu3Tyd6S+dqmvy+0eAXnH9TnhzzzzTL399tv61re+pebmZs2fP19r1qzR9OnTJUnbtm2TxxMZK3DMMcfolltu0eWXX65vfOMbmjdvnm6//XY1NDRIkt566y3dcYfJhp4/f37Maz3wwAM64YQTMvJzIU7bdqmnxSz7+yRJNQPbNdXy65rqb+nLSw6UJk9PvG1JlVRRN/L+7Sx3K269x2vug4HBDPwYNQ0myG8rLJW84TISU2aYbPhAP0F4AAAAAAAAAACQWyw7aBJytRtAPnI9CC9Jy5cvH8xkj/fggw8OWfexj31MH/vYxxK2nz17tkIhDiZZpW27dN3CweC7fcg/ZuPXdFeRpLcl/aVIWr5+9GD7cOy/uRVX3MEKB+FDARNQP+wMU7Z+yxqz3s6Of//V0l1fkqrmmv5KUsEkgvAAAAAAAAAAACBHhSMyxM2AjMuKIDwmuJ6WwQD8sPx9enDjiyqqK9GiOZXyeuJT2kcQDEpP/8Es93bEPmfP6x4MmCz3j9wkDfRKt5xhAvb2KLCCUnPf3y35e8PrJklLrjAnp0kVzvsDAAAAAAAAAADglmf+LD3zp6GJiwAyhiA8ssaP/v2Sng/1q7a8WCuW1quxodbZhlHTFQwJ9nuiMuFtBcXSp+6IbVdYYu77e6SBvWbZN0ladKHzHwAAAAAAAAAAAMBtrVul1x6Uyu3qw2TCA5nGEBhkneb2Xi1btUFrNjUlv3FwIPaxPcor6DcZ7f4+KTAwdLu/nGvud22Wzv2ndPF/pen1yb8+AAAAAAAAAACAq+wpfClHD7iFIDyyjn0qWLl6swLBJE8M8QH2wXL0Qaljh/SdadL3Zgy/fV+nVDlHqjnMlK9/a4P0+iNmPQAAAAAAAAAAQK4orpBmLZKmH+p2T4C8Qzl6ZKWQpKb2Xq3b2qrFc6tG36BoitTXIS08L3b9wadJFftK+x0TKUlveaTv72fmif/809Lkfcy6UFC65InY7W89R+p4U7rwAWnmglT8aAAAAAAAAAAAAOljZ77XLZLef7W7fQHyFEF4ZLVdnb3OGtpB+HjzTjI3ycyBIkmW17QNBU2ZeikShC8oke67wswHf8znInPKBwND9w0AAAAAAAAAAJB17CrDlqu9APIZQXhktWllxc4aegvMfaB/+DahoLm3PCYQHwqGb6FIMD7ol/4THhW2+JKocvb+5DsPAAAAAAAAAACQaaG4OeEBZBxzwiP9SqokX9GITXpDBdoTKht8bEmqLS/WojmVzl5jTzjL/bWHYtd3NEk7npbatkeC8B6PCcRLpkR9dJb7bRdGln3FBOEBAAAAAAAAAEBusTwmvrHtcenqg6Xff9DtHgF5h0x4pF9FnbR8vdTTIkka8Pv1yCOPyFN7iH7w7y2SpD2hMu1QtaRIcZQVS+vl9YwwSqtt++A+tf97pNcekPq7pB0bzbqSKunJX0mP/FQ6+hJpwblmveU1ZeYDCpekH4js880nzb23yATrCcIDAAAAAAAAAIBccuL/M7dX7pNWfdjESwBkFEF4ZEZFnblJ0sCA2kve0qnHvkfBZ4r1QlNnTNOa8mKtWFqvxoba4ffXtl26bqHk74td/+i15iaZ7PsjP2WWQwFzkyLl6CWTBR8KSlXzpJaXI/spCJfBZ054AAAAAAAAAACQiyhHD7iGcvRw1eyqkiHr7r30+JED8JLJgI8PwMfz90mBcJugXyqcLB18mjTvZJPlLpkAfGGp9LmnpElTI9v6Jpl7e655MuEBAAAAAAAAAEBOCQfh7TniAWQMmfBwzb+f36kHX9o9ZP0/nn5LZx+9X2peJDrjfep+0sf/aB7/4cNSf7fkLYy0LSiV9u4JL4cz4Y+6wATuq+elpj8AAAAAAAAAAADp9Myfpc13SIV2IiRBeCDTCMLDFc+0WPrNY88kPOxffvsmVU8uHD0b3gl7TvlQXDn5c24b2rYwKivfzoQ/8pPj7wMAAAAAAAAAAECm7HpBeukuafphbvcEyFuUo0fGBYIh3fa6Z8RxVytXb1YgmIKRWYOZ8MHh23TskG5YLO3eYh6/53LpIzeN/7UBAAAAAAAAAAAyLhxfsShHD7iFIDwy7qk39qit3xqxTVN7r9ZtbR3/iw0G4f3StieklVOl694R22Zgr7Rrc+Rx1VypJjw6rPU1acfTUnfL+PsCAAAAAAAAAACQKUVl0vQGqfoAt3sC5B3K0SPjdnX2OWzXO/4Xm36o9O6vmKB6KCCFgmZ++JtOlNrflD75t9h54b/8slRcEXl891elV9ZKH7yB0vQAAAAAAAAAACD72ZnvM46UTvmuu30B8hRBeGTctLIih+2Kx/9iNYdJC84xy6//19x7vFL321LXTikwIFnhghCl00xg/uk/SNPqpYPeJ3nC/yJB//j7AgAAAAAAAAAAkHZx5egBZBzl6JFxR+03VRWFIY106K8sLdDC/aYO36CkSvKNEsz3FZl2tmDA3FveSOA9FJCCA2bZWyBte1y67wrpub+adZ6ocvYAAAAAAAAAAADZbnAOeILwgFvIhEfGeT2WPjw7qN9s8crS4HisGK3dAzr+Rw9oxdJ6NTbUDm1QUSctXy/1jDBXe0mVVDxFenuLVFhiStFLJgA/OFd8QIMnoY63pH9fZpYLJpn7wUz4QJI/JQAAAAAAAAAAgIuaNkrXLpCmzpbOuc3t3gB5hUx4uOKIqpB+9vEjVFM+fMn55vZeLVu1QWs2NSVuUFEnzZg//K2iTnr+dun6d0h3fdlkvUuSxxPJcA8FE2e5++KD8GTCAwAAAAAAAACAHLDkCunyt6V3f1VqfVVqe8PtHgF5h0x4uOaUQ6fr5IYZOvqq+9Ta3T/k+ZBMjvrK1Zu1pL5GXs8YyqbYQfRQQAramfBx5ei9BdKUmSYT3lZQHLu9HYRv2z569n1FXfL9BAAAAAAAAAAASAWPN3yzYySJahIDSCeC8HDV+jf2JAzA20KSmtp7tW5rqxbPrRq23bCi53QvqZLmnihVzpXeeDT8AkGpbpF06Wbp0euke/6fWZ8oE75tu3TdQsnfN/zr+YpMmXwC8QAAAAAAAAAAAEBeIggPV+3q7E1puyGi536ftVA65x/m8V8+ZcrSF5RG2hZGLduZ8Ac1SlNmSHXvNBnwIwXgJfN8TwtBeAAAAAAAAAAA4I5nbpVeWWuSEyWZlEcAmUQQHq6aVjb8nPBjaTeEJyoIH+2M3w1tGx2EtzPhD1lqbpK0Y+PY+gAAAAAAAAAAAJApO56WnvurtN9x5jHl6IGMIwgPVy2aU6na8mI1t/cmHIdlSaopL9aiOZVjewE7CB8KDN/mtYek+66QOnZE1tV/YGyvBwAAAAAAAAAA4KpwxMWyYh8DyBiP2x1AfvN6LK1YWi/JBNyj2Y9XLK2X1xP/rEODc7oHpM3/lL43S7rl47Ftut+W3npK6gwH4acdKpXPCj/XIr29RercObbXBwAAAAAAAAAAcEPBJGnqHKmcKXSBTCMID9c1NtTqxrMXqKY8tuR8TXmxbjx7gRobase+88r9paMvkRo+Ivn7pf5OaaBH+tunpWuOkF65Vwr6Tdu6o6XPbZDO/Wdk+0d+Kl3/DunRa8feBwAAAAAAAAAAgEyxy8/XHC59YaN03p2udgfIR5SjR1ZobKjVkvoa/c8fntK9L+zShxfM1I8+esTYM+Bt0w6RGr9nlp/5s7n3eKWOJmnP61J/t9S1K9J+09+lvi5p9nHS5GlST4tZHz+nPAAAAAAAAAAAQFaKL0cPINMIwiNreD2WDphWpntf2KWpJYXjD8DHCwXNveUxN8kE4O9baZa3P25ukvToNbHb7m1LbV8AAAAAAAAAAADSwc6EHzIRMIBMoRw9skpZsRkX0tXrT80O/X1S+5tSx45INrvllTzht35vR6Qc/UgGuqSSKslXNHI7X5FpBwAAAAAAAAAA4Ka3X5RuPE5a9VG3ewLkHTLhkVUmF4WD8H0pCsK/+aT02/dL1QdKiy8x6zzeSCa8nR0/mmBAqqiTlq83Jer/+DGpO1zG/jP3m31KJgBfUZeavgMAAAAAAAAAACRryRXSif9P2rlZ+u2pUm+b2z0C8g5BeGQVOwjfmaogvBUOjgcDceXow+sdB+HD7SrqzC0UNUd89QFScXlq+gsAAAAAAAAAADAehSWSSqSCSebxYHl6AJlCOXpklVI7E753IDU79ITHmYQCUuk0qe5okxXvSTIIHx10l6TPPhFZ7u8efz8BAAAAAAAAAABSyWJOeMAtZMIjqwzOCZ+qTHh77vdgQDrkNHOTpDs+L1XOjYwCG03dO2MfT97HZL/3tkv9PanpKwAAAAAAAAAAwHg9c6v0xn+lKTPDK8iEBzKNIDyyil2OvrsvMEpLh6LL0Uf7wLXmfsdGZ/uZt2TousLJ4SB815i7BwAAAAAAAAAAkFLbHpU2/F46OJyYSDl6IOMIwiOrTA5nwnemrBy9XXY+RUF9Sdr9irTuF1LHW+Yx5egBAAAAAAAAAEC2sIPug+XoCcIDmcac8MgqZUWRcvShVIzMsueEDwakdTdJ/3eg9K+vR54vqYpkyw/HWxj7ePdL0rpfSiXV0v8+J806avz9BAAAAAAAAAAASCVvoTS5RiqtdrsnQN4hEx5Zxc6ED4akvQMBlRSO8y06aaq08DypqMyUje/aKfV1SGtXSK/cKx37BWn+J6Sn/yDN/6S06KLY7V++R3rgu9J9V0jn3GbWde8297OOkir2HV//AAAAAAAAAAAAUiqc5LjPIdJHb3a3K0CeIgiPrDKpwCuPZYLwXb3+8Qfhy2qkpdeY5Yf/z9xbHlNKfucmE1D3FZv1U2ZKM+bHbt/yirkP+iPresJB+BJGjgEAAAAAAAAAgCwzWI7e3W4A+Yxy9MgqlmWpNFySvrPPP0rrJIWC4RfxmJtk5ooPhuef9xYM3caeUz4YNad8d4u5f+O/0j2XS1v/k9p+AgAAAAAAAAAAjJk93S9ReMAtBOGRdex54btTEYQPBqWeVpPxbgfhPd7IPPDBQCTL3ZMg636wXVRfut8293telx79mfTmk+PvJwAAAAAAAAAAQCrteV369cnSH89wuydA3qEcPbLO5GKf1G7K0Y9bV7P040NMgP24S806yxubCR8YIQhvr+vvlnZsNMt7tpr7glJpoFtqfU1q2y5V1I2/vwAAAAAAAAAAAONx8nek9/w/E7u4+WSm1wVcQBAeWWdyKsvRR2e8R2fCe+wgfNAE5L2F5hbPDsLv3CT98vjY5wa6zf3Tf5Ce+4u0fD2BeAAAAAAAAAAA4K5JU81tb5vbPQHyFkF4ZJ3JxWZu9uhM+EAwpHVbW7Wrs1fTyoq1aE6lvB4Hc5nYc7orJE2eJtUcJk2ZIbWGs9mDQelDN5rbaNuPxN8n9bQQhAcAAAAAAAAAANnBsuMoo8Q4AKQcQXhknclFJvDdFc6EX7OpSStXb1ZTe+9gm9ryYq1YWq/GhtqRdzYYRJd01Keld/6PWb7321JZrVRYOvL25bOkQ5ZKL6xO9scAAAAAAAAAAADIvGf/Kr21Xqrc3zwOEYQHMo0gPLKOXY6+q8+vNZuatGzVhiFjtJrbe7Vs1QbdePaCkQPxVlQQPhiQvCbLXid929xGs89B0ru+nFwQvm27yYofTkkVGfMAAAAAAAAAACA9Xr1PeuZP0vyz3e4JkLcIwiPrTC4ygfKO3gGtXL05YZGUkCRL0srVm7Wkvmb40vTRmfDBYeaYv+9Kaefz0jGfk2YfO56umwD8dQtNefrh+IqYPx4AAAAAAAAAAKTXYOiETHgg0zxudwCIN7nYjA15bVd3TAn6eCFJTe29Wre1dfidRWfCP3iVdM186bEbYttsf0La8i+pq3no9gG/1NvhvPM9LSMH4KXI/PEAAAAAAAAAAACpZpef9/ikoilSUZm7/QHyEJnwyDpl4XL0e3r6HbXf1Tl8oF7eAumwM0xGfE+rtGer1NsmrbtJevZWqeGjkQx5T4J/h13PS79fmuRPAAAAAABIOab+AgAAABwKB+GrDpAu2+5uV4A8RRAeWac0HIQPOqyOMq2sePgnPV7pIzeZ5Tu/aO4tr9T+pvTmk9KsRVJgINy2IMH2/IsAAAAAgOuY+gsAAABwLkT5ecBtlKNH1ikpNCXk2/f2qbK0cNh2lqTa8mItmlPpbMfBQHhDj7lJUiggBe0gfIKAe3Q5+5H4ikzWBQAAAAAg9Zj6CwAAAEiCHYS3RmwFIH0IwiOrrNnUpJWrn5ckvfp2j1q7E5ekt08bK5bWy+sZ5STi75P6uyNBeI/HZMhLUigYWe9NEIS3A/OFZdJFD0nv/7F5PHWO9Im/RtqQbQEAAAAAAAAAALJJZ5P0+9OlP33C7Z4AeYda28gaazY1admqDXJSJKWipEBXffgwNTbUjt74+/tK/l5p9rvMY8sbyXAPBqLK0ScKwkcF62fMl7p2mcfF5dKso8L78EtlNQ56DQAAAAAAAAAAkGYnf1c6/utSX7v02HUm0RBARpEJj6wQCIa0cvVmRwF4SSryebSk3mHg2w6428H2IeXo/WZ5pDnh7Tb+XnPvK5YKJ0fa9Xc77DkAAAAAAAAAAEAalU2Xqg+QJk0Nr2COeCDTyIRHVli3tVVN7b2O2zd39Gnd1lYtnutgHnY7kF5SJVUdIJVUmhIskslw/9x6kxFvJRiTEh+En/se6ZJ1Zr2v0ATugwMmCD+pwryGr2jkuQqZPx4AAAAAAAAAAACYsAjCIyvs6nQegE96G084uH7SCmmfg8zyY9ebkvK+YsmyEs8HL0mFJdLhZ5ps+lBIKiqL7MN+vrc9kglfUWfmh+9pkX55fKTdRQ9FlkuqmD8eAAAAAAAAAACkx3N/k3ZtlvY52DwOkQkPZBpBeGSFaWXF6dtmcP53f2Td4kvMbTTF5dKHfzn884WTTRB+IKocfUXd0CD7jPnO+goAAAAAAAAAADAeL94pPf8P6Wg7DkIQHsg05oRHVlg0p1K15cWyHLafVlakRXMqnTUeLCkfSPz87Z+V/vZpqaNp9H298Zj0wPekF+8yjwtLzX2iOeHLas196TRn/QQAAAAAJGZP/TUSpv4CAAAAYlnhqAuZ8EDGkQmPrOD1WFqxtF7LVm2QpdHHZJ13zGx5PQ5D9p5wJvzdX5H6OqUTvibVfzDy/Aurpb4O6T3/b+i2oZAU6DdZ9AUl0rbHpId+IB15tnTw+6WP3mzaVe4/dNslV0q3fUaaXu+snwAAAACAxKKn/uraJd3yMbP+nNulSVPNMlN/AQAAAIYddLcsk6joIRwIZBr/dcgajQ21uvHsBVq5erOa2hPP917gtTQQCOnA6WXOdzxvibR3j7TrRWn3S6Z8/At3Sut+Kc0+TgoMmHaJTkJBv/SdcCb7196Q/H1mubdT2rEx0m73y5Fl+8KPHfwfLgMfAAAAAOCcPfXXnjci6/Y5WJpS616fAADOtG03A6mGw0AqAEixcBC+Yj/pWyMcfwGkDUF4ZJXGhlotqa/Rdfe/rJ/cGwlsH1RTpm8vPVS/eOgVPbhlt1q6+5zvdOk15v6PHzNBeMsjdeyQtj4kTaqQguEgvLdg6Lb2fPKSCaZ37zLLL/zT3BLxFZkMDTv4Hj0XPQAAAABgfELBxMsAgOzUtl26bmEkuSUR+3oagXgASA3KzwOuY054ZB2vx9LJh9bErDtqv6laPLdK1WXFkqTdXf3J79gOilteyeOJrLOD5Iky4T0eE7SXTLu+ztFfx98ndTabUvSSdMBJyfcVAAAAAJCYHXi3vFIZWfAAkPV6WkYOwEvm+ZEy5QEASYoqRw/AFWTCIyvNriqNWxNSIBhS1eRCSVJrd5JB+FAoEmy3PJEMd7sUvTT8nCgeX2Re+NG+MNgG9kaWj/3f5PoKAAAAABiet1CauVAqKIkMsAYAAAAwVM8e6U+fMNPnnvkHt3sD5BWC8MhKD23ZJY8lBcODtf74xHbd/+LbOmZulSSppSuJcvQ/P05qfi7y2OONzNceiNpPonL0UmwQPjpoP5KBbnPvK5a8/JsBAAAAQMpU1EkX3u92LwAAAIDsdfJ3pHd/RZIlPfAdyTNM/ANA2jBkHFlnzaYmLVu1YTAAb2tu79XfN7wlSXqhuVOPvdqiQHwjJ6yoEvP+qIz64U5CdoZ80G+C8U7YmfD+Xqn9reT7CAAAAAAY3t1flf6xzEwFBgAAACDW1NlS7RFSaXV4BXPEA5lGEB5ZJRAMaeXqzQlPB9HrXmru1Fk3Pa7jfnC/1mxqGnmndul53yQzX2BBSWRdwSTpGzukr2+TfEWJt7ez5oMBadGFzn6Q6HL0f/iQs20AAAAAAM489xfpmVuk3na3ewIAAABkMeaEB9xCnWxklXVbW9XU3uu4fXN7r5at2qAbz16gxobaxI3sIPpHb5YOPtUsP/tXk/nu8UqF8fPPxznwfaa8fGGJCeI70d8dWbbnogcAAAAAjN/OzdLePWY5FHS3LwAAAEA2ev4fUssrUs0R5nGITHgg0wjCI6vs6nQegJdMdrwlaeXqzVpSXyOvJ25UV9t2yR+e973lFWnHRrNcPU/6zL1SSdXoL/KhGyPL3buddcwf9XMQhAcAAACA1In5vhVwrx8AAABAtnr2L9JLd0vv+X/hFQThgUwjCI+sMq2sOOltQpKa2nu1bmurFs+NCqq3bZeuWxgJwq/95tCNvUXSgY1mXpTTfjz6i239j5kjfqTAuq9IqtjXZM13NpGZAQAAAACpFP0dK0QQHgCyXkmVuV5mX6NLxFfkLFkGAODMYOa7FfcYQKYQhEdWWTSnUrXlxWpu7016XNaQLPqelpE/3EtSoE964Z+Sr0RacK75sF9RN7SdfYJ6/u8mAN/4fWnfxeY1OnZIk6ZK5bNMG3sflXOkX7ybTHgAAAAASKWYIDyDngEg61XUScvXm+toN58SqWhy0UORNsNdkwMAjFE4psGU8IBrCMIjq3g9llYsrdeyVRtkKbkCKWPJoh/k75F+ebwZdbt8feyH/uveIe3eIp2/JhLUn3aINGP+yPv0hP+9CMIDAAAAQOpEl6APEoQHgJxQUWduljeybrRrawCA8SudJl3+ttu9APKSx+0OAPEaG2p149kLVFPuLKhuSaotL9aiOZXjf3F/nxmVO+QVZILpdhDeWzTyfoLByJcKgvAAAAAAkDpkwgNA7rJIyQSAjLCr+1oeyVdobgAyikx4ZKXGhlotqa/Ruq2t2tXZq9d39+in926RFJsdb39sX7G0Xl5Pmj7ER2e020F4XzgI37FD2vxPqbDUlLO3/fsy6Ymfm+Ujz05PvwAAAAAgH9mB95IqsigBINfMfpe05V9u9wIA8oAdhGfwE+AWgvDIWl6PpcVzqwYfH1QzWStXb1ZTe2Tu95ryYq1YWq/Ghtr0dcRjZ7QHzBzyUiQI37ZNWvN1qXL/2CB8X5e5f++3pHd9KX19AwAAAIB8UzBJ2ucQqXKO5C1wuzcAgGQsuUKat0Sq2NftngBAfujvlv7+GbP8oV9KHgpkA5lCEB45w86Ov/HBV/R/92zRnOpS3Xvp8enLgLclzIQPl8q3g/H2elt/OAhfWJbevgEAAABAvpl1lHTJ4273AgAwFvscaG4AgPRacqVJECyukP71VbPuQ79wtUtAvmHIC3KK12PpxIOnS5La9w6kPwAvRTIrYuaED8+f4ptk7gf2xm5jB+H9vVLnzvT3EQAAAADyyX+ulu76kvT2Frd7AgBIRk+r1P5WpIokACA9ph0s7Xu0NHma2z0B8hZBeOScmVNN4Lu1u189/f7Ejdq2S107I8Hy8YjOhD/vTulTqyMnrmEz4bvN/dpvSlcfKIVCAgAAAACkyKbbpCd/JbVvd7snAIBk3P5Z6Sf10u0Xu90TAMg/xCmAjKIcPXJO+aQClRX71Nnr11t79mre9LiS723bpesWDg2Mj9XMhVJBiVS6j1S3KPa5gnAmvH+vOYFZ4cz8+NG8oaBkeVPTHwAAAADIZ1sflnZuMstcSASA3PL6f8z9C6vd7QcATHQvrDaxkpkLo1by2RnIJILwyEkzyov1Um+X/rbhTZ1w4DQtmlMZKU3f0zL2ALyvSCqpMiennhazruEjked3bDT3JVVSRV0kEz4UNJnydun6/rggfDAgeQjCAwAAAMC49XVGlkMB9/oBAAAAZKsnfy299oD0vh+63RMgbxGER85Zs6lJr7f0SJJ+8dBr+sVDr6m2vFgrltarsaHW+Y4+fJO5f/EuqXxf6bCPmOC6NHomva9IWr7eZMfbBvZGgvD7Hi1Nmirt2GAeB/2SUlAaHwAAAADyXTAq8B4KutcPAAAAINtZUbNSU0UKyCjmhEdOWbOpSctWbVCfP/ZCS3N7r5at2qA1m5qc76z6QHMC2ny71PS0NGO+yW53kknv7zPtfEXS2X+XzrsrUppekj70c+nTayKPg8PMXQ8AAAAASE504D1IJjwA5BbL7Q4AQJ4g4A64jUx45IxAMKSVqzcnPHWEZD7Cr1y9WUvOrZSjwu9NG6XVXzDLnjH+K1iWdMBJZjm6hL0UezFox0apco4J8gMAAAAAxi66BD3l6AEAAICh7Kz34nLpa69LsiKVfAFkBEF45Ix1W1vV1N477PMhSU3tvXr+rQ4d7mSHvR2R5bEG4W1t20cuYf/7pZES9gTiAQAAAGDsglGZ8JSjBwAAABKw0xktM3UugIyjHD1yxq7O4QPw0Vp7+p3tcPK0yPJ4RoA99zdp3U3OS9gDAAAAAMbODrxXzpXmnexuXwAAyTngRLd7AAD5wc6Et5gGBHALmfDIGdPKih21qywpdLbD0mmjt3HiviuktjdSsy8AAAAAwMgKS6SK/aS6RVJhqdu9AQAk4+TvSjOPkkr3cbsnAJAfAv3SHZ83y6f+yFTsBZARBOGRMxbNqVRtebGa23sTzgtvSaopL9ah8+aYE8lImeneQikQ9XzbNjNvuyTt3pJcx3zOBgcAAAAAAFLgkKXmBgDIPRV10rGfd7sXADDxLblC2rtHqpwj3b7MrGu8ShJBeCBTCMIjZ3g9llYsrdeyVRtkSTGBeLugyoql9fJOrTVzrw9X+r1rp3Tr2dKfPh5Zt3OT9Mvjx9axAoLwAAAAAJBRT6+S3n5JOvR0aeZCt3sDAHCqt0MKBaSCUsnnsJolACB5MxeY+/6eyLpQovRGAOlCEB45pbGhVjeevUArV29WU3tkjvia8mKtWFqvxoZas6KiztwS2bHRlGAZD1+RVFIVXiYIDwAAAAAZtfkO6eV/S9UHEoQHgFzyx49K25+Qjv5sOCMTAABgYiIIj5zT2FCrJfU1uvqel3TDg6/qkJoy3fn5d8nrsUbfOBkfvslc0Nm5WXriBrN8TLhcVklVJMhPEB4AAAAAMuf5f5gAvCSFgu72BQCQnF0vmPvHbyAIDwDp9NIaqatZqntn1Eoy4YFMIgiPnOT1WDr1sFrd8OCrerNtr+58doemlRVr0ZzK1AXjqw+UZsw3tyM/MXy7gkmpeT0AAAAAwOi6d0eWQwH3+gEAAABkq0eukbY9Kn3ol5F1lKMHMoogPHLWq293SZI6e/36wp83SpJq48vSp9LO56U3n5SqDpBmHxdZ7ysy9x6fFPQPv310CXsAAAAAwNgEowLvZMIDQI5JcSVLAMDIrOjjLkF4IJMIwiMnrdnUpP8NB96jNbf3atmqDbrx7AWpD8S/+oB0z/+TDjsjNgh/7Bek+Z+UiisiAXnbLWeaki+n3yjNftfw89QDAAAAAJyJDrwHCcIDAAAAQ9kBdwY/AW4hCI+cEwiGtHL15oRjtkIyp5SVqzdrSX1N6krT/+woqeVls+wrjH1u5sLhtyssMfeV+xOABwAAAIBUCJEJDwAAAIzILj3vK5QufcEsF5a51x8gD3nc7gCQrHVbW9XU3jvs8yFJTe29Wre1NXUvGuiLLPuKnW/nCY9zCTJPIQAAAACkREw5er5rAQAAAEOFg/CWR5oyw9w8hASBTOI/DjlnV+fwAXhH7UqqhpaNjxc/f3v0sjdu2+bnpKf/KG17wjxe+y3ph3Ol//5UOuAkqf50qaTSUZ8BAAAAAKOws99nLpQO/7i7fQEAJGfeErd7AAB5hnL0gFsoR4+cM63MWSb6sO0q6qTl66WelpjVgVBIz7/VodaefpVVTtf8KbPktZ+MDsLHB/BfWC099APpqAukfd8p7d0j9eyWggNS41XOfigAAAAAgDMFk6TSfaS6d0qlVaO3BwBkj/f/n1R9oFSQRKVJAEDy7HL0oaC05jLz+L3flApL3e0XkEcIwiPnLJpTqdryYjW39yacF96SVFNerEVzRsg+r6iLmaN9zaYmrVy9OarM/XbVlr+tFUvr1dhQO3IQ3i5P7w+XrB/Ya+4LSpL5sQAAAAAAThy9zNwAALln0lTphK+53QsAmPhO+ra0t1WasUD6yzlm3fFfJQgPZBDl6JFzvB5LK5bWS0pcSCUkacXSenk9zsqsrNnUpGWrNgyZZ765vVfLVm3Qmk1NIwfhCyaZe384+N7fE14fDsIHg+YGAAAAAEiNLf+WHvy+9PojbvcEAJAMf5/k749kaAIA0mP2sdIhS6WyWrd7AuQtgvDISY0Ntbrx7AUqLykY8lxFgnXDCQRDWrl6c8KMenvdytWbFZwUzqqfNFU6+LTYhnZQfjATPioIf3OjdMVU6cU7HfcJAAAAADCKl/4lPXiV9AZBeADIKTccLX1nH+mJX7jdEwDIPwyAAjKKIDxyWnvPQMJ1gxnso1i3tXVIBny0kKSm9l694p8u7XuMdMznpOp5sY184Ux4uwz9YDn6SZIV/hcLBUbtCwAAAADAgfW/ldb/xiwH+a4FADmlp8Xcr6EkPQCk1cv3Ss/+ReqMjpMQhAcyiTnhkZNGy2C3ZDLYl9TXjFiWflfn8AH4aC9UvVcHvvfcxE+OlAnv8ZplLgwBAAAAQGrseT2yzIBnAMhdwaDkIUcMANLige9KOzZIZ90aWUcmPJBRBOGRk5xmsK/b2qrFc6uGbTetrHjE15mh3ZpqdWpO/2Tpibukvk6p5jBp8jTToKRq6Jzw+xwkWZZUMlWyCMIDAAAAQEpFf78KBd3rBwBgfEIBUagVANIlHHC3rKHrAGQEQXjkJKcZ7KO1WzSnUrXlxWpu7x1y+pmh3bq/6Esqtgaku4fZga9IOu9f0kdvlkr3Mes+8qvI857wv1jQ76i/AAAAAIBRRAfeGfAMALmLgVQAkD4xWe+WCMADmUcQHjlptAx2p+28HksrltZr2aoNQ56rtDpNAH4k/j5Tcr7hI4mfJwgPAAAAAKkVHbQhgAMAuYuBVACQAZa0/ElzP6nS7c4AeYV6P8hJdgb7cLO9W5Jqy4u1aM7oJ5XGhlrdePYCVU8ujFlfFfd4TOw54ZmnEAAAAABSgyA8AEwMXC8DgDSKKkdfPU+qPkDykpcLZBJBeOQkO4Nd0rCB+BVL6+X1DPdsLBOIXzj4+NPHztbN573DWWcGeqTnb5ee/4cUDEr/d5B0zRFST6s0Y7407xRpyixn+wIAAAAAjMzOnJz7XumdF7vbFwBAcg5sjCyTCQ8A6TNYjt5ZjARA6jHsBTnLzmBfuXqzmtojc7+XFnp10bv315L6mqT21++PZFDUlBfLO1opetvePdJfPyUVTjYB965ms95bKL37K0n1AQAAAAAwCm+hVFAq7btYqqhzuzcAgGScfqNUViNZHnM8BwCk3/3fNdVHjv2CVFzudm+AvEEQHjmtsaFWS+prdN39r+j6B15WfyCk7v6AfnLvy/rNI6/rU8fsp0VzqrS7q0/Tykx5+uGy43v6I6Nvu/uSGInrLTL3A3vNzVYwaSw/EgAAAABgJI3fMzcAQO7xeKUlV7jdCwCY+E78ptTbJk0/VPrTmVLQL73jMwThgQwiCI+ct3Zzs3567xZ7hpNBbXsHdM19r0h6ZXBdbXmxViytV2ND7ZD99PT7B5e7+/xDnh+WPWo3FJD6OsLriiLzwQMAAAAAUmv7k9K2R81FxQNOcrs3AAAAQHY58OSoB+HExFB8FAVAOjEnPHJaIBjSytWbhwTgh9Pc3qtlqzZozaamIc/tjc6E708iE95XFLWTVnNvZ8Hf/RXpO9Ol//zY+f4AAAAAACN77UFp7bekzXe43RMAQDKu2lf6drn08r1SwOFUkACAFCEID2QSQXjktHVbW2Pmgx+NfYpZuXqzAsHYE05sOXq/VFIVG2BPxFdk5rGy7d1j7gtKzH3QL/l7+VIBAAAAAKnyyLXSA98xy6EkBlADANwX6Df3f/yI1Nnsbl8AYCJ77SHphTulrrclK/EUvQDSi3L0yGm7Op0H4G0hSU3tvVq3tVWL51YNrt87ELl409PvlyrqpOXrpZ6W4XdWUmXaeYukQJ/UEw7CF4aD8J7wv1gwifL2AAAAAIDh7dwUWaakJgDkllAw8TIAILXWfF3atVk653ZRjh5wB0F45LRpZcVj3jY+gB87J3w4IF9RZ26JtG03AfqeFslTYILwra9JlQdIk6eb563wvPAE4QEAAAAgNYKBxMsAgOwXXcGEaiYAkH6WFZUJTxAeyCSC8Mhpi+ZUqra8OKmS9Lb4AH5MOfr+UYLmbdul6xZK/r7Y9Q9+z9y3vmKeP/zj5jFfKgAAAAAgNWKyKPmuBQA5JfoYHiQTHgDSJibrnXL0gBuYEx45zeuxtGJpfdLbeSxpT3d/zLq98XPCj6SnZWgAPp6/LzIXPNkZAAAAAJAaMVmUBHAAIGeEQgykAoCMsYPwlnTBPdL/PCxNrnG1R0C+cT0If/3112v27NkqLi7WO9/5Tq1bt27E9n/961918MEHq7i4WIcddpjuvvvumOdvu+02nXzyyaqqqpJlWdq4cWMae49s0NhQq5+fvUAVJQWOtwmGpEtu2aA1m5oG18Vkwvel6EuAh3L0AAAAAJBSMVmUBHAAIGfED5xiIBUApI+dCW9ZUu3hUu0Rkq/Q3T4BecbVIPytt96qSy+9VCtWrNCGDRt0xBFH6JRTTtGuXbsStn/00Ud11lln6YILLtDTTz+t008/Xaeffro2bdo02Ka7u1vHHXecfvCDH2Tqx0AWaGyo1frLl+gL752XVGGVlas3KxA0J6OkytE7VTZDmv0uaeqc1OwPAAAAAPKdXb740A9LJ3zd3b4AAJwLhaS57408ZiAVAGQApegBt7gahP/xj3+sCy+8UOeff77q6+v185//XCUlJbr55psTtr/mmmvU2Nior3zlKzrkkEN05ZVXasGCBbruuusG25xzzjn61re+pZNOOilTPwayhNdj6ej9qxQavakkU4ylqb1Xv31kqwLBkPYORALvPf0BhUJO9zSCg0+VzrtTOvri8e8LAAAAABCx/wnStEPc7gUAwCmvTzrnNuldX5beebFUUul2jwBgAouKbzz6M+nh/5P27nGvO0Ae8rn1wv39/Vq/fr0uu+yywXUej0cnnXSSHnvssYTbPPbYY7r00ktj1p1yyim6/fbbx9WXvr4+9fVF5vfu6OiQJA0MDGhgYGBc+8ZQ9u80Hb/bprbupLe58q4XdNN/XlNxgXdwXSAYUtfevph1Mfx+OSl+P+D3S7yHAGSZdB6HAQDOcCwGxuGjvzP3oRDftzBmHIcBF707qooJ/4N5jWMxkD7Wu78m7W1TqHw/+f70cVn9XRo4aKnkm+x215BFOA6PjdPfl2tB+N27dysQCGj69Okx66dPn64XX3wx4TbNzc0J2zc3N4+rL1dddZVWrlw5ZP0999yjkpKSce0bw1u7dm3K9/lauyVpmMD5CJo7esNLkdIsd9z9b00eJtJe3vO6TnCw30ceeUTtJW8l3R8AyIR0HIcBAMnhWAyMzeTeHaru3Ky9hVXaWX6k291BDuM4DADu41gMpEOBpH2k5qd1ajip8KGHHlJ3UeL4G/Ibx+Hk9PT0OGrnWhA+m1x22WUxGfYdHR2qq6vTySefrClTprjYs4lpYGBAa9eu1ZIlS1RQ4CSf3LlAMKS/Xf2wdnb0OS5LbwydF+Xod52gfSuHGYTR9Iz00uh7fVdVqzwbr1HwoPcreOqPk+oRAKRLOo/DAABnOBYD42M9+2f5Vv9ewbknKXDq/3O7O8hBHIcBF/R2yPezw2T1d2vgkvXS5BrJV+R2r+AijsVAZvg2F0h9vTr++HdLlXPd7g6yCMfhsbErqo/GtSB8dXW1vF6vdu7cGbN+586dqqmpSbhNTU1NUu2dKioqUlHR0A98BQUFvOnSKB2/3wJJ3/7AoVq2aoMsKclAfKz+oDV8/6ZMN18S/H2Jn5ckX5G8BcVST4u8A93y8l4CkGU4zwGA+zgWA2PwwFXSQ9+XJHkUlIf/IYwDx2EggwYsqd9MJVlw/ULp/H9J+x3jcqeQDTgWA2mw7XFpoEeasUCSR5JU4PVJ/K8hAY7DyXH6u/KkuR/DKiws1MKFC3XfffcNrgsGg7rvvvu0ePHihNssXrw4pr1kSiQM1x75qbGhVjeevUA15cVj2t7Oie/p9w/fqKJOWr5euughc/vk32KfP/Z/zfOl1eZxcIR9AQAAAACce+ORyHIo6F4/AADJiT9mcwwHgPS5/bPSHz4kvR1dfn48aYsAkuVqOfpLL71Un/rUp3TUUUdp0aJF+ulPf6ru7m6df/75kqRzzz1XM2fO1FVXXSVJ+sIXvqDjjz9eV199td7//vfrz3/+s5566in98pe/HNxna2urtm3bph07dkiSXnrJ1AyvqakZd8Y8ckdjQ62W1Ndo3dZW7ersVXVpkW57+k39fcPo87OXFfvU0etXV19g5IYVdeYmScGg5CmQggOSxyfVHmGe84Tnpw+Osi8AAAAAgDPRQRu+awFA7og/ZnMMB4A0igq425mHIYLwQCa5GoQ/88wz9fbbb+tb3/qWmpubNX/+fK1Zs0bTp0+XJG3btk0eTyRZ/5hjjtEtt9yiyy+/XN/4xjc0b9483X777WpoaBhsc8cddwwG8SXp4x//uCRpxYoV+va3v52ZHwxZweuxtHhulSRpzaYmRwF4SaotL1ZHb5d6+pLIXvd4pNN+Ik2aKu1/glQ0Obw+/C/GlwoAAAAASI3o71dkUQJA7hiSCc/1MgBIm8GAu6VIFB5AJrkahJek5cuXa/ny5Qmfe/DBB4es+9jHPqaPfexjw+7vvPPO03nnnZei3mEiCARDWrl6s+P206YU66WdXepKJggvSQvOGbpuMAhPOXoAAAAASIkQQXgAyEnxQXeO4QCQRuEgvGWZ6XRDAal8lrtdAvKM60F4IN3WbW1VU3uvo7aFPo/Kis2/RU+/w9G4bdulnpbEz7W/ae4JwgMAAABAalCOHgBy05By9AThASBtojPh697haleAfEUQHhPerk5nAXhJKin0qrTQ/Ft09zsInLdtl65bKPn7RmhkSZNrHPcBAAAAADACO4hz1AXS4We62xcAgHPeQmnfxdK2x8xjytEDQPpZlKIH3EIQHhPetLJix21LCrwqLQoH4Z2Uo+9pGSUAL0kh6eiLHfcBAAAAADACOxP+oFOlfd/pbl8AAM5NqZU+vUZ6+EfSnjekKTPd7hEATGChyOJTv5EG9kpHfFwqqXSvS0CeIQiPCW/RnErVlherub03+rQTo6q0UC3d/ZpU6FVpkVeS1N3HaFwAAAAAyDqfuddkw3sL3e4JAGAs3v0Vt3sAABPfu78q9XVI5XXSLWdKPbul/U8gCA9kkMftDgDp5vVYWrG0XpI0XOGVjy+qkySVFPpUUmjPCc887gAAAACQdXxF5oLic3+RXrzL7d4AAAAA2WfBOdLiS6Sy6ZSkB1xCEB55obGhVjeevUA15YlL07d290uSigs8mlRg/i227OzSY6+2KBAcLn8+Cbd/Vtqxceitbfv49w0AAAAA+WbXC9Lty6T7v+t2TwAATr39kvSjedK1R0q97ZK/3+0eAUCeSUGsA4BjlKNH3mhsqNWS+hqt29qqXZ29en13j3567xaFJP1pnQmGP72tTc/v6JAkbdzeprNuely15cVasbRejQ21Y3/xXc9Lvzx+6HpfkbR8vVRRN/Z9AwAAAEA+ueeb0qbbzHKIacQAIGcE+qXuXeb2/X2lD98kHX6G270CgInprQ3muDu9QYM1gkME4YFMIhMeecXrsbR4bpWKfJ7BAHw0fzCknv7YizjN7b1atmqD1mxqSn2H/H1ST0vq9wsAAAAAE9WLd0odb5rlUNDdvgAAnAvGDZziGA4A6XPrOdLNp0gtL0eVoycID2QSQXjknUAwpJWrNzs+3djtVq7enJrS9AAAAACAsYsO2sQHdAAA2Su+egnHcABIo+hYBpnwgBsoR4+8s25rq5rae5PaJiSpqb1X67a2avHcqsgTJVWmpLy/b+wd2r0l9nFJFeXpAQAAAGA40UF4sigBIHfEB3+YUgQA0mfwmGtFZcIDyCSC8Mg7uzqTC8CPuG1FnZnTPVFJ+d1bpNsuHH2n8W2YJx4AAAAAhheMDsITwAGAnBGf+U4mPACkUTgIb1nSR35lEgmnzna1R0C+IQiPvDOtrDi121bUpTZgbs8TTxAeAAAAAIaKKUdPJjwA5Iz46iUMpAKA9InOhJ99nKtdAfIVc8Ij7yyaU6na8uQC8Zak2vJiLZpTmZ5OAQAAAACcsYM2x10qvf9qd/sCAHCuYJJUe0TkMQOpACD9KEUPuIYgPPKO12Ppm+8/xHF7+xS1Ymm9vB5OWAAAAADgKjuT8rCPSQc1utsXAIBzM+ZL//Ow1Ph9qeEjUtX+bvcIACawUGTxub9J638rde92rTdAPqIcPfLS1NIix21ryou1Ymm9Ghtqk3uRkiozv7u/L8neAQAAAACGtfxJkz1ZXO52TwAAY3H0MknL3O4FAExsx31R6u+SJk+Xbvm41PGmVHO4VFrtds+AvEEQHnlpV2evo3azq0p035dOGFsGfEWdtHy9md991wvS7Rcnvw8AAAAAQKxJU6XeDunFOyWPTzrkNLd7BAAAAGSXo6MGOw2WpA8lbAogPQjCIy9NK3M2J3yfPzi+EvQen3TbRdLul8a+j0xq224GDQynpMoMLgAAAAAAN3U2S3/9lMmGJwgPALlh63+kf14iTW+Qzvi9CQp5vG73CgDyBzF4IKMIwiMvLZpTqdryYjW394543tnZ3qt/bHhTNeWTtGhOZfIB+VAwtwLw1y0cuXy+r8hk9xOIBwAAAOCWu78a+Z4VDLrbFwCAc/3dUtsb5nZllfTeb0nv+pLbvQKAiWnnZinol6oPlDSOREMAY0YQHnnJ67G0Ymm9lq3aIEuxA8CiHwclffEvz0iSascyN7wnwb+Y5ZVCgeG38RWZjPNM62kZff56f59pRxAeAAAAgFs2/F7y7zXLIYLwAJAz4o/ZDKQCgPT53WnmWv5nH4+KwZMKD2QSQXjkrcaGWt149gKtXL1ZTe2ROeLLSwrU1jMwpH1ze6+WrdqgG89e4DwQH11S64Al0owjpQXnUvIdAAAAAMYqelDzSAOcAQDZJf6YzTEcANInFJ96GL8OQLoRhEdea2yo1ZL6Gq3b2qpdnb2qLi3Sl/76jKShQfiQzKlq5erNWlJf46w0fXQQ/qw/Sd4Cs1xRJ+1+WWp+VrI8Uvm+0qyFqfiRAAAAAGBii86kJBMeAHJHMDDyYwBACtkBd0rRA24hCI+85/VYWjzXlH9/7NUWNXf0Dts2JKmpvVePv9qiY+dVj77z6HL0Qb8JuPe0SoWl0gurpftWmueKy6Wvb4u0bduekmz5QDA0OMBgWlnx2Oa1BwAAAIBsEh20IYADALkjfuAUmfAAkD521rtlSaf9WBrYK1XNdbdPQJ4hCA9E2dU5fAA+2iW3bND3P3LY6GXprahM+KBf+t0HpDfXSWeukjqbIs/1dZqTomWZAPx1C0een91XJC1fP2Igfs2mpiGl9sc0rz0AAAAAZItQSDFzWRLAAYDcMWROeI7hAJA+UZnwB5zkak+AfOVxuwNANplWVuyoXdveAS1btUFrNjWN3NDjM6XmJemqWSYAL0ldu6SOHZF2oaDU32WWe1pGDsBL5vkRMuXXbGrSslUbYgLwUmRe+1H7DQAAAADZKDqAs+RK6fQbmdsSAHJFYalUdUDkMQOpACD9LCrjAm4hCA9EWTSnUjVTihy3X7l6swLBES74+AqlLz4nzTsldn3Ts9LuV2LX9XYk0dPhBYIhrVy9WYl6Za8btd8AAAAAkI2ig/ALzpXmf4ILiwCQKw56n/S59dIHr5cOfJ+0z8Fu9wgAJq7oy/8vrZGe/YvU9bZr3QHyEeXogShej6WzFu2rn9z78qht7fnh121tHZxTPqG27dIra2PXbfjt0HYvrZEOPDmp/iaybmvrkAz4aMP2u6TKlLkfrQx+yQg/KwAAAACkk8cnffF5E4wvmuJ2bwAAY3Hk2eYGAEifY5abeeAnVUr3fFxqeUU6/1/S5H3c7hmQNwjCA3FmV5cm1X7UeeR7WobOeZXI3ZdK9xRJZ/whqddPuj/DtauoM/PM22Xuf3m8ud/vWOmU75nlkqoR56EHAAAAgLSyLKl8lhTwS6/ca75rzVsiebxu9wwAAADIHsd/1e0eAHmPIDwQx+m88I7b37Hc+c78fVJve1Kvn3R/RmpXURcJss9cKL21Xjrm89KM+ePqEwAAAACkVKBPuuVjZvkbO8w8wwCA7Pb8P6SHfijtf4LUeJXbvQGAPBKevinEFLVAJhGEB+IsmlOp2vLiEUu6S+a0VVNerEVzKkfeYfzc72lm97+5vTfhvPCO+x3oN/feglR3EQAAAADGZmCvdN+Vke8rkrPKYwAA9/W0Srs2m9u6m6QF50qn/djtXgHAxNTyqrmv2NdUk5KkhBEDAOnicbsDQLbxeiytWFpvjw0b0Yql9fJ6RmmZ4bKIdv8lDfkZ7MeO+j0QHoTgd1beHgAAAADSbmCv9Pj10pM3RdYFA+71BwDgXPSgqeCAuQEA0uMX75Z+tkBqfzOyjkx4IKMIwgMJNDbU6sazF6i2PHFp99ryYt149gI1NtSOvrNkg/DF5ZKvaOQ2viIzP/sw7P7XxPW/Jpl+t7xs7v96/uhtAQAAACATEmW9kwkPALkh/ngd5PgNAGkTE3B3knIIINUoRw8Mo7GhVkvqa7Rua6ua2/dqd1e/vv+vFxQISX+68GjNrnY652CSY10mT5eWr5d6WkwW+s2nmPUHv19691fNcklVZO72Ufp/6LfWqNcf1BkLZ+mqjxw+egZ8PC5oAQAAAMgWBOEBIHfFVy7h+A0AaRQOwlsW5egBlxCEB0bg9VhaPDeScf639dv10s4u/enJbTrhwGlaNKcyPeXoK+rMrWtXZF1JtTRjflK78XosBcIj3vaZUpR8AF7iCxEAAACA7GEHcCxv+LtKiHL0AJArQvFBeI7fAJA2g5nwlnTSSqmvQ6o+yNUuAfmGcvSAQ2s2NemN1h5J0i8eek1n3fS4Fl65Vtfcu0WB4AgjyLyFY3/R4nLpgCVm2d+X9ObBYEgDAdO3vf1JBtPf8RlzX7pP0q8LAAAAAGlhDxK2PJEBzwwcBoDcMKQcPUF4AEifqEz4gxqlw8+Qyqa72yUgzxCEBxxYs6lJy1ZtUO9A7JeFtr0D+sm9L+vwlf/W3c/uSLxxf1dkebSAfPxc774i6cBwOfqBnqT73R+I9HfvQJJfbA47w9wXTEr6dQEAAAAgLeysSY9Xavy+dOr/SUVl7vYJAOBMYak0ZabkCRdnJRMeAABMYJSjB0YRCIa0cvXmEWdL6e4L6LO3PK3/ebNNl51aH/vkubdLN50oTZklfXqNmes92iv3SfdfIdUeKZ35h6FzvReUmPuBvUn3PToI35dsEN4XHjAwhgx8AAAAAEiL6Ez4RRe62xcAQHLe8Rlze+FOad0vpWmHut0jAJi4osvRb31Y6u2Q6t4pTabyLZApBOGBUazb2qqm9l5HbX/x8FYdMWuqTj28NrKyv9vcF5ZG5nqPNjjve3Doc61bpc23m+UxlIrp948xEz4Ukl6+N7yTrpHbAgAAAECmlM2Qlj8VdVERAJBzDjnN3AAA6bPoQinol4omS2suk3Zuks75hzT5RLd7BuQNgvDAKHZ1OgvA2775z006paFGXo9lVvSFg9hFkxNvUDzF3Pd2DH1ux9PSy/dI+x0rffD6pPohjSMIHwxID3zHLM/lpAwAAAAgS/gKpep5Znnb41KgX5p5lFRY4m6/AAAAgGxyynejHliudQPIZ8wJD4xiWllxUu1buvv120e2KhAMZ2b8/QJzv+vFxBsUhYPwfQmC8NFZ9GMwEFWOvjeZIHygP7J8+g1jem0AAAAASKtbzpB+t1TqeMvtngAAnHjqZumm90qPXud2TwAgP1FNCsgoMuGBUSyaU6na8mLHJekl6cq7XtCv/rtVK5bWq3Ggx6yMDmxLUtt2Mz98b4d02BlScYW0Y2Pk+ZKqqCD85KHbDaekarCsfWwmfHC4LYaK7qu30Pl2AAAAAJBOXbukJ34hFZVJltesCyXxXQcA4J72N6W3npLa3pAe/qE053jpzD+43SsAmJg6dpj7ydOjEuEJwgOZRBAeGIXXY2nF0npdvGpDUts1tfdq2aoN2mon0vuiMurbtkvXLZT8fbEbPfnLyLKvSFp0kVl+/jaT3fGRXyfeLpqvSFq+XqqoU19UEL63P5lM+IHIctAveXySRckaAAAAAC7r2iX95/+k0mmSFS7uF0ziuw4AwD328ToUknrbpb5Od/sDABPZTw8z1/YvfVGDUXhi8EBGUY4ecKCxoVY/P3uByic5G7cyQ7t1qLVVh1pbIyun1JpM9x0bpV2bRw6kS+b56Iz3XS+Yx0ls1x9djt4/xnL0360xX4wAAAAAwG2h8PcayyN5vLHrAADZza5c4i0IP+b4DQBpE116ngQ7wBVkwgMONTbUakl9jb7w56d157NNw7abod26v+hLKrYGYp/YvUX65fFm2f6yMZr+vZFlu6x9EmLK0SeVCd8/8mMAAAAAcIMdwPF4I8uUoweA3DAkCE9KJgCkT/gYGxOA57gLZBJBeCAJXo+l6z6xQPtMfl6/efT1hG2mWp1DA/DxAqM8bxuICsIH/eaWhOggfO9AEkH4+Nfx9yb1ugAAAACQFsHwdxzLq8GympSjB4DcYB+vPQWxjwEAqTc40MmS3vVlUz132iGudgnIN5SjB8bg5ENrMvNCh58hffQ3kcdJBsNjg/BJZIeUVktLr4l6XTLhAQAAAGQBO4vSsiRP+JIGmZQAkBsoRw8AmWdZUv0HpKPOl8pnud0bIK8QhAfGYNGcStWWF6f/harmSod+yMx3KCUdDI+eE74/EFQg6PDi1KSp0sLzpNJ9wq9LJjwAAACALGAHbDxe6dj/lZZcIU2Z4WqXAAAOFRRLxRVS4WTzmOlEACCNGKgKuI0gPDAGXo+lFUvrZY3edPwsS/JNMsvjyISXkixJL0m+8EADf19y2wEAAABAOgxmwnukd1wgHfsFaUqtu30CADiz5Arp629IJ39HmnmUtM/BbvcIAPKAJb25Xnr1fql7t9udAfIKc8IDY9TYUKsbz16glas3q6k9TZniT/9Renmt5C2USqYmPUI4Pgi/dyCg0iIH//Y9rVLTRql9u3kcIAgPAAAAIAvUHC5d9FCklDEAIPfst1i68D63ewEAE9uCc819QbH0r69Ib62XzvqzdND73O0XkEcIwgPj0NhQqyX1NVq3tVXN7Xv1yCu79cLTW51t7C2UAqOUl3/yl5Flf49UOk3yFY2cme4rkkqqJMWWo5ekvf0OM+GbNkp/+JBZPvg0qbjc2XYAAAAAkE5Fk6UZ883yrhek/h6p+gC+swAAAADRPvCzoetClKgHMokgPDBOXo+lxXOrtGZTk/6+4S3VO61Rf+YqafJ0s9z0rLT6cyO39/dJvkJp+Xqpp8XMD3/zEvPcrEXSqT8yyyVVUkWdpKGZ8H1+h0H4wIC5n7FA+vgfnW0DAAAAAJn0t09LuzZL59wuzX2P270BAIzmvz8x5ZAXnic1fMTt3gBAHrGDFgThgUwiCA+kQCAY0srVmxWStCdUpt5QgYqtgeE38BVJ0+oHg+VJqagzt87myLqSykg2SJShmfAOy9nbGfqUeAQAAACQTVpfk57/h1RWK1lesy7JabsAAC7Z9aK09WGpuEL69+VS5f7S+Xe53SsAmHhCIam33SwXTZEsp5mDAFKJIDyQAuu2tg7OC79D1Tqx72pNtTqHtCufVKDl75mrYw47KBKAb9su7d7i7IW2r4sE2/fuiawf6EnYPNGc8I4MBuELIyVqOFEDAAAAcNvuV6T7rpBq50e+oxCEB4DcEApflwoFpc4dUmGpu/0BgIkqGJB+sJ9Z/upWDWbCU44eyCiC8EAK7OrsjXm8Q9XaEaoe2rBHevSuPl3Q1qGT6lu0qLJb3uuPGnmO92jRgfeiKVL1QdLul8w8iAnEB+F7HQfhw1n8r/9HuqJSWnqttOAcZ9sCAAAAQLrYARzLQxAeAHKNfby2Ky+GHF6nAgAkKS7YblGOHnADQXggBaaVFSfV/tePvK5fP/K6ji97S79zGoCXpEBUsL98pnTqD6Xff1Dq745t17Zd6mnR1I6tOtR6a3C1b1exNLkqZt74xK/TH1kOBaVAEn0EAAAAgHSxAzgeb2Q5SBAHAHKCfbz2FsY+BgCkDxVuAdcQhAdSYNGcStWWF6u5vTepsWQtXf1SURIbxAfsi6ZIk6dLpVFZ923bpesWSv4+XSDpguj93xu+9xVJy9cPH4iPDsInel0AAAAAcEMwKhN+sKwmQRwAyAmDA6nsTHgyMgEgLWKOr5b0zv+R6j8oTat3rUtAPvK43QFgIvB6LK1YWp90MZekv2r4ozLhu96WSiqlzz8tnXdnZH1Py+hBc3+faTecuqOlU65SaFKlJGnz9rf12KstCgT5cgQAAADARXYAx/KabPjodQCA7DZYjj6cF8YgKgDDCARDeuzVFv1z41tclx6TqN+XZUkNH5EWXyJVzXWvS0AeIhMeSJHGhlp98aR5+sm9L6fxVaLGzTxxo/Sfq6VF/2PK0qdSTYPW7K5Sd9+D+oj+rXuefUM/3fC4asuLtWJpvRobalP7egAAAADgRHQ5+sPPkOYcL1Uf5G6fAADOeLymFL03XLaRcvQAElizqUkrV29WU3skIY3r0gByEZnwQArNri5Nz47rFpv73nZTbl6S9u4x95Ompvzl1mxq0rJVG9TWbw4RhfJLkprbe7Vs1Qat2dSU8tcEAAAAgFENZsJb0oJzpfdcJk072N0+AQCcOeP30jffNmWRpx0q7XOg2z0CkGXs69LRAXiJ69JJiy9Hv3OztO1xqXuE6rgAUo4gPJBC08qK07Pj7Y+Z++f+YuZ7b9seCcI/9H3p58dJ/d0pealAMKRf3PGgjrS2qNpqlyQVaUBSpIjNytWbKQEEAAAAIPP2P0E6/1/SKd9zuycAgLGqmit99lHpU6vd7gmALBIIhrRy9eaEU7hyXTpJlkc67GNSw0clb4F091ekm0+RXn/Y7Z4BeYVy9EAKLZpTqdryYjW39yY/37tT9nzudhBekpqfM0H4wvFn4q/b2qqTeu7WJUV3qD1UoocDh2lrqGbw+ZCkpvZerdvaqsVzq8b9egAADCcQDGnd1lbt6uzVtLJiLZpTKa/HcrtbAAA3lVabm2QGJ/d1SlNq01IhDAAAAJmzbmvrkAz4aFyXToKvUPrIr4auDzGAAcgkgvBACnk9llYsrdeyVRsctd8TKlNvqEDF1kDyLxYdhJdSlgm/q7NXBTJzcv0pcKK+7//EsO0AAEgX5oADAIzqzi9Kr6yVPniDdOQn3e4NAGA0911hSiIf8zlp9rFu9wZAlnF6vZnr0mNg2QkNBOGBTKIcPZBijQ21uvHsBaosLRi17Q5V68S+q/Wpgh/p0ff+XfrwTc5fKD4IP9CTZE8Tm1ZWrILwHPADI4zTSVvpfQBA3mMOOADAsHZulh7/ubTl36bMphSZJx4AkN22r5O2/EvasUH62ULpRgLxACKcXm/murQDoZAUGDC36Ox3MuGBjCIID6RBY0OtHr/sJFWWFo7adoeq9XDnTH3yrj492l7p/EX2tsU+tjPhS6okX9HI2/qKTLsEFs2pVEWhORkPhIYG4S2ZTMRFc5LoKwAADjEHHABgRG+uk9Z8TVr/O8njNetCAXf7BABwJhh1vG55xdwAIMye6nW4Sei4Lp2E/m7pympz81M5AHALQXggTQp9Hn3vQw2ypGE/ONhC4dsvHn7N4d5D0jsukBaeJ02ZZVbZQfiKOmn5eumih3TNpEv0WOAQvVx8mL7cf5GunHmjdNFD5vmKuoR79nosvWPfyZKkU71P6NmiC/Tzgp9IUT/HiqX1zMkLAEiLZOaAAwDkITuAY1lkwgNArrGP155w9cggg6gARNhTvSbCdelkxSUuWPzOADcQhAfSyC5NX1PurETO7q5+h3u2pJO+LS29RpoSnhc3uhx9RZ00Y74mB9q02PuC2or31d+CJ2iLZ640Y/6wAXjbrDKTAR/yFGiKtVel2itJqikv1o1nL2AuXgBA2jAHHABgRIMBHG8kCE8QBwByg125xFsQ+xgAwuzr6eWTYqd65bp0kmLKzkelCVKOHsio4Sd8BpASjQ21WlJfo5+s3aLrHkhRma3dWyLLngKpuEJqeU1q2x4TYJ8abJEk9ZVMkyT1Djj8chMwgwH2mzFN2vGaCi2/lh5Rq5+eeSQjDQEAacUccACAEdlBeMsTSYkiEx4AcoN9vB4MwnP8BjBUY0Ottuzs1I/XvixJuuQ9c3XpkoO4Lp2UuGD7kWdLc94lTT/Une4AeYogPJABXo+lYw+oHjUIvydUpj4VqEgDI+/wtguHrlt7ufTAlTGl5qsCJghf2/+6PuZ9UNv6TnTW4cM+Kk1vUGdbp0p2PK4i9ausuIAPOgCAtLPngGtu7004L7wlMwKeOeAAIE8NlqP3avDiIkEcAMgN9jHcE5XhGgxKHoq1Aoi1s6NvcHnW1BKuS4+HZUmHn+F2L4C8RBAeyJBFcypVWVqg1u7hA+w7VK339F6t5UdX6hOL6qSunVJvu9S50wTZR+Pvk3paIkH4kJkvd+7uB/Sjggf02b55zjp7yFLpkKXa/Z/bNV1Skfzq7PU72xYAgHGw54BbtmqDLMWO3WYOOABATDn6A06SpsyQao9wt08AAGfiM+GlcEl6gvAAYjW1R6agc1zdFRFDytEDcANBeCBDvB5LH5o/U79+5PUR2+1Qtb7xuDRjRkAn3HOOCayPUXVoT8w5tmjv23rs1RYtmlPpKHjRHTCHiEINqKt3lOx8AABSxJ4DbuXqzTFfvGvKi7ViaT1zwAFAPrPnD7Y8JqOHrB4AyB0XPWQC8QPd0tTZpqoJ1UwAJBAbhOc4kby42oKtW6W+Tql8llRCZUEgUwjCAxl0Un3NqEF422/uWa8TxhGAVzCgarVJkjZrf9XrNZX079ZZNz2u2tGCGG9vkQJ96uszH3aKrAEy4QEAGdXYUKsl9TU6+PJ/aSAY0rsPrNZvzltEBjwA5Lv6D0rTDpXKatzuCQAgWR6PJI/kLZe+8IzbvQGQxZrb9w4ukwk/Bp4C6aD3m2XLI931JenV+6QP/UI64uPu9g3IIwThgQyy57mNHsk3nN3d/VLRGF5k9xZJUqinRT4rqGBI2h6YqnqftL+1Q5LU3N6rZas26MazFyQOxP/zs9KbT2rSgZdqfXCedoamqquPIDwAILMCwZAGgmb0dllRAQF4AIDJnJw62yz3tJqMnuJyaVKFi50CAABAquztD2hPT6Qqa6+fIHzSiiZLZ90ydH0oNHQdgLQhCA9kkD3P7cWrNqTvRW67UFKkCr3Hkk7xrZcknef9t/4TOExvq0KWpJ/f0akl9WcODWoE+iVJTYWz9bn+lZKkmWTCAwAyrDNqKpS9jHwHAMS799vSht9JJ14uvfsrbvcGADCaf31d6t4lHf91aZ8D3e4NgCwUCIa0ZlNTzLo+ytGPn2Vf/ycID2QSQXggwxobavXFk+bpJ/e+nPHX9loh/bboR4OPe/sKtHFTvRYefnhsw4AJenQHPIOrOpgTHgCQYdFToeztJwgPAJC0Y6PU/KxUfZAprSlJQS7MAkBO2LJG2rNVesdnpJ9fYOaDP+8uqpkAkCSt2dSklas3D6ki+/LOTpd6NJGEg/BkwgMZ5Rm9CYBUW37iPNVMKXa7Gyq2BtTZunPoE+FM+G5/JEO+q8+vECdpAEAGRQfhe8iEBwBI0kt3S3d8TnruL5LHa9aFOEcAQE4IhQdNeQrMgKqdm6QglRcBmAD8slUbEk7j+sirLUOy4zGK7hbpiirpimozYJVMeMAVBOEBF3g9lr79gXq3uyFJqiwpHLoyHIQf6N2rx4su0dNFF8kb8qubLEQAQAZ19kXNAcc5CAAgScHw+cDympsUCeoAALLbYBDeo8GszCCf84F8FwiGtHL15hHDwytXb1YgSADZuZAZ5BQcCAfgrVG3AJB6BOEBl9hl6VOmbMaYNjt05pShK8Pl6NsCBaqx9miq1aVC+dXFvPAAgAyKKUdPJjwAQIoK4HijytFzjgCAnDA4kMpDNRMAg9ZtbU2YAR+tqb1X67a2ZqhHE0B0RVvLSrweQNoRhAdcNFJZ+j2hMvWGCpzvzDe28vZeK8EouHAm/J6BSJZ8kfrVybzwAIAMIggPABgilCiAQyY8AOQE+3gdXc2EgVRA3tvVOXIAPtl2kIaUnT/0Q9Jxl0rTD3WnO0Ce8rndASCf2WXpL161YchzO1StE/uu1lGeF3Vt4Q2j7+w9l0m3XZiajh15ttT9tnyvtmog5FGBFdRh1lb539ooBcqkkiqpoi41rwUAwDCiB3/tpRx98tq2Sz0twz/P+RxALhoM4Hg0eHGRLEoAyA328drjNbeAGEgFd/GdKStMK3OWXOa0HaKFE/Dmn+VuN4A8RRAecFljQ60uOHa2fv3I60Oe26FqvRqamdbXf/TV3TomupJ923bpiZ9L/j59Vxo8T/++6AfSHT8wD3xF0vL1fAgFAKRVfCZ8KBSSlaiCC4Zq2y5dt1Dy9w3fhvM5gFwUjArCzzpKesdeadYid/sEAHAmJhM+XKCVgVRwC9+ZssaiOZWqLS9Wc3vvsPPC15YXa9Gcyoz2K6dRdh7ICgThgSxwUn1NwiB8UorLzQfDkT44JvC9u1/U8qmHqrGh1qzoaRl9H/4+044PoMg3jJAGMio6Ez4QDGkgEFKhjyC8I5zPAUxU0VmUhyw1NwBAbvjCs+Y4XjhZKquR+rs1mP0BZBrfmbKG12NpxdJ6LVu1QZaGFFKXJK1YWi+vh+OFc+Hfop3I0NEkDfRIpdUmjgAgIwjCA1nAHu3X1D6OeW3+fbn00d9K/V1SKKjQP/5n1K8xvaEC7QmVaeXqzVpSXxP+IMMoOSAhRkgDGRedCS+ZkvSFPo9LvQEAZIUjz5H2O0aqmud2TwAAySqaHFn+3Hr3+gEg6zQ21OrGsxdo5erNQ66RV0wqiCSQwRlvobT/CZGqI3d9SXrpLum0n0pHne9mz4C8QhAeyAL2aL9Ec8M71rJF+nNkbhc7AP/Z4h+pp32X5nh2aEXBHzUQ8uorAxcpKEsdoVJVWJ3a0/6m1m1t1eK5VZJ/IPH+gXzHCGkg44YE4QcCKleBS70BAGSFmgZzk6T+HpNF6SuSiqe42y8AAACMS2NDrZbU1+jIK9aqo3dAn3/vAbr2vlcomDEWJZXSuf9M8AQJeEAmEYQHskRjQ61u+MSRuuSWp1N2KlzW/3ntKZmq3xZ+Q8WWCa4XWAH9tPDGmHa9oQI9vLNemlslhfyJdgUAQMZ19MYODNs7wHyRAIAoj/5MevB70sLzpaU/dbs3AIDRrP6CFPRLJ10hlVa53RsAWcjrseQPBiVJR8+p0rV6Rb1cCxg/uyw9c8UDGUUQHsgipx4+Q+e9vke/efT1wXV7QmXqDRUMBtGTsS00XXN9XaNuW2wNqMbXYx4ECMIDALJDonL0AIA89+ZT0p7XpekNkfKaIc4PAJATNt4iBfql478u/fnzUtcu6fQbpGqmGAFghEKhwQH4U0sLJUm9A0GFQiFZFinxyCFt203F1OGUVFFNNQ8QhAeyzMmH1sQE4XeoWif2Xa2pVufgurnWW7q28AZH+6soKZA6Rm/XsTccqA9Sjh4u4YMJgDidQzLhGSgGAHlv/W+kp1dJ7/2W5AkH4cPZUgCALBcKH689XmnHRqnjTamvc8RNAOQXE3A3y5XhILwk9fmDKi7wutSrHNSxQ7r+aMlbIH311UgmPOXoM6Ntu3TdwpGnNvUVScvXc717giMID2SZRXMqVVterKb23sF1O1StHaHqpPf1Ls9z8nuPd9T2+2te1PKqQ9VYSBA+4wg+88EEQEJDM+EJsuQVzo8AErED7pZXgxcRQ5wfANdwvkYyguHKJZYnMpCKYziQ3TJ8nO/uj1wHqCgpGFzuHQgQhE9GMCD1tUteeyADVQQyqqdl5Ovcknm+p4XPSRMcQXggy3g9llYsrdfFqzaMe18LrC3a4H2P4/YrV2/WkjNLNdrHmZCvSFYJc3elBMFngw8mABKwg/BVpYVq6e5nTvhklFSZ88do55dsPZ9zfgQwHDtYY5eilyhHD4wmXQEUztdIRiikwcFTljdyHA9yDIdLcv07Uya4cJy3p6ErLvCoyOeV12MpEAypd4ABO2MTF3xnTnggowjCA1mosaFWPz97gb5+23Nq6xl7ZnqHStXV56x07/7WW2ptL9Nzew7UfEn9BVP0oa6v6ciKHn1n73fVF/Lpw/3flmSpoLBaF7/pU2PFmLsGG8HnzCA7Iz84+TtLvBdyhD8QHAy671NWpJbufvX0U47esYo6cyGkp0Xau0d64Q5zsXP2sdLUOaZNNr/fOT8i3/BZxTk74O6JGjqcKIuS32n+4W+eWDoDKJyvkYzoY7XlCVc0EQOp4J7o70ySzCCRuIBlvp47bC4c53vCQfjSQhO6mlTgVVefX70Myk+SPegp/J4+8BRpygxpeoN7XQLyEEF4IEs1NtRqSX2Nrr3vZV1738tjmq3FF/LrzW2vS0Wjt7228Ab1hXx6euc1Ch59ida90a3nO+doyx6/VhZZKrL82hmq0m6VSx3Sxas26IZPHKlTD58xhp4BY7R7S+L1I30pStVFJ0ZIx8q2i5xO/s52Ca5A//BtyNTJGtGDyKZNKdaLzZ186U5WRV3kvfzkr6QX75T2OUg69EPu9gtALDJJk5MoEz4+i5LfqZFtn9fSib/58LIhUN6108z/PZyJ9F7E8KKP1R5PZDAV5ejhJvs705Z7pG2PSrPfJR3wXrd7ldfswfeTCs0xorjAo64+qdfP9YCkDGa8h4PwR57tWleAfEYQHshiXo+lLy45UAdNL9Nnb4mUp98TKlNvqEDF1shZ8qcXPKb3hZ50/HpFll9HrfuCPlx4vTZ2lEmSBuRTsyo1Uy2aZb2t3aHywfbL//S0rpOlUw+vTfInA6K0bR8+uB7vtgsTrx/pglqqLjoNGSGdQL5cPMrGi5xO/s4jBd9tZOpkDbsUfXGBR2XF5iOrXZYOCUQHWrp2Sr3tsc8PdJv7XS+YtrzHgeSlK6CZDQGydEjX72twPmGvVH2AdMQnpFkLY9sk8zu126e6n26xf+9dO6Vbz87c4EO3A/4T9f8okxJ9J0vV3y2T70Vkr5hMeG8kE55y9JCk9jel/vbhn0/3eeTV+6UnbjTvU4LwrrIz4UvCQfgin7mnHD2AXEQQHsgBpx5eqxt0pC655WmFJO1QtU7su1pHeV7UtYU3jLhtkeVXf8inQstZCV+f/Nq36xnt0sHaoWpJ0q5QhWZaLTra87wGgrEzxl//p60q6V2sExYtTLQ7YGROgrlOZOqCWkWdVD7LlHYurjCj9/MRFzmRAXt6zIXaAq9HXb1m0NlevnQnlsyx9KlfS0//Xjrzj9Lk6ZH1uRZkwsTmdjAvkWwcgJbN0vn7sssWW5Y090RzG6uundLNJ0+cv2uyn61T9XktVX/vbPzfzyeJBjyn6v0/2mBYvjvkB1+R9OWXTZCzcLJUVCYVlcdWNonGMSFvTOrfLd+N75QCLp6Pu982949cI+14WvrU6vS8jhN5/t63g/CTwuXoiwvMMYLKeMmKK0e/d480sFcqmiIVTXavW0CeIQgP5IhTD5+hnwWl5X9+WpIJxL8amulo24v6v6gpVveoAXubXZr+432Xq9zq1uHWa5Kkrxfcqq/r1iHt++4uUGDeBnmn7uvwp0HOGesXgNG269o5/gB8pvV1SD8Mz6d82k+k/U+QKvd3tUt5Zbj3lNNqCk7s3jLhv9RmuzWbmvSNf2ySZDLiH9qyW5L03JttLvYqizkZGBMtMCDdckbsulwKMmFiy9ZgNwPQkpPO39c7L5YOer8066ix98/W2+6sn7s2J/9Z2I0L6MmeDzL5uqP9vbP1fz/fcVxDKlmWNHla5PFn1g7flmNCXin0d8kaKQAvmffCtsci59ZUn0e7d0WWX/+vqdBgT5mQSbz3B8vRlw6Wo7cz4QnCJ8VbJM1aZN4vknTXl6RNf5cafyAdfbG7fQPyCEF4IIecNn+GntvRpl88vDWp7aZY3eoIlSa1TZHl11+KrlSBNfoHnCIN6NmXt+rwRXkahJ/oI1TH+gXA0RzdBanrZ6Z0vR1ZvvOL0geuIwifKamqnDCa2y5M3ZfadB4fJuixZ82mJi1btcEesx3j7k3NWrOpSY0NTIOSclxkR7bI9WD3cIPCRhqw6HQgWXy7HD3OxxjLPNGzj4ssB/wma87ySN27I+fFVA7Ok0Yvpe0tiK0w4u+Xfn9aXl9AH9ZIAyrH8r9v7y/Vf3M3TNDPdsCIUn1MQHZxclwrrXG+v+iKHak+j3bvjiyHglJPqzR5n8RtU3m8jt8X7/0h5egjQXgq4yVlSu0wg50SXW1BypVUmePUaN8HSqrGtn8+N+YMgvBAjrns1HodNqNCn7v1acfb2JntyXISgLf173xRats//w7u2TBCNd0n3bFeDHc0R/fA2PvllujR0ZLUsztxu1Tig5WRyeyuVHypdXp8OPdOyVc4fJvhsuvcPvakQSAY0srVm0f8Srhy9WYtqa+R12NlrF/IsGSCksgemT5XZWvVkkTlnKWxD1gcad/xgV8p9neSC58fRg1uF0pnror9GaNtfVha+01p9rulN59I/nPCSL+faKOV0o6vMOItGP1zbnxGn+TO3ySd84DHc1L+PxmZGqBpv1Y6/58m6Ge7nJQLx85c1d8trV1hBk41fl/qeGv8/8PJDn5D5jg9rl38xNj2H30eTcXfuyvuWk/3rsRB+FQer9N9HsvR49lw5ej7/GTCj0/4GkqIIHxGVNSZ44D9P7h3j/lOUVIlecJxmrH+D/K5MacQhAdy0GnzZ8jjsXT9n5xnxBc5nBN+rI5a/1XpmW/mz8Hd/iC77bHxjVAd76g4TrqZF//FzOnF22REf1Hq2pl89lW0LP1SlatfBpPidADL794/8t830f+w033HX9yXsvp3u25rq5rae0ds09Teq3VbW7V47hhHCyO7JXMhajyjxlPJ7ePZeF8/Ff134/NIKquW2OzfRddOU6Y82p43xrfvsQ5YHMlIU0tIzioSnflHaVp9at4j0e2cDqQZNbjdP/RnjGaFy8SO9Xd5z+XJb+OE04Gm8QMrkrlon6rpedI5D3g8J+X/k5GCAZqT+ndLTc9IPl/i//3icnM/2ufx8f7Ocq0KSPTx0ls4+neVXBl8zffr9BrYKz15k1k+Zrl056XjPyYkM/gtHdz+HJjNnB7Xdm3W5N4dY3sN++8/2sDE0QQDkb/jpEppb6u59jP90KFtU3m8TmeiQaqOZ+nO5k1gb3w5eh/l6FPCnhs+mUx4jnHjU1FnbtufNFVUy+vMADT7d9rTMrZrdrn2uTHPEYQHctSph9dqyp6DpAfc7kmUfDm4p3KkavSouBf+Kf3nx5HnTr3azHU50smXk27Ey2vNRSD7S1e6Pgh2vx33OMVB+LG8vxJdhLe5eZFouBKzTgYWTISLW107nbUbLQAxnv/hTF5YT4FdnSMH4JNthxwRH7hzcvz78E3SvouTfx+nOmDt9HiWqOKF36/yntell+8xwR/7/BUfBCouT3xBsW27mad6PMdTp1PHRF/UTPQ7SmZgkDTy79jpsdPeZ6o+42Qyozad7N+JvTwS+/PDeN8j9nt8tPLr6RAKX4zd9fzYtg+md6By0py8pzPxXk11dmEqRX++HG/VlPY39d7NX5P3+RQEiDP1nWssVUCcBFCS4fQ9ePrPpWmHmL/ZSINpUsXJOV4auU3XTuffr0fbV7b972SDYFQA7bqj0n8cS/f/JIM2UsL3t3N11HjPxyMNTEw0hUn85+3eDg0GJsvrTBC+e5xVD7t2jn5cSuZzb7zoc+B4Pp8n+j+J7/cZfzC/rzu/KPV3mXWLPy8d9pHhX38cIpnw4SB8uBz93n6C8EnZ87p0c6NUVCYtfzL57TnGpUYoJP3hdPO/c+5q6ZaP8jvNMwThgRx23Lx9kgrCBy2fPKH0Xmh67rE1Omxxgicm0hfQsYxUHenDsT0qbsMfYrdp22aC8PaouPH8DpO5WJNoPqpc8MB3Yh/bQYPiqaNfdPIWDB8wjv+92ZnwdsZHqsvRp3okdPyXqrbtUsdOE/hpekbqbXEW7LElUyZ6tMBQMv3ONW3bpVs/6XYvEnN6gX+kiwX+/uRL6Dswraw4pe2QpJH+t0eazzqZDNn4C149LSYTNdkLb9UHji0AP56LCGMNfA1T8aJA0gmS9FJyu0s64DnS/7zTqWPiy2zbQflk/9dvu9Bs/6m7pX0XDX1+PMfO8Q6wyOSUJ+mWKJt3JON9j/j7pK0PTZzfn9t2b4n8De33dHR22Z43MvO7tgfypfJCYCoqSI3n82V8pl5Pi7yhFGZoj+U8miy7Cog9uGu4/3f7M739utHlUKP7O1wW8UicHi+DfmnG/MTfsRIZ7vuYbaTfoaNBZeHPrqNl7Tux7TFp7beyY1BxtmQpJupH9PuzuDxSvUTKzHFsw+/NYH1JKppsshDH8vllOElkeufE91qX3ktWugbEJboW4uSzfPMz5n6818L+dJaZeiE4wnnG6TEnkejjdyqPN05/T/2d5hif7L53bR7+c2pxuTStfsic8EXhcvS9/gk6J3y6/vcCfqmzServCa9Ishx9sgM5sqFCWyaN1F97gM3k6VJPa2TwyiM/JZkuDxGEB3JZkiPaQ0uvke764tgvWjhw2HNXSc9dNfSJfB/FNdqH47bt0vqbY7d59BpzG2m7ZF7fyfapyKyxP4S4HbyPzu6yL1Ldd4X06n3m+SPPlQ45LXIhz2kmuT0n/LRDTBB7vKOjo6VzHuSojMmCQL/zwE/0z5/M+8NbMP5jjf27SPaDtuWRQi5/OetpyZ2ym/FScRwY4/Fq0ZxK1ZYXq7m9d9gCabXlxVo0p3LsfUuVXPuC6MRIF+LHOp+1mxmy8cYzjYPkLDtuOKn87OXvk9peH//vc6znnOigfHTp82S2/+37pI/fMrQM+liPnWRpxBpPkHKs4gdDYuzGEhRNp1ReCExF+f+xvLcXf16ac9zoUy+MVzLn0fEMfHYynVGi143/2Qd6Em8TL75vTvva2WTunVy38BaOr7KLo0FlDn5fTs9Ba74+ehs7+JrOz4vZcv7L1moyT/068fr477jp/kx/69nS5zZk92eQbHkvpVr08cppxS1b83PSln/HDiSZPN35MTAUiFTsGU6qrhkk+g4z1mtLTgdatW9Pbr9t26WfLRj9WOwtVOHcP0qSSgbnhDfB+AlZjj6t/3vhqyqhgBnktnePedzxVmTQW6quW2RiwHs2HYPGet6zr0kjrxCEB3KZPaJ922OOLtZ4axrMB3+H7VOKUVwRw80JOlrQcLwfqkcrM9W1U2p6duxfnO2snWQv/I42h+B42cGK6gNjA+Z9nebLlJNS4NG/94r9pPrTpco5Jgifqkz4dF646Nop3Xzy2PYd/b5x+mXswzeZL6jjLTsZn4HlVKYD8Iku3Lg9CGU8UpENOpZs+66d8va26+eHt+nmR7aqPVSqt1Ux+PSeUJl2qForltbL67GG7m+8krkAl21fEFNdZjaRsc5nnaqAcSYN9xnJk0VfncY7P3mqzjnRJXmTEfSPXgbdqd1bzDknmQEWuThIJhmZDsAjt3h8qSnDH33ezPZ5wR+7VnryF8kPGkql6GPQWL4zxXO6bfz5+z8/llpelZ691WRnOnk/jPXaQcsrkYv8dinjR66Vdj5n1hWUSuffbZadlKx3Oq1JNkn3FFzpmJ5uLEHpXKsmY7+XkpnWRxr7d75Av3vXw5xWOHMSoE50TSrbP1ON59rnln+ZW67I9HXerrhrYYmy3HtapL5wBrCT62+SFOiXp7dVUtlgJnxkTvgJmAmfyuN4/P/7WxvMfX+X9MvjI+sfv8HcpNRdtxjvz5HsgHm3jz3pPu/Z55dElQSlyP8VckIWXUkCMCZ2YCyZ9lL6L9YnMp65jiYauzy8lFzWeKo/VKcy8DvWvp25KlL+fKwlEUeTaJ+bb5c2/yP57T0+6bRrzf/QUZ+WiivM6OjoEu5S8mWWkh2VnYzxDK6QYj/8OX09p5k1TtgftIvLU7dPJ5xM45CtWR/ZILqSgeR4Hu0jJF2ToNJ9b6hAHy+6To0Ntanva7JB9bF+wUxXpk18mdmEJd+/OXIpRIwum+aOTjbrOFEWY6qOW+MZdBR/MXcs+7JL3DttKw2d536srz3RTLRBZfnuwzeZQahS5Lzw7F/ClZx2jW/fTj//vOMCU33K7sN4B2iOZwBBNgwKd6vKQfT/8fO3mexOWzrPbZv+boL9wxnoNgOaDzjJecn62y4074N3fdk89vjMe7trnO/pdHEy4Nvt96UtqnLayANqCmO/w0u5ea5w+v9oVzT4yzmp+U4tjS94lOqBw8mK/715C6XTfpr4s9h4B40iM577W+y0DU71RwUBnWa5O2QH2+0g/KTCcDn68WTCj+W7uJNpNqKPhdElyJ2+hlOjXZ8az9Rp2XIeciId0yVlY5XDbKuMhXEhCA/koyQz6FPF/6dP6pkP3a/5DYelJ4sxVUY7+aZiMIF98UBWZoMiL681/bfnQXN7xLrHJ7W+Zj7A+nul/u4MvrjDOZDiBf3SHZ8dvV38Bf50fxkeyXhLxEYHLZx47Gfje73h+uAtTH/lhPjXtLzSu74ilVRERpoWTTZ/z+Jy8/7NxN8x/qJNqvaXzi8T9vsmRce6YmtAVZ7O8fcrkWRHXY/lQqPTuUqjL2rGB9Ojv+Qn+oIff0GgpCqSvf3xP0p3f0VqmyAXw15eG/k7BAak0ur0XOyYKNL5eW+8+05F35LNro2f5x7mAuwTN2bXYBOMjx38GOiT7vrf1P5tHX+H8EQWh5v/NRnzz5Y2/Hbs28cPEMzFwOFYuHUh18l7btXHpMbvJZfRFfRLD31/7P3KVtEV6hL9v0QPSI4exO7EaAHgZL6fjjSV20S19T/j/84XP7D/5O9E5qi3s9GHY//Nkh04vGtz+r+rBvqlfzq4PoLsNdbrNyd8zbwn7UHqKbxO0ztgzh+T7HL04Uz4Pv8Yg/DJ/u84HZSUrFRMM2pPtxlvPIOsE2Vd29e7ktl+PG2TvdY+0uCB6KoM0dUYbEWTY4+/o02dl01l8JOVqgFgGBeC8MBE4KQMra8oNnDjQka8LzSgb/3pYb1V3Kzzj52t5SfOy75gvJMPZqkqR+vGRc7oYKy3UFpyxfj2Z/mk0Dh+jqDf2Xx6uSj+An+yWbTZyO05zgP9UuP3pZJKky3T1yk9/Yf0vmYoID2cBRf5oi/aeAuk064Z34CE+GzQdM6RmsJjnevl58ZzEdvpXKXZfFEz/guz0y/K6ciCSWZwkf0+B1zlkZ78jVQxK5JltLctdaXBxysdA+jgrvEOwoy24fdjy5J78iZzS1k/fju+7eMGCBZQISYLBCfu90Gntj1mbvdcnr7zQfRn2PhgQtt28/q5+P00U1J9jkz2OogdtJecV+OSpFs/Obb+AU7Y1ahOu0bq2JHSXR/avU4f8JRpzo4d0qR9NbPXr0OtrSru8Uk6PPFG8dPkRA9mclId0t8nPfNn8zknXcdju7LGeKYZ/d37U5+YkslB1cO1dZr0Ey1RgDnZqgxOvotFB/zt91muDOSMv5b4qbulfRe51588ZYVCoTGmAk5cHR0dKi8vV3t7u6ZMmeJ2dyacgYEB3X333Tr11FNVUDCGAywSG2vplGRKjoWC4/4Q8ruBk/RaaIb2aLJ6vWVaeOhBOqp+XvZkx+/YGDtPDpBKFz0kzZjP+ywbfDh8QTiXSzx5fNJxX07NIIHoi3FZ/P78aPAq/e2KMWRajPSFXDLPpeMCsP0/L2X173XMsiV46JSb8xEDqWJ5zQAxAADGavHnpPKZUvtb0hM3SEHOKxPKRQ+Z+4n23QN5b8AqVMEXNoyvmofbMlndMZ9EDwhJ5UBU2yf+Yu5TXR0h07yF0ueG/g8Rrxsbp3FkMuGBiaKibuzzyFbUmQPwaEH8XZvHnaH3qYJ7Y1e8KPW/4NWPb/uEZszYT/vNnKFdKldnr1+WLB0+q1yHzSqXt7SakinIfV07TSAuV0ZMTmT2HKm5LOiX/vt/qdlXdKn1bY+lZp9p0DsQ1GOv7taiOVXOBm6lq4ycU9FTgKRiKpNsk0sBeIkAPCYGAvAAgPGi+snE9vLa5KqWADmiINQfuV4RfY04l6pN5nIAN5sFBtI7NcafP5F71z8SCfQPX8YfaUMQHoDhJIg/UpB+HAqtgL6iP0g7ZG7RnjN3fvlknX+3vPu9My19ADJionxomwh2b4mdVzFXpfL9lANVAfa33tJ3fvVnFZRV6+IPHK/GhtrhG2fDaPjoEdiW171+IIIsYgAAAExk6cgCBbLFbReaimzv+rI0qcIkjaVj+jMgGtdyMQ4E4QE452Tu+TTxya+Bm0/RQ5UfU7B8lvb6yuUrmarC8lq9HSxVUfVs1Uwp1qI5lZHsyNHKDxeXx2YnTp5OhjLSiw9t2cOevww55drCGyRJvX0Feu+qq6WzTx4+EJ9to+EJ/GYH/g655YCTpbpFXEwGAAAAYAT90kMpmJYPADKAIDwA5yrqzJzBLpX2LbBCOnHPX6Q9sesHQpZu9Z+gjSrRZq+l/9/evcdHUd59H/9uspvNgZxDEgIEUBHkICoIIrbaioJQe1usFUsttT719iUogvbWWinSVkGoh+IBhLu3ej+th9KnWrXalqLVWkERRJFDkFNFYoAQciAhySZ7PX+EXXaTTTKbzO4m4fN+vXgBs7Oz18zO/Gb2+v3mmuzs3uqblqDRn/9GcYakZ483ebFUd4wOeoQvlkNT99ThyaMk0eFRhqNK972yVZcNy285NH35foqqgJ5g19+a/gAAgJ5lzI1SzuCmmz0aPdKrt1G0DgAAehyS8ADCE/gM+Vg+ZzeAy2H0PddbJyccVYtEPXqwwvFNf5OER3dCAr7TTncc0NHKVF23cr3mTBysC0478Zz4rjAMPYBg01Y1DRPJuRoAAEjSh785+W+nW/rGMumVCD7PF2hLvEv6xq+lymKuVwEAtiIJD6BjApPxNUeaEkpdICEPAGGJc3LHRTe1LOFJeUycXtx/ibY8naTtcdJpvXvptOQaDSQBD3QtOWdKqa08OgJA+MbcGJzAwklfu5cECtDdNNRJTh4VhhiZtqrp5o6M/lLxZs4hAABbkYQH0Dm+ZLzUlJD/fF3Ts5ZPYbfV36Ldpq/GOIq0MOF/Y92cbq1eTiWo9QRpnVz65HCczivMULzTbd+dr111iHtHPM8zttuVy6TXbqeAqJtyObz6nuvNkxPKTvxB9zNtlZSYLtVWNP0/Mf3kYxtemCF5Y/j4CHSO09001KxM55dF4RSiJd7V+cfWxCc0/W33NYbTLZ05iSR8KE63NOhi6Z9LGRHnlBUnyRvrRqAjEtObjmE7jt1pq5oKAI8dlMr2SH+5u/PLRM/kdJ9MwAMAEAEk4QHYJ6N/013xp7Ba49KH3qEqVo6OmlT9xDyvRAeJg466qW6uDiuj1dePmlQVP79fKQnF+ubAp3V+npSrcnmqj6p340GNKFrWoc99+UihEtJ66/K4JXJ6u1BydtL9PbsDYdqqpr+jWciTN7xLPV7DVvEJPWt90HHdIXGZc6ZUcE7o1277qOkYLdsj/e3err8uPYWvA7t0Z8fi8uTFTZ2aydn2dWxe/suefR6MFO4Mtsa3z0tNiZvnvhPee5pLzm76uzPXGKGWn5x9yv/mCinwTsbZGzteHO6Ilxxxp1bxV5xT+sqd0j9/FZlzbGfPJ22Jd0nX/q6pcE+yfuyi6+mV13Ts+kZa9BVm+tQckf56r2Qs7KOB15XFm+1uaZPAZ9onpjdN62m/J2Ot+TnQjhE4my+zo9epgYUefO8AwjV5sbTmZ+HFDjuu1/wF8ogmkvAA7JWcbV/1cjdzW/0t/gS8JBUrR1+ve0iZjipJTc8vXpbwpKVl1Zt4JTi44/mwMrTVDGp3vur6Rj2/U3p+pyRlSMrQcIf0Z3fHPnfVu3u11UgF+pX/+/PprXLlOI9LkrwNHi1O+I0SHNFJCH1w0KGxUfkkezXIKWcbIxr4/HF/sqpqGzQzzOXXmzg97rlK+5Tvn5apY5ZGoli7/ZD2JaQpI3m46sa9JE9VqSQpNdGl1ESn/vjPTXLVV0qSKk2KJCnNUa1MVSnFUatqk6Sj6qUzEo7oNr0YZssj693zHlWpMpSa6FJ9RbFSyrbpq188FetmIQbeHb1MpcpQQcN+jf3orlg3p4WGuAT9bXe9DuzarfLjHhkjZSYnKCslQeU19cpITlB5zeCm4/SCkfJUlSql/oj6eL/U+F2PKM5KZ2wUvHrGQnkyBytX5XKXfqrz91o753dVaw9naE95qhrLc/V/HAlymvA6F9dWn649u1JVfrxavWr/oTxntb6WOkSZVUUdblMsz4MNDqc+GnmfztuyUPGm9eRco+K1acCNqnD0koxRWlydcuv3a+CBVy19TqPiJYdD8Tbt1w1xCVp/rEAX2bK0jiu68GG9X5UtyaFxqaUa8t68sN7/r8F3qsykSpKcyZlKSO+jqlqPrXHt2c8SVF+epqyUBHnKqnVNXILi2yjGbIhL0N8qBupAeWorsctx4u+W1xj9Gr/Q2E3/1W6b/rg/Wbu/TGyx7IH1h7P/SVoAACssSURBVHRpmOvndSTIOIziu1FyuejChyXJ0v6y9nCG9lV4lNXrgHJ7JSnleK7O6cBnNk5/TpvrClRf/KnGfXCb4trYXg0OpzaPWqj0lGSdlpui+ONlTaNpSZK7lz8512iM9nxerMMet0pMuqpqG+SQQ2f3S9fIjFrFOxz+JPJ7u0v11Dt7lF691/JvRys2DLpFJmOAjtV5VOZNVo0rR2f3S9fwgnR9cjReX3iz1e+qqTonu7GpPZIajdHOXbtVVV6qhmOlSnE7lZboUmFqo+LlaEqSvr+8zY5gb5xbpv8Fis8s7FxfQWsFL80TaFYTrt2hQPEU84+dh+Xu319jB/VTfJwj9ExZp4VfZGFhv/PKKXPuDMV/9KylRRqnW46L5gbte41eo83/sVZVZQeVkdQ0tH75cY+ykhM0PP244n9/PYnaE7xyyhHnkKOt81Frd6j7Hol5QqMx2vJFhb74bLO+sWtB+x/eVuFvOAKX06xNLYpIao70rCLScOLn1+6V0goYfRAI5HRLQ7/R9MdCsa7X4dL745YpoWCEzhkxUvHnfq/1mOObHpho940y6JvOyB9RRxIegL18dx4EVi8f2d00JKC3ZyeVd5u+/gS8T7FyVGyaph01qao1rjbvjK8zTv1n/VxJ0jPupba0a0H99fqp6/moJYpbU2/idb9nho6ql5ymsd3kda1x6eiJztZYCfz+ggR8hevrhneo0CJctcalJ9eXamwHCwti6b/qbrT0ff/qn0eU6ajSzDDWsXnxi89wx15L73/47zu1NSiZEvgswgZJZ7d8U4gRlQtqS3WT+49tHt/RLq5Z9O5RbTUZatphe2u4o1BfjfL+s8Rzjb4wvSVZL4yA/Xz7wnBHQ4eLkyLFfwz/+bCkwxbf5ZKULylfBXo4qFjK7jhcZ+L1dMNk3ez6c7vzrtjq1FYjSRkq0FC95XbK3clzr+8RN4GsrmPg8SfJ0rnXp9a4NH/Nlyo+ccL734CiNKuf74uvBSrVm+47bBkZ6Mn1pTo7oe1rqUANJk5OR8eHJQ7c/kdNqoo/yFGBHmpRoBfoqElVcVHLc9Kf3e0n4X3Hg6Sgz7D6iKNQ+8tRkyr9s0Fvuq1vN7vVG6dueNOp4hPn2OGO42HHogc+zWxWmNm0LgVKanfdao1TDqnN47HWuPTUhgoVa7t/2rIQxZiBjprUDsQunWh3ooV2N10bFatlMqpApZrQzvt9vyt8o0r5rqszHVVyKPhyprfKtTLhkTbjQ51x6nHPN3VHwh9bncdOtcalG95s6rKysq0CY5bkO+7C/9zvPr9P79c2SkpvcbwnOuOaPq+hKa4cNakqXt90vKcnOnXZsCEaf3qOyqrrVF7hkSmXDlbW6u/bD6nieF7Ap5zYFzZUK8kVp6kj8zX+9Byt212qP2yqk9RXwx32Jivu29FXW02zTtcN1XKo+sS+sF+SlJIQr68MzlGK26m/bz+siuNJkvqf+NMkNTFe087tq8KsFPX52jdVX3lYqYkuVdTWa/uXldq8v1w19Se3UfWvt2viWUeUn5GkXiN/rzxntdITXWEV0rRWkJKR7FBZ9ckivjMaD2iahe3x7uhl2lDq0oHdH+tXcY+3O/9t9beo2Nlf5xZm6Kw+6cpVuarrG5QZd7xLFjh2xK4B07WltreKDlbpbj0T9c9f+tcibTX1Sk90auJZucrPSApRgOSwVID0x4++0O4tJ/eXvhe/pqI9+/Tu7lLVelpeFxw1qer/UY2lkurb6m/RNu9wnfHqQY0e4FFWSoLW7S7Vmu2HVHHcF4MCj9+mdbpm8G81Pt8RVnF0vXHGvB+nI97P/64OmGx9cNChmvqT7a80KTqsDB01qXJIyghxjk1xx+nrQ3KVkdNHrt0OldfsUUZyQlNc9Re8pfm3++ufHlRNfaMKlKmJ7ZwrGhwJWrWhXM7MPUHFvoHL7hdXrWutFOHtrteXu31tq1f58cD4lBO07ITDW8K+0SAWNg+/WyO3PdRmsWmdXHqq8Nc6r7c0/sM5bc7b4EjQqvLz5XQUqu8lf1bRnn1av7dMx+oaItp3htAaHa42v69w7RowXWf8+wXblhcJjYrX+jPmav/RGk0/Etv9zVewn57o0mFvily7HSdizwD1Ont10LVR6om/Sypr9WbRIX1xPFnF/0iXtF/piV/qsmF5J683j3tkzICT50rPidhT3vSaQw6NPz1bF+Rnt17ghogjCQ/AfoHPiffxVWn5nsnVw4aTrTfOdhPGze+MD+WoSVWxciwnEK340AzVJXUP60zH/nY713zqjP2JA9+6+QQmr0NpPn9X1WqivhNa60Rva3t1VqR+4Ncal9ab4bqk7mFL33emrK9j4OMfQi2vvaIXOws9rBzfvVVuqbjGlzjzdVJY6RhvrisUsUjS295z/EmTApXyiI5OCCcZ3Borx0W0hSpgC4ddMTiwUEwK7iTMdFTpZoW33YuVo/+sn9vpgrrdpm+LEWGsxreXG7/SYtv6zr29Va40R3WL9wWud+B7O7OdMx1Vtu1zh5Whr9c9ZOmapta4dF3dT9U/7lCHOvlaO8dE4rzvE3g8dOQzQu0vPl+ve0hj4nbEpMPzpvq5nTrO2zqnWb2+lhT2dWckv+twfhfY/f7W1snKtZokzTKvRuQ80tZvh85sq3DUGpf21yX5/99iH2hjtStqG/SHTQf0h00HwvrM4x5vyPfZec5u6xhqXltaXd+ov2w92Obyqmob9ey6z5tN9UhySEo/8SewAQ36fx8Vh5hflgsEf/PuPm017XceF6hUUywUbfzXPxtUrAwV6EzVWpj/Q+9QFdfn6MNdknZJOlHc0lRo1l5BTLwcUpvFuIFFM71VrqcSHmnz93idceon9TeqTGk6rAxbElpzdo7UVjNIwx17dXcnijY7exNARcj9pclwx15d2uH9JeXEn1bUloaxL2Rq19aD7R4rPhW1DfrvLdJ/b5HCKY6+6cQ+Ee2E5YL66/Vvkx/0aMDeKtewuH36L9fqdt//838PtzSi4YFQ56Na6YOPJan8xB9rLJ8X11VLAQV3oTxucxFegSp0rYXCOSt9cA/XT9Ns15/ajCfGSI4wc221xqVbNhZIVopNd2RIO2StMDVoe7dzDIbgMfFydZNRQhfUf18fmiEd6r+x4/3tubH2dkmyZdm1xqVf7uyvZzp4rvCYOLk6USjd3LOeiTqoTEnyj1ZZaVK00/RX8adNfezTY3wzwsmCfY9aj2+eZn8nSioMmqMj15uPv7VLGckuLZ42UpNH9Amv4bBFl0jCP/HEE1q6dKlKSko0atQoPfbYYxo7tvWBBlevXq358+dr3759Gjx4sB588EFNmTLF/7oxRgsWLNCqVatUXl6uCRMmaPny5Ro8eHA0VgdAKM0T80O/0fJZXzVHpIoD0vtPdqu75uuMU9Pr7rXU8WO1M6+p08WpRJsuunyf6+tca6/zPcF49Lz7/k51+rTVERzYpkjpaMdVrJOXbSWWw0lQh/uZ19X9VPUOV8jXrf7ob614oDMJhbY+q7XtJHW+c7sj2tunrRbXBCaufZofu77h8H0Cf2iESqDFQvNjKfA7aS0GdcW75a3cQVlv4vW45z/a7RDpCF+n7E7Tv0PJ4EChjovm30U4d0u3pas/VuVZz0TtMQX6t8lr/5gx6lBRT2DHpZ06lXwLjFMhRvWwItpFTs2X2fyapq12FitHB71ZlkciCvzOukIc9bFjmxcrRx96h1q+NrJ297i1O8x3Nrv7NpzRoayc06xeU0byurMjOnstbPe1tNXltXUe6ec4bClBE0pbvx0i/btBav/aMtp8sd5q8Uyo63CfrhTPmrP7nBLuOTJaBTFSeIVAX7N4jrOLnedt300AkRgtLpLXINH8/Wh1PXaa/ipWjqX5rV57t5fUrDUurfGeH3I9dzb2123Ol6N+DWiVXeeKSJxf29u3rPTB1RqX/uC9RH+ou6TdZTXv2wk8V/v6DAJ1pN8mGufmH9XPU5qjulMxpPl1fmvborOx6kMzxH8d05EYGOr9rfWbhPubPTCedKRtHhOvH9XPCxpdyepNQqGuT6zeoGJFrXHpqcZvRuw6Z7lnqqqULOlkv5vTNKrBES+pa/ZhhVJe49HNv92kFd87j0R8DMQ8Cf/iiy9q3rx5WrFihcaNG6dHH31UkyZNUlFRkXJzc1vM/9577+m6667TokWL9I1vfEPPPfecrrrqKm3atEkjRoyQJC1ZskTLli3Ts88+q0GDBmn+/PmaNGmStm3bpsTExGivIoBQQt0t7zPuP4MS9I2luxT3z1/JYbpeZ36kOmuaLtKb7l5vfsEVTudWqCSY1c731n4kWKnKjHUiW2r9h044Pz7C1ZHE/xLPNdrmHRh0MdvZ/an5RW7vExWWrSWE/J/Zyj5htZPAjmPBzs+Kxo/CcHSm08iOxFkkWU1gtbce0bpbPvBHpJWYIFnrOA3VIdLRH/OByXf/drSQDG5PyOOi2XfR1kglvQMqttsq5rLzh3U4rB5n4fxQj0VRj9S0D7R192+s4lu0t0fIY0FhJF5j9P01X35nkgZ2rYOVYqjAYi6p/dhnZZ5Q54JYfyfouLbOIwUqbTdBE0okfjuEe13e2ZFZIqFYOa0m1ptrrwC6q4pEPAj3HBmtgphItinc4qZQ7/dtYztGYQj3sXxWY0Ckzx/Rur6KRLGI1WvvwERae5/b2XbjJCv7Vlj7RHv7aag+gy7UjxBOIYqV38CBo5o1/00fcp8MsS06E/va6nvtSAy00v8T+Js91HV94HZoHk/CfWzq9Lp79ZHODH7BYqF6Zx4fKYUemSNQJGNOrXHp/zZOCr38gGvf9vqwukIfuc/CV7fpsmH5DE0fZQ5jTExD8Lhx43T++efr8cebnsHk9XrVv39/3Xrrrbr77rtbzH/ttdequrpar732mn/aBRdcoHPOOUcrVqyQMUYFBQW64447dOedd0qSKioqlJeXp2eeeUbTp09vt02VlZVKT09XRUWF0tLSbFpT+Hg8Hr3++uuaMmWKXK7Qd10CLZTvD75zvovcNT+17v6od3ZYebZqax3WdraBH16h+baN1cRbOPuQle++1rj09bqHbN/+0fzOe/L+Fct1s+O5zK3dZRWJ7z9Sw7BJ0g/qfqx/mHNtX24o4cRsK3fhBu5DkYgzdml6Fu9P250vEm3rKjHEynfffBh8H//wed001gWyui9EI77EUlfZL4FIC7WvR7IItr22WH18RSSun+0Qy/Mpuhc7zzOB1+O+YzdTVbrX9Vy7d1GHOpY4B0ZeLPsKgI4IJy5EK4a09jm+WBjqGsbK53flGNiZtnX0vQUq1VvueZYewWDH9U04v8t9I+VJ1r+Xrvz9hvL8jy7Q+NOzg6aRr+sYq3nkmN4JX19fr40bN+onP/mJf1pcXJwmTpyodevWhXzPunXrNG/evKBpkyZN0ssvvyxJ2rt3r0pKSjRx4kT/6+np6Ro3bpzWrVsXMglfV1enuro6//8rKyslNe18Hk/XeWZmT+HbpmxbhCUlv+lP7+HB00ff2JSQDxQ4xH1ihrwpvbXtyyodqa5TXfmXMlWHNfnfS+U0re+DHjnlUtd8Zn1XqD7uancYdyW+bROJofJi+d1H8zvvyftXV7p7tSOdatEYpjVwG11yYkQQO5PxoYZGjiS7j9tI3Vlkt1i2ravEkK5wvu5OuutdnFZ1lf0SiLRW9/UY3P7ha4vVx1d0RV35XI+uxc7zTGt3Ya6pO7/zj8NBRHDdie4mnLgQzVEqWv2cTlzHdOUY2Jm2dfS9xcrRf9bPjdrIeT1lFBW7fFleLY8nOGFMvq5jrG6vmCbhS0tL1djYqLy8vKDpeXl52rFjR8j3lJSUhJy/pKTE/7pvWmvzNLdo0SItXLiwxfS//e1vSk5OtrYyCNuaNWti3QT0aCkn/vZIKj452ZktZWbrzZQHldBwTF4jfVHtUHWDlOKU+qUYxTmkOK9HE3YtVnybiXqXLi5M1mA1KsUpHfNINQ2S5FCK0yjFJX1WKW0+Eqd6b/AwL8nxRkMyvCqqiFNNQ/hDwHS3E7x9jKTuMWROpC7yTt3vHnZosf/Y0KkWSSc7zx9SYUKV7hiwT6P3P604tV4s4DEO/alhgkqVrkol+5/bFTjEcqzWIxLL7aqdbV25bdFEzAaA2OvOsZjzKbqS7nwsnQr4ftDzdZ8+QbRtp+kf1SJD4uNJe7Zu1utffBTyNfJ14ampqbE0X8yfCd8V/OQnPwm6u76yslL9+/fX5ZdfznD0EeDxeLRmzRpddtllDG+BLs1bcbW8ze+yD5Scrbnp/dpdTqPX6IO9ZVq/t0ySNG5QlsYNylJ8nEONXqMP/31UJZW1Kj1Wp/KapouPjKQEZfVyqbzGo4xkl8qq61u8tn5PmdbuOKyK4yfvDk1JiNOE07N1XmGm//1ZKQnK7eWWkXT4WJ3KquuVkdz02v6jx/Xy5i9VVWv9DtPUxHhdNaqPqusb9ZetB1VT77X8Xh+HOlZEmp7k0swLBqgwO0nv7T7S4c+PFi7y0J105f31S/XWPdMm6pzheWqsmK3GNmJzY2KW8stTpMpa6VidvDUeJUmKr6zTR0XBMbMn6MrfW1duGwAA3QXnUwDAqcwhKT/drbsmDdHPX9uushru1u3uKDKMjfw0t2Zf+9UWz4QnX9cxvhHV2xPTJHxOTo7i4+N18ODBoOkHDx5Ufn5+yPfk5+e3Ob/v74MHD6pPnz5B85xzzjkhl+l2u+V2u1tMd7lc7HQRxPZFl5czSFLnh0V1Sfrq0Hx9dWjLuOaSdNGZeS2mW/Gd8wf6E/yHqmqVm5qosSeS++G475sj9cHeMpVUHD+RoE9QeU3Lv7N6uZWfFvwZS71G63cf0bo9pfIaKTM5QVkpJ99XVl2n8uMemROv5aQ2LWP0gExt/PdRHaqqVU6KW3JIhyprVVZ98nNGD8jUhr1lWrenVJJD40/P1gWnZfs/+9tjBoT9+VZfCzXPwcpa/X37IVUcb3mxn5oYr2nn9lVhVkqH3t8VpCc6ddmwPKW4nfrjRwfCKszoCpJdcTKSjntOFmV0tNijPVkpLv3HqAJV1TZoTRf+TnuKPumJWnDlME0eceK6rp3Y7JJ0UW7o13wxs6TieFPhUxgxwEoMWbe7VK9/WqKa+tB36kdqnwS6MoZSBgAAANAZC64crskj+ujKc/q16MNct7uUvpluiCLD6Lvvm8OV6E5o9XXydeGxuq0cxpiY9gWOGzdOY8eO1WOPPSZJ8nq9Kiws1OzZs3X33Xe3mP/aa69VTU2NXn31Vf+0Cy+8UGeffbZWrFghY4wKCgp055136o477pDUVJGQm5urZ555JuQz4ZurrKxUenq6KioquBM+Ajwej15//XVNmTKFgxpAtxKYwAssGLBa/BBYNGGl+CBUYUFnCwzKqut05Fitdu/ao9EjhyovI7nFOjRfz8BCjNxewe0OVazR1jx2FkYEFnaMHZQlSUFFKb5ij8D16Mznh/q+rSZ17V7vaL0/lm0L9/jqKhpDFAc1L0Bif+l6bYt27MpKSdCRY8f1753b1X/wUFXVebvVd2L1nOV7f6/aEuU5q5We6FJVrUepiS5V1Nb7C75cqb3lzh7Q5de7p7YtVMdlqALDz8tqWi3US090auJZucrPSGq1+NDtjJNDUm2DN+h9lw3L0/jTc6K23qHalpIQr68MztHoAVkR/06sFmY236Z2LLt5MVhrn9FaUVmyK06j+mVoW0lVpzq6m7cjcH8LtZ+lJzo1rE9ai89t/r1Z2ZfbK5iz0l6fRFec4hwOy8vybe9qT6Pe/axUx+raf5+v+LNfZrJt++LGz49a/nwpdLGrFd2p+NC3L6W4nZ0unI7mels5BjqqteO0uq4xrGMo8H1ttS0W282O77stnV2ncN6fkeTSzAsHaOyg7KBr2bbi+ZSRfTT+9Jx2z/Gd1dZ6dDS+NBfqGqM7xaBQ7No2drCyLcPZ3uHM26IovxXdoW+mreOsu++v3cWpup0zk11aNG1kq8cR+bqOsZpHjnkS/sUXX9TMmTP11FNPaezYsXr00Uf1+9//Xjt27FBeXp6+//3vq2/fvlq0aJEk6b333tPFF1+sxYsXa+rUqXrhhRf0wAMPaNOmTRoxYoQk6cEHH9TixYv17LPPatCgQZo/f74++eQTbdu2TYmJie22iSR8ZHFQA0BsEYcBIPaIxehKrI6uFE5BYqhlSur0KE52sGM0KTs+P1RHcWCBYUfaFKros/RYXVCBopX1Diwqaz4qVVuFpVaKJ9trR2vfj5Xvzeo863cf0b92HdJnn+3W6JFD1TstqUVRVvPtFmq/l9SieLWtotH2il7bKv60U/PtFKqoKlSxa1ujp/nW23Fifzl/YJal4sNIFTdZKRhrq8i2rW0T6vPDWe9wi9nCKVbt6PEZqm2tHaehik47WsDc0f2lrSLKcLZbqPNa82Va3Zfaix1W9+VQ26S9tnU0nofad0Id550pmA81EqJvG40dlCWPx6PHX/yLBg4bpYrjjW3Gl7a+U1+cClWU35GkrJWbECJRCNzeOSaaRaOt7Yt2xL7WRseM1nkwVlq7lm5vm3TFQt7utGwr+3JXLObvyLku1HqHivmB6JvomG6ThJekxx9/XEuXLlVJSYnOOeccLVu2TOPGjZMkXXLJJRo4cKCeeeYZ//yrV6/Wvffeq3379mnw4MFasmSJpkyZ4n/dGKMFCxZo5cqVKi8v10UXXaQnn3xSZ555pqX2kISPLA5qAIgt4jAAxB6xGABiizgMALFHLAaA2CIOd4zVPHJMnwnvM3v2bM2ePTvka//4xz9aTLvmmmt0zTXXtLo8h8Ohn//85/r5z39uVxMBAAAAAAAAAAAAAGhXXKwbAAAAAAAAAAAAAABAT0ESHgAAAAAAAAAAAAAAm5CEBwAAAAAAAAAAAADAJiThAQAAAAAAAAAAAACwCUl4AAAAAAAAAAAAAABsQhIeAAAAAAAAAAAAAACbkIQHAAAAAAAAAAAAAMAmJOEBAAAAAAAAAAAAALAJSXgAAAAAAAAAAAAAAGxCEh4AAAAAAAAAAAAAAJuQhAcAAAAAAAAAAAAAwCYk4QEAAAAAAAAAAAAAsAlJeAAAAAAAAAAAAAAAbEISHgAAAAAAAAAAAAAAm5CEBwAAAAAAAAAAAADAJiThAQAAAAAAAAAAAACwCUl4AAAAAAAAAAAAAABsQhIeAAAAAAAAAAAAAACbkIQHAAAAAAAAAAAAAMAmJOEBAAAAAAAAAAAAALAJSXgAAAAAAAAAAAAAAGxCEh4AAAAAAAAAAAAAAJuQhAcAAAAAAAAAAAAAwCYk4QEAAAAAAAAAAAAAsAlJeAAAAAAAAAAAAAAAbEISHgAAAAAAAAAAAAAAmzhj3YCuyBgjSaqsrIxxS3omj8ejmpoaVVZWyuVyxbo5AHDKIQ4DQOwRiwEgtojDABB7xGIAiC3icMf48se+fHJrSMKHUFVVJUnq379/jFsCAAAAAAAAAAAAAOhKqqqqlJ6e3urrDtNemv4U5PV6VVxcrNTUVDkcjlg3p8eprKxU//79tX//fqWlpcW6OQBwyiEOA0DsEYsBILaIwwAQe8RiAIgt4nDHGGNUVVWlgoICxcW1/uR37oQPIS4uTv369Yt1M3q8tLQ0DmoAiCHiMADEHrEYAGKLOAwAsUcsBoDYIg6Hr6074H1aT88DAAAAAAAAAAAAAICwkIQHAAAAAAAAAAAAAMAmJOERdW63WwsWLJDb7Y51UwDglEQcBoDYIxYDQGwRhwEg9ojFABBbxOHIchhjTKwbAQAAAAAAAAAAAABAT8Cd8AAAAAAAAAAAAAAA2IQkPAAAAAAAAAAAAAAANiEJDwAAAAAAAAAAAACATUjCAwAAAAAAAAAAAABgE5LwiLonnnhCAwcOVGJiosaNG6cPPvgg1k0CgG5v0aJFOv/885Wamqrc3FxdddVVKioqCpqntrZWs2bNUnZ2tnr16qWrr75aBw8eDJrn888/19SpU5WcnKzc3Fz9+Mc/VkNDQzRXBQB6hMWLF8vhcOj222/3TyMOA0DkHThwQN/73veUnZ2tpKQkjRw5Uh9++KH/dWOMfvazn6lPnz5KSkrSxIkT9dlnnwUto6ysTDNmzFBaWpoyMjJ044036tixY9FeFQDolhobGzV//nwNGjRISUlJOv300/WLX/xCxhj/PMRiALDPO++8oyuvvFIFBQVyOBx6+eWXg163K+Z+8skn+spXvqLExET1799fS5YsifSqdXsk4RFVL774oubNm6cFCxZo06ZNGjVqlCZNmqRDhw7FumkA0K29/fbbmjVrltavX681a9bI4/Ho8ssvV3V1tX+euXPn6tVXX9Xq1av19ttvq7i4WNOmTfO/3tjYqKlTp6q+vl7vvfeenn32WT3zzDP62c9+FotVAoBua8OGDXrqqad09tlnB00nDgNAZB09elQTJkyQy+XSG2+8oW3btumhhx5SZmamf54lS5Zo2bJlWrFihd5//32lpKRo0qRJqq2t9c8zY8YMbd26VWvWrNFrr72md955RzfddFMsVgkAup0HH3xQy5cv1+OPP67t27frwQcf1JIlS/TYY4/55yEWA4B9qqurNWrUKD3xxBMhX7cj5lZWVuryyy/XgAEDtHHjRi1dulT33XefVq5cGfH169YMEEVjx441s2bN8v+/sbHRFBQUmEWLFsWwVQDQ8xw6dMhIMm+//bYxxpjy8nLjcrnM6tWr/fNs377dSDLr1q0zxhjz+uuvm7i4OFNSUuKfZ/ny5SYtLc3U1dVFdwUAoJuqqqoygwcPNmvWrDEXX3yxmTNnjjGGOAwA0XDXXXeZiy66qNXXvV6vyc/PN0uXLvVPKy8vN2632zz//PPGGGO2bdtmJJkNGzb453njjTeMw+EwBw4ciFzjAaCHmDp1qvnhD38YNG3atGlmxowZxhhiMQBEkiTz0ksv+f9vV8x98sknTWZmZlDfxF133WWGDBkS4TXq3rgTHlFTX1+vjRs3auLEif5pcXFxmjhxotatWxfDlgFAz1NRUSFJysrKkiRt3LhRHo8nKAYPHTpUhYWF/hi8bt06jRw5Unl5ef55Jk2apMrKSm3dujWKrQeA7mvWrFmaOnVqULyViMMAEA2vvPKKxowZo2uuuUa5ubk699xztWrVKv/re/fuVUlJSVAsTk9P17hx44JicUZGhsaMGeOfZ+LEiYqLi9P7778fvZUBgG7qwgsv1Nq1a7Vz505J0scff6x3331XV1xxhSRiMQBEk10xd926dfrqV7+qhIQE/zyTJk1SUVGRjh49GqW16X6csW4ATh2lpaVqbGwM6lSUpLy8PO3YsSNGrQKAnsfr9er222/XhAkTNGLECElSSUmJEhISlJGRETRvXl6eSkpK/POEitG+1wAAbXvhhRe0adMmbdiwocVrxGEAiLw9e/Zo+fLlmjdvnu655x5t2LBBt912mxISEjRz5kx/LA0VawNjcW5ubtDrTqdTWVlZxGIAsODuu+9WZWWlhg4dqvj4eDU2Nur+++/XjBkzJIlYDABRZFfMLSkp0aBBg1osw/da4OOfcBJJeAAAephZs2bp008/1bvvvhvrpgDAKWP//v2aM2eO1qxZo8TExFg3BwBOSV6vV2PGjNEDDzwgSTr33HP16aefasWKFZo5c2aMWwcAp4bf//73+t3vfqfnnntOw4cP1+bNm3X77beroKCAWAwAOKUwHD2iJicnR/Hx8Tp48GDQ9IMHDyo/Pz9GrQKAnmX27Nl67bXX9NZbb6lfv37+6fn5+aqvr1d5eXnQ/IExOD8/P2SM9r0GAGjdxo0bdejQIZ133nlyOp1yOp16++23tWzZMjmdTuXl5RGHASDC+vTpo2HDhgVNO+uss/T5559LOhlL2+qXyM/P16FDh4Jeb2hoUFlZGbEYACz48Y9/rLvvvlvTp0/XyJEjdf3112vu3LlatGiRJGIxAESTXTGX/oqOIQmPqElISNDo0aO1du1a/zSv16u1a9dq/PjxMWwZAHR/xhjNnj1bL730kt58880WwwONHj1aLpcrKAYXFRXp888/98fg8ePHa8uWLUEXXWvWrFFaWlqLzkwAQLBLL71UW7Zs0ebNm/1/xowZoxkzZvj/TRwGgMiaMGGCioqKgqbt3LlTAwYMkCQNGjRI+fn5QbG4srJS77//flAsLi8v18aNG/3zvPnmm/J6vRo3blwU1gIAureamhrFxQWnHeLj4+X1eiURiwEgmuyKuePHj9c777wjj8fjn2fNmjUaMmQIQ9G3geHoEVXz5s3TzJkzNWbMGI0dO1aPPvqoqqurdcMNN8S6aQDQrc2aNUvPPfec/vSnPyk1NdX/vJ709HQlJSUpPT1dN954o+bNm6esrCylpaXp1ltv1fjx43XBBRdIki6//HINGzZM119/vZYsWaKSkhLde++9mjVrltxudyxXDwC6vNTUVI0YMSJoWkpKirKzs/3TicMAEFlz587VhRdeqAceeEDf+c539MEHH2jlypVauXKlJMnhcOj222/XL3/5Sw0ePFiDBg3S/PnzVVBQoKuuukpS053zkydP1o9+9COtWLFCHo9Hs2fP1vTp01VQUBDDtQOA7uHKK6/U/fffr8LCQg0fPlwfffSRHn74Yf3whz+URCwGALsdO3ZMu3bt8v9/79692rx5s7KyslRYWGhLzP3ud7+rhQsX6sYbb9Rdd92lTz/9VL/+9a/1yCOPxGKVuw8DRNljjz1mCgsLTUJCghk7dqxZv359rJsEAN2epJB/nn76af88x48fN7fccovJzMw0ycnJ5lvf+pb58ssvg5azb98+c8UVV5ikpCSTk5Nj7rjjDuPxeKK8NgDQM1x88cVmzpw5/v8ThwEg8l599VUzYsQI43a7zdChQ83KlSuDXvd6vWb+/PkmLy/PuN1uc+mll5qioqKgeY4cOWKuu+4606tXL5OWlmZuuOEGU1VVFc3VAIBuq7Ky0syZM8cUFhaaxMREc9ppp5mf/vSnpq6uzj8PsRgA7PPWW2+F7BeeOXOmMca+mPvxxx+biy66yLjdbtO3b1+zePHiaK1it+UwxpgY5f8BAAAAAAAAAAAAAOhReCY8AAAAAAAAAAAAAAA2IQkPAAAAAAAAAAAAAIBNSMIDAAAAAAAAAAAAAGATkvAAAAAAAAAAAAAAANiEJDwAAAAAAAAAAAAAADYhCQ8AAAAAAAAAAAAAgE1IwgMAAAAAAAAAAAAAYBOS8AAAAAAAAAAAAAAA2IQkPAAAAAAAsJ3D4dDLL78c62YAAAAAABB1JOEBAAAAAOhhfvCDH8jhcLT4M3ny5Fg3DQAAAACAHs8Z6wYAAAAAAAD7TZ48WU8//XTQNLfbHaPWAAAAAABw6uBOeAAAAAAAeiC32638/PygP5mZmZKahopfvny5rrjiCiUlJem0007TH/7wh6D3b9myRV//+teVlJSk7Oxs3XTTTTp27FjQPP/zP/+j4cOHy+12q0+fPpo9e3bQ66WlpfrWt76l5ORkDR48WK+88kpkVxoAAAAAgC6AJDwAAAAAAKeg+fPn6+qrr9bHH3+sGTNmaPr06dq+fbskqbq6WpMmTVJmZqY2bNig1atX6+9//3tQkn358uWaNWuWbrrpJm3ZskWvvPKKzjjjjKDPWLhwob7zne/ok08+0ZQpUzRjxgyVlZVFdT0BAAAAAIg2hzHGxLoRAAAAAADAPj/4wQ/029/+VomJiUHT77nnHt1zzz1yOBy6+eabtXz5cv9rF1xwgc477zw9+eSTWrVqle666y7t379fKSkpkqTXX39dV155pYqLi5WXl6e+ffvqhhtu0C9/+cuQbXA4HLr33nv1i1/8QlJTYr9Xr1564403eDY9AAAAAKBH45nwAAAAAAD0QF/72teCkuySlJWV5f/3+PHjg14bP368Nm/eLEnavn27Ro0a5U/AS9KECRPk9XpVVFQkh8Oh4uJiXXrppW224eyzz/b/OyUlRWlpaTp06FBHVwkAAAAAgG6BJDwAAAAAAD1QSkpKi+Hh7ZKUlGRpPpfLFfR/h8Mhr9cbiSYBAAAAANBl8Ex4AAAAAABOQevXr2/x/7POOkuSdNZZZ+njjz9WdXW1//V//etfiouL05AhQ5SamqqBAwdq7dq1UW0zAAAAAADdAXfCAwAAAADQA9XV1amkpCRomtPpVE5OjiRp9erVGjNmjC666CL97ne/0wcffKDf/OY3kqQZM2ZowYIFmjlzpu677z4dPnxYt956q66//nrl5eVJku677z7dfPPNys3N1RVXXKGqqir961//0q233hrdFQUAAAAAoIshCQ8AAAAAQA/0l7/8RX369AmaNmTIEO3YsUOStHDhQr3wwgu65ZZb1KdPHz3//PMaNmyYJCk5OVl//etfNWfOHJ1//vlKTk7W1VdfrYcffti/rJkzZ6q2tlaPPPKI7rzzTuXk5Ojb3/529FYQAAAAAIAuymGMMbFuBAAAAAAAiB6Hw6GXXnpJV111VaybAgAAAABAj8Mz4QEAAAAAAAAAAAAAsAlJeAAAAAAAAAAAAAAAbMIz4QEAAAAAOMXwZDoAAAAAACKHO+EBAAAAAAAAAAAAALAJSXgAAAAAAAAAAAAAAGxCEh4AAAAAAAAAAAAAAJuQhAcAAAAAAAAAAAAAwCYk4QEAAAAAAAAAAAAAsAlJeAAAAAAAAAAAAAAAbEISHgAAAAAAAAAAAAAAm5CEBwAAAAAAAAAAAADAJv8fJd2LqHxj9G8AAAAASUVORK5CYII="
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T22:59:03.704637Z",
     "start_time": "2025-04-28T22:58:56.043204Z"
    }
   },
   "cell_type": "code",
   "source": [
    "submission_loader = UnlabeledFacialDataset(\"data/test.csv\")\n",
    "\n",
    "features_list = [\n",
    "    \"left_eye_center_x\", \"left_eye_center_y\",\n",
    "    \"right_eye_center_x\", \"right_eye_center_y\",\n",
    "    \"left_eye_inner_corner_x\", \"left_eye_inner_corner_y\",\n",
    "    \"left_eye_outer_corner_x\", \"left_eye_outer_corner_y\",\n",
    "    \"right_eye_inner_corner_x\", \"right_eye_inner_corner_y\",\n",
    "    \"right_eye_outer_corner_x\", \"right_eye_outer_corner_y\",\n",
    "    \"left_eyebrow_inner_end_x\", \"left_eyebrow_inner_end_y\",\n",
    "    \"left_eyebrow_outer_end_x\", \"left_eyebrow_outer_end_y\",\n",
    "    \"right_eyebrow_inner_end_x\", \"right_eyebrow_inner_end_y\",\n",
    "    \"right_eyebrow_outer_end_x\", \"right_eyebrow_outer_end_y\",\n",
    "    \"nose_tip_x\", \"nose_tip_y\",\n",
    "    \"mouth_left_corner_x\", \"mouth_left_corner_y\",\n",
    "    \"mouth_right_corner_x\", \"mouth_right_corner_y\",\n",
    "    \"mouth_center_top_lip_x\", \"mouth_center_top_lip_y\",\n",
    "    \"mouth_center_bottom_lip_x\", \"mouth_center_bottom_lip_y\"\n",
    "]\n",
    "\n",
    "map_feature_to_index = {\n",
    "    feature: i for i, feature in enumerate(features_list)\n",
    "}\n",
    "\n",
    "#Generate Submission\n",
    "# Use the trained model to predict labels for unlabeled data\n",
    "def predict_on_unlabeled_data(model, dataloader, device, test_format_file_name, output_file_name):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    image_index_to_prediction = {}\n",
    "\n",
    "    with open(test_format_file_name, newline='') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "\n",
    "        with open(output_file_name, mode='w', newline='') as csvfile_out:\n",
    "            writer = csv.DictWriter(csvfile_out, fieldnames=[\"RowId\", \"Location\"])\n",
    "            writer.writeheader()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for row in csv_reader:\n",
    "                    image_id = int(row[\"ImageId\"])\n",
    "                    if image_id not in image_index_to_prediction:\n",
    "                        model_prediction = model(dataloader[image_id-1].to(device).unsqueeze(0))\n",
    "                        model_prediction = (model_prediction + 0.5) * 95\n",
    "                        model_prediction = torch.clamp(model_prediction, min=0, max=95)\n",
    "                        rounded_prediction = torch.round(model_prediction).to(torch.int)\n",
    "                        image_index_to_prediction[image_id] = rounded_prediction.squeeze(0).cpu().numpy()\n",
    "\n",
    "                    to_write_row = {}\n",
    "                    to_write_row[\"RowId\"] = row[\"RowId\"]\n",
    "                    to_write_row[\"Location\"] = image_index_to_prediction[image_id][map_feature_to_index[row[\"FeatureName\"]]]\n",
    "                    writer.writerow(to_write_row)\n",
    "\n",
    "\n",
    "predict_on_unlabeled_data(model, submission_loader, device, \"IdLookupTable.csv\", \"submission.csv\")\n"
   ],
   "id": "c778223924987ad5",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T22:58:09.375782Z",
     "start_time": "2025-04-28T22:58:09.373804Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ad3b3633f501d440",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
